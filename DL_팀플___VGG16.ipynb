{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_Mbc1aUOnY7",
        "outputId": "8656e8e7-f77b-432e-cb4f-86ddca566133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "Successfully installed opencv-python-4.8.1.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfh_Pq-NObSn",
        "outputId": "1300ab61-c2be-4c2b-8916-2d2a5b3c2a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5xUtHdjGF0R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import cross_validate\n",
        "from keras.layers import Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDWfJ2a-Gdsx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data augmentation"
      ],
      "metadata": {
        "id": "VXdQgFUWM9f7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 증강 X funtion"
      ],
      "metadata": {
        "id": "kwAUXNe3MgC7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1SVEvp1GfUn"
      },
      "outputs": [],
      "source": [
        "# 증강x\n",
        "def load_images_and_labels_parallel(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for folder_name in os.listdir(data_dir):\n",
        "        folder_path = os.path.join(data_dir, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for filename in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, filename)\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # 이미지를 RGB 형식으로 변환\n",
        "                img = cv2.resize(img, (32, 32))  # 이미지 크기 조절\n",
        "\n",
        "                # 이미지 데이터를 리스트에 추가\n",
        "                images.append(img)\n",
        "                # 레이블을 리스트에 추가\n",
        "                labels.append(folder_name)\n",
        "\n",
        "    return shuffle(images, labels, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 증강 O function\n"
      ],
      "metadata": {
        "id": "Tu9sgjJPMjie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤으로 하나의 증강 방식만을 선택 후 적용"
      ],
      "metadata": {
        "id": "PjCQwd8eTZs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "\n",
        "def load_images_and_labels(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # 랜덤으로 선택할 증강 리스트\n",
        "    augmentation_options = [\n",
        "        {'name': 'rotation', 'param': 40},\n",
        "        {'name': 'width_shift', 'param': 0.2},\n",
        "        {'name': 'height_shift', 'param': 0.2},\n",
        "        {'name': 'shear', 'param': 0.2},\n",
        "        {'name': 'zoom', 'param': 0.2},\n",
        "        {'name': 'horizontal_flip', 'param': True},\n",
        "    ]\n",
        "\n",
        "    # 데이터 증강을 위한 ImageDataGenerator 정의\n",
        "    datagen = ImageDataGenerator()\n",
        "\n",
        "    for folder_name in os.listdir(data_dir):\n",
        "        folder_path = os.path.join(data_dir, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for filename in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, filename)\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = cv2.resize(img, (32, 32))\n",
        "\n",
        "                # 원본 이미지를 리스트에 추가\n",
        "                images.append(img)\n",
        "                labels.append(folder_name)\n",
        "\n",
        "                # 랜덤으로 선택한 증강 옵션을 적용\n",
        "                selected_augmentations = random.sample(augmentation_options, k=random.randint(0, len(augmentation_options)))\n",
        "                for aug_option in selected_augmentations:\n",
        "                    if aug_option['name'] == 'rotation':\n",
        "                        img = ImageDataGenerator(rotation_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'width_shift':\n",
        "                        img = ImageDataGenerator(width_shift_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'height_shift':\n",
        "                        img = ImageDataGenerator(height_shift_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'shear':\n",
        "                        img = ImageDataGenerator(shear_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'zoom':\n",
        "                        img = ImageDataGenerator(zoom_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'horizontal_flip':\n",
        "                        img = ImageDataGenerator(horizontal_flip=aug_option['param']).random_transform(img)\n",
        "\n",
        "                    # 증강된 이미지를 리스트에 추가\n",
        "                    images.append(img)\n",
        "                    labels.append(folder_name)\n",
        "    return shuffle(images, labels, random_state=42)"
      ],
      "metadata": {
        "id": "EXzICLrSeP0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "S3QEcti9M0yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uujV_Qgrg8Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## vgg16 baseline model"
      ],
      "metadata": {
        "id": "yIkYJpKSNByP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline + 증강X : 0.7387279391288757**\n"
      ],
      "metadata": {
        "id": "PUQBKgxqNYvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels_parallel(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test))\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgT1h8NNN30",
        "outputId": "5f7c83a9-f7ef-431d-a12a-78a004e61f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 6s 428ms/step - loss: 63.1705 - accuracy: 0.5922 - val_loss: 0.6919 - val_accuracy: 0.7308\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6866 - accuracy: 0.6731 - val_loss: 0.5700 - val_accuracy: 0.7308\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6262 - accuracy: 0.6731 - val_loss: 0.6238 - val_accuracy: 0.7308\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6377 - accuracy: 0.6731 - val_loss: 0.6181 - val_accuracy: 0.7308\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6342 - accuracy: 0.6731 - val_loss: 0.5794 - val_accuracy: 0.7308\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6116 - accuracy: 0.6731 - val_loss: 0.5554 - val_accuracy: 0.7308\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5983 - accuracy: 0.6731 - val_loss: 0.5543 - val_accuracy: 0.7308\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5713 - accuracy: 0.6731 - val_loss: 0.5264 - val_accuracy: 0.7308\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6573 - accuracy: 0.6731 - val_loss: 0.6703 - val_accuracy: 0.7308\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6766 - accuracy: 0.6731 - val_loss: 0.6692 - val_accuracy: 0.7308\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6705 - accuracy: 0.6731 - val_loss: 0.5719 - val_accuracy: 0.7308\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6626 - accuracy: 0.6731 - val_loss: 0.6362 - val_accuracy: 0.7308\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6633 - accuracy: 0.6731 - val_loss: 0.6650 - val_accuracy: 0.7308\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6718 - accuracy: 0.6731 - val_loss: 0.6590 - val_accuracy: 0.7308\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6659 - accuracy: 0.6731 - val_loss: 0.6444 - val_accuracy: 0.7308\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6556 - accuracy: 0.6731 - val_loss: 0.6169 - val_accuracy: 0.7308\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6382 - accuracy: 0.6731 - val_loss: 0.5832 - val_accuracy: 0.7308\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6249 - accuracy: 0.6731 - val_loss: 0.5791 - val_accuracy: 0.7308\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6228 - accuracy: 0.6731 - val_loss: 0.5808 - val_accuracy: 0.7308\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6212 - accuracy: 0.6731 - val_loss: 0.5755 - val_accuracy: 0.7308\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6121 - accuracy: 0.6731 - val_loss: 0.5567 - val_accuracy: 0.7308\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5815 - accuracy: 0.6731 - val_loss: 0.5243 - val_accuracy: 0.7308\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5598 - accuracy: 0.6731 - val_loss: 0.8344 - val_accuracy: 0.7308\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.7350 - accuracy: 0.6731 - val_loss: 0.6347 - val_accuracy: 0.7308\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6525 - accuracy: 0.6731 - val_loss: 0.6359 - val_accuracy: 0.7308\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6526 - accuracy: 0.6731 - val_loss: 0.6319 - val_accuracy: 0.7308\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6493 - accuracy: 0.6731 - val_loss: 0.6248 - val_accuracy: 0.7308\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6452 - accuracy: 0.6731 - val_loss: 0.6152 - val_accuracy: 0.7308\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6398 - accuracy: 0.6731 - val_loss: 0.6053 - val_accuracy: 0.7308\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6348 - accuracy: 0.6731 - val_loss: 0.5962 - val_accuracy: 0.7308\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6326 - accuracy: 0.6731 - val_loss: 0.5893 - val_accuracy: 0.7308\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6320 - accuracy: 0.6731 - val_loss: 0.5843 - val_accuracy: 0.7308\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6318 - accuracy: 0.6731 - val_loss: 0.5854 - val_accuracy: 0.7308\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6314 - accuracy: 0.6731 - val_loss: 0.5894 - val_accuracy: 0.7308\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6316 - accuracy: 0.6731 - val_loss: 0.5909 - val_accuracy: 0.7308\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6321 - accuracy: 0.6731 - val_loss: 0.5929 - val_accuracy: 0.7308\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6319 - accuracy: 0.6731 - val_loss: 0.5902 - val_accuracy: 0.7308\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6276 - accuracy: 0.6731 - val_loss: 0.5702 - val_accuracy: 0.7308\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6326 - accuracy: 0.6731 - val_loss: 0.5960 - val_accuracy: 0.7308\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6321 - accuracy: 0.6731 - val_loss: 0.5975 - val_accuracy: 0.7308\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6330 - accuracy: 0.6731 - val_loss: 0.5978 - val_accuracy: 0.7308\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6326 - accuracy: 0.6731 - val_loss: 0.5938 - val_accuracy: 0.7308\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6293 - accuracy: 0.6731 - val_loss: 0.5699 - val_accuracy: 0.7308\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6241 - accuracy: 0.6731 - val_loss: 0.5873 - val_accuracy: 0.7308\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.6283 - accuracy: 0.6731 - val_loss: 0.5970 - val_accuracy: 0.7308\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6326 - accuracy: 0.6731 - val_loss: 0.5972 - val_accuracy: 0.7308\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6281 - accuracy: 0.6731 - val_loss: 0.5630 - val_accuracy: 0.7308\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6500 - accuracy: 0.6731 - val_loss: 0.5945 - val_accuracy: 0.7308\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6317 - accuracy: 0.6731 - val_loss: 0.6056 - val_accuracy: 0.7308\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6363 - accuracy: 0.6731 - val_loss: 0.6056 - val_accuracy: 0.7308\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6358 - accuracy: 0.6731 - val_loss: 0.6020 - val_accuracy: 0.7308\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6340 - accuracy: 0.6731 - val_loss: 0.5971 - val_accuracy: 0.7308\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6331 - accuracy: 0.6731 - val_loss: 0.5920 - val_accuracy: 0.7308\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6314 - accuracy: 0.6731 - val_loss: 0.5891 - val_accuracy: 0.7308\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6321 - accuracy: 0.6731 - val_loss: 0.5863 - val_accuracy: 0.7308\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6325 - accuracy: 0.6731 - val_loss: 0.5855 - val_accuracy: 0.7308\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6331 - accuracy: 0.6731 - val_loss: 0.5853 - val_accuracy: 0.7308\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6330 - accuracy: 0.6731 - val_loss: 0.5862 - val_accuracy: 0.7308\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6319 - accuracy: 0.6731 - val_loss: 0.5888 - val_accuracy: 0.7308\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6317 - accuracy: 0.6731 - val_loss: 0.5915 - val_accuracy: 0.7308\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6305 - accuracy: 0.6731 - val_loss: 0.5837 - val_accuracy: 0.7308\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6243 - accuracy: 0.6731 - val_loss: 0.5634 - val_accuracy: 0.7308\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6064 - accuracy: 0.6731 - val_loss: 0.5536 - val_accuracy: 0.7308\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5715 - accuracy: 0.6731 - val_loss: 0.5424 - val_accuracy: 0.7308\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5599 - accuracy: 0.6731 - val_loss: 0.5542 - val_accuracy: 0.7308\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5468 - accuracy: 0.6731 - val_loss: 0.5269 - val_accuracy: 0.7308\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.5395 - accuracy: 0.6731 - val_loss: 0.5184 - val_accuracy: 0.7308\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5344 - accuracy: 0.6731 - val_loss: 0.5287 - val_accuracy: 0.7308\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5432 - accuracy: 0.6731 - val_loss: 0.5343 - val_accuracy: 0.7308\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5279 - accuracy: 0.6731 - val_loss: 0.6115 - val_accuracy: 0.7308\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5216 - accuracy: 0.6731 - val_loss: 0.5191 - val_accuracy: 0.7308\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5023 - accuracy: 0.6731 - val_loss: 0.5780 - val_accuracy: 0.7308\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5027 - accuracy: 0.6731 - val_loss: 0.5078 - val_accuracy: 0.7308\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4905 - accuracy: 0.6731 - val_loss: 0.5201 - val_accuracy: 0.7308\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4850 - accuracy: 0.6731 - val_loss: 0.5430 - val_accuracy: 0.7308\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4807 - accuracy: 0.6731 - val_loss: 0.4970 - val_accuracy: 0.7308\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4552 - accuracy: 0.6731 - val_loss: 0.5048 - val_accuracy: 0.6538\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5592 - accuracy: 0.7379 - val_loss: 0.6714 - val_accuracy: 0.4872\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6320 - accuracy: 0.5599 - val_loss: 0.5869 - val_accuracy: 0.7051\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5507 - accuracy: 0.6634 - val_loss: 0.5368 - val_accuracy: 0.6026\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5097 - accuracy: 0.6343 - val_loss: 0.6534 - val_accuracy: 0.7436\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5340 - accuracy: 0.6472 - val_loss: 0.5363 - val_accuracy: 0.6154\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5113 - accuracy: 0.6731 - val_loss: 0.5732 - val_accuracy: 0.6795\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4854 - accuracy: 0.6828 - val_loss: 0.5156 - val_accuracy: 0.6923\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4643 - accuracy: 0.7087 - val_loss: 0.4896 - val_accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4597 - accuracy: 0.7540 - val_loss: 0.6392 - val_accuracy: 0.7564\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4689 - accuracy: 0.7184 - val_loss: 0.5035 - val_accuracy: 0.7179\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4338 - accuracy: 0.7799 - val_loss: 0.6593 - val_accuracy: 0.7692\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4045 - accuracy: 0.7735 - val_loss: 0.5016 - val_accuracy: 0.6795\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4221 - accuracy: 0.7961 - val_loss: 0.5546 - val_accuracy: 0.7436\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3503 - accuracy: 0.8641 - val_loss: 0.6295 - val_accuracy: 0.7308\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3235 - accuracy: 0.8706 - val_loss: 0.5352 - val_accuracy: 0.7692\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3359 - accuracy: 0.8770 - val_loss: 0.5743 - val_accuracy: 0.6667\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3727 - accuracy: 0.8285 - val_loss: 0.5936 - val_accuracy: 0.7692\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3575 - accuracy: 0.8447 - val_loss: 0.4968 - val_accuracy: 0.7179\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3079 - accuracy: 0.8576 - val_loss: 0.4907 - val_accuracy: 0.7308\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2719 - accuracy: 0.8867 - val_loss: 0.4824 - val_accuracy: 0.7436\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2210 - accuracy: 0.9288 - val_loss: 0.5056 - val_accuracy: 0.7564\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2423 - accuracy: 0.8932 - val_loss: 0.6078 - val_accuracy: 0.7436\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3373 - accuracy: 0.8511 - val_loss: 0.4918 - val_accuracy: 0.7692\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.4918 - accuracy: 0.7692\n",
            "Test Loss: 0.49182119965553284, Test Accuracy: 0.7692307829856873\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 4s 140ms/step - loss: 48.6946 - accuracy: 0.6990 - val_loss: 0.6918 - val_accuracy: 0.6154\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6814 - accuracy: 0.7023 - val_loss: 2.1946 - val_accuracy: 0.6154\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1252 - accuracy: 0.7023 - val_loss: 0.6864 - val_accuracy: 0.6154\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6801 - accuracy: 0.7023 - val_loss: 0.6831 - val_accuracy: 0.6154\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6722 - accuracy: 0.7023 - val_loss: 0.6758 - val_accuracy: 0.6154\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6526 - accuracy: 0.7023 - val_loss: 0.6645 - val_accuracy: 0.6154\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6341 - accuracy: 0.7023 - val_loss: 0.6699 - val_accuracy: 0.6154\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6107 - accuracy: 0.7023 - val_loss: 0.6680 - val_accuracy: 0.6154\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6131 - accuracy: 0.7023 - val_loss: 0.6741 - val_accuracy: 0.6154\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6077 - accuracy: 0.7023 - val_loss: 0.6863 - val_accuracy: 0.6154\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6102 - accuracy: 0.7023 - val_loss: 0.7016 - val_accuracy: 0.6154\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6108 - accuracy: 0.7023 - val_loss: 0.6985 - val_accuracy: 0.6154\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6099 - accuracy: 0.7023 - val_loss: 0.6882 - val_accuracy: 0.6154\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6078 - accuracy: 0.7023 - val_loss: 0.6825 - val_accuracy: 0.6154\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6042 - accuracy: 0.7023 - val_loss: 0.6877 - val_accuracy: 0.6154\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5968 - accuracy: 0.7023 - val_loss: 0.6638 - val_accuracy: 0.6154\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5925 - accuracy: 0.7023 - val_loss: 0.6539 - val_accuracy: 0.6154\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6110 - accuracy: 0.7023 - val_loss: 0.6663 - val_accuracy: 0.6154\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6231 - accuracy: 0.7023 - val_loss: 0.6662 - val_accuracy: 0.6154\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6187 - accuracy: 0.7023 - val_loss: 0.6635 - val_accuracy: 0.6154\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5934 - accuracy: 0.7023 - val_loss: 0.7088 - val_accuracy: 0.6154\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5940 - accuracy: 0.7023 - val_loss: 0.6638 - val_accuracy: 0.6154\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5907 - accuracy: 0.7023 - val_loss: 0.6619 - val_accuracy: 0.6154\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6059 - accuracy: 0.7023 - val_loss: 0.6688 - val_accuracy: 0.6154\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6150 - accuracy: 0.7023 - val_loss: 0.6697 - val_accuracy: 0.6154\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6131 - accuracy: 0.7023 - val_loss: 0.6728 - val_accuracy: 0.6154\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6102 - accuracy: 0.7023 - val_loss: 0.6805 - val_accuracy: 0.6154\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6091 - accuracy: 0.7023 - val_loss: 0.6919 - val_accuracy: 0.6154\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6098 - accuracy: 0.7023 - val_loss: 0.6973 - val_accuracy: 0.6154\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6111 - accuracy: 0.7023 - val_loss: 0.6960 - val_accuracy: 0.6154\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6113 - accuracy: 0.7023 - val_loss: 0.6867 - val_accuracy: 0.6154\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6084 - accuracy: 0.7023 - val_loss: 0.6831 - val_accuracy: 0.6154\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6067 - accuracy: 0.7023 - val_loss: 0.6776 - val_accuracy: 0.6154\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5972 - accuracy: 0.7023 - val_loss: 0.6559 - val_accuracy: 0.6154\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5675 - accuracy: 0.7023 - val_loss: 0.8143 - val_accuracy: 0.6154\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6431 - accuracy: 0.7023 - val_loss: 0.6666 - val_accuracy: 0.6154\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6229 - accuracy: 0.7023 - val_loss: 0.6663 - val_accuracy: 0.6154\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6240 - accuracy: 0.7023 - val_loss: 0.6666 - val_accuracy: 0.6154\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6198 - accuracy: 0.7023 - val_loss: 0.6692 - val_accuracy: 0.6154\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6142 - accuracy: 0.7023 - val_loss: 0.6787 - val_accuracy: 0.6154\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6090 - accuracy: 0.7023 - val_loss: 0.6878 - val_accuracy: 0.6154\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6080 - accuracy: 0.7023 - val_loss: 0.6853 - val_accuracy: 0.6154\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6077 - accuracy: 0.7023 - val_loss: 0.6797 - val_accuracy: 0.6154\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6091 - accuracy: 0.7023 - val_loss: 0.6770 - val_accuracy: 0.6154\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6092 - accuracy: 0.7023 - val_loss: 0.6784 - val_accuracy: 0.6154\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6070 - accuracy: 0.7023 - val_loss: 0.7011 - val_accuracy: 0.6154\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6077 - accuracy: 0.7023 - val_loss: 0.6803 - val_accuracy: 0.6154\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6022 - accuracy: 0.7023 - val_loss: 0.6830 - val_accuracy: 0.6154\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5881 - accuracy: 0.7023 - val_loss: 0.6698 - val_accuracy: 0.6154\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5972 - accuracy: 0.7023 - val_loss: 0.7968 - val_accuracy: 0.6154\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6191 - accuracy: 0.7023 - val_loss: 0.6559 - val_accuracy: 0.6154\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.5840 - accuracy: 0.7023 - val_loss: 0.7445 - val_accuracy: 0.6154\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6099 - accuracy: 0.7023 - val_loss: 0.6584 - val_accuracy: 0.6154\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6132 - accuracy: 0.7023 - val_loss: 0.6503 - val_accuracy: 0.6154\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5864 - accuracy: 0.7023 - val_loss: 0.7059 - val_accuracy: 0.6154\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5869 - accuracy: 0.7023 - val_loss: 0.6243 - val_accuracy: 0.6154\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5549 - accuracy: 0.7023 - val_loss: 0.6096 - val_accuracy: 0.6154\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.5365 - accuracy: 0.7023 - val_loss: 0.6014 - val_accuracy: 0.6154\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.5372 - accuracy: 0.7023 - val_loss: 0.6224 - val_accuracy: 0.6154\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5286 - accuracy: 0.7023 - val_loss: 0.6024 - val_accuracy: 0.6154\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5460 - accuracy: 0.7023 - val_loss: 0.5839 - val_accuracy: 0.6154\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5478 - accuracy: 0.7023 - val_loss: 0.5651 - val_accuracy: 0.6154\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5152 - accuracy: 0.7023 - val_loss: 0.5966 - val_accuracy: 0.6154\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5308 - accuracy: 0.7023 - val_loss: 0.5672 - val_accuracy: 0.6154\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5239 - accuracy: 0.7023 - val_loss: 0.5290 - val_accuracy: 0.6154\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.4907 - accuracy: 0.7023 - val_loss: 0.5309 - val_accuracy: 0.6154\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4674 - accuracy: 0.7023 - val_loss: 0.5524 - val_accuracy: 0.6154\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4763 - accuracy: 0.7023 - val_loss: 0.5579 - val_accuracy: 0.6154\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5509 - accuracy: 0.7023 - val_loss: 0.5303 - val_accuracy: 0.6154\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5111 - accuracy: 0.7023 - val_loss: 0.5393 - val_accuracy: 0.6154\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5231 - accuracy: 0.7023 - val_loss: 0.5542 - val_accuracy: 0.6154\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5231 - accuracy: 0.7023 - val_loss: 0.5357 - val_accuracy: 0.6154\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5317 - accuracy: 0.7023 - val_loss: 0.5828 - val_accuracy: 0.6154\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5246 - accuracy: 0.7023 - val_loss: 0.5285 - val_accuracy: 0.6154\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5032 - accuracy: 0.7023 - val_loss: 0.5144 - val_accuracy: 0.6154\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.5028 - accuracy: 0.7023 - val_loss: 0.5272 - val_accuracy: 0.6154\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4863 - accuracy: 0.7023 - val_loss: 0.5330 - val_accuracy: 0.6154\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4753 - accuracy: 0.7023 - val_loss: 0.5230 - val_accuracy: 0.6154\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4683 - accuracy: 0.7023 - val_loss: 0.5226 - val_accuracy: 0.6154\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4513 - accuracy: 0.7023 - val_loss: 0.5082 - val_accuracy: 0.6154\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4711 - accuracy: 0.7023 - val_loss: 0.5029 - val_accuracy: 0.6154\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4776 - accuracy: 0.7023 - val_loss: 0.5048 - val_accuracy: 0.6154\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4721 - accuracy: 0.7023 - val_loss: 0.4889 - val_accuracy: 0.6154\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4419 - accuracy: 0.7023 - val_loss: 0.5877 - val_accuracy: 0.6154\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4122 - accuracy: 0.7023 - val_loss: 0.4983 - val_accuracy: 0.7692\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3919 - accuracy: 0.7767 - val_loss: 0.6207 - val_accuracy: 0.7051\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3798 - accuracy: 0.8188 - val_loss: 0.4682 - val_accuracy: 0.7436\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3598 - accuracy: 0.8252 - val_loss: 0.9448 - val_accuracy: 0.7051\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4442 - accuracy: 0.7799 - val_loss: 0.5408 - val_accuracy: 0.6538\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5366 - accuracy: 0.6278 - val_loss: 0.5491 - val_accuracy: 0.6795\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4674 - accuracy: 0.6893 - val_loss: 0.6388 - val_accuracy: 0.7051\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4115 - accuracy: 0.7702 - val_loss: 0.5696 - val_accuracy: 0.7051\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4183 - accuracy: 0.8220 - val_loss: 0.5008 - val_accuracy: 0.7436\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.3352 - accuracy: 0.8252 - val_loss: 0.8725 - val_accuracy: 0.7308\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2621 - accuracy: 0.8641 - val_loss: 0.9769 - val_accuracy: 0.7692\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2925 - accuracy: 0.8608 - val_loss: 0.8908 - val_accuracy: 0.6923\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3512 - accuracy: 0.7961 - val_loss: 0.4392 - val_accuracy: 0.7692\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3611 - accuracy: 0.8220 - val_loss: 0.5034 - val_accuracy: 0.7564\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3457 - accuracy: 0.8188 - val_loss: 0.6226 - val_accuracy: 0.7821\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3078 - accuracy: 0.8511 - val_loss: 0.7432 - val_accuracy: 0.8205\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.7432 - accuracy: 0.8205\n",
            "Test Loss: 0.7432253956794739, Test Accuracy: 0.8205128312110901\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 5s 420ms/step - loss: 45.2381 - accuracy: 0.5355 - val_loss: 0.6912 - val_accuracy: 0.7403\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6840 - accuracy: 0.6710 - val_loss: 0.6622 - val_accuracy: 0.7403\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6922 - accuracy: 0.6710 - val_loss: 0.6755 - val_accuracy: 0.7403\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6795 - accuracy: 0.6710 - val_loss: 0.6654 - val_accuracy: 0.7403\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6718 - accuracy: 0.6710 - val_loss: 0.6418 - val_accuracy: 0.7403\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6446 - accuracy: 0.6710 - val_loss: 0.6510 - val_accuracy: 0.7403\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6982 - accuracy: 0.6710 - val_loss: 0.6264 - val_accuracy: 0.7403\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6500 - accuracy: 0.6710 - val_loss: 0.6265 - val_accuracy: 0.7403\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6487 - accuracy: 0.6710 - val_loss: 0.6181 - val_accuracy: 0.7403\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6440 - accuracy: 0.6710 - val_loss: 0.6051 - val_accuracy: 0.7403\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6370 - accuracy: 0.6710 - val_loss: 0.5919 - val_accuracy: 0.7403\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6330 - accuracy: 0.6710 - val_loss: 0.5803 - val_accuracy: 0.7403\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6322 - accuracy: 0.6710 - val_loss: 0.5759 - val_accuracy: 0.7403\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6315 - accuracy: 0.6710 - val_loss: 0.5716 - val_accuracy: 0.7403\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6296 - accuracy: 0.6710 - val_loss: 0.5686 - val_accuracy: 0.7403\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6191 - accuracy: 0.6710 - val_loss: 0.5481 - val_accuracy: 0.7403\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.5903 - accuracy: 0.6710 - val_loss: 0.5972 - val_accuracy: 0.7403\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6376 - accuracy: 0.6710 - val_loss: 0.5977 - val_accuracy: 0.7403\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6722 - accuracy: 0.6710 - val_loss: 0.6140 - val_accuracy: 0.7403\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6439 - accuracy: 0.6710 - val_loss: 0.6179 - val_accuracy: 0.7403\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6447 - accuracy: 0.6710 - val_loss: 0.6116 - val_accuracy: 0.7403\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6405 - accuracy: 0.6710 - val_loss: 0.6006 - val_accuracy: 0.7403\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6361 - accuracy: 0.6710 - val_loss: 0.5876 - val_accuracy: 0.7403\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6320 - accuracy: 0.6710 - val_loss: 0.5798 - val_accuracy: 0.7403\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6337 - accuracy: 0.6710 - val_loss: 0.5757 - val_accuracy: 0.7403\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6370 - accuracy: 0.6710 - val_loss: 0.5751 - val_accuracy: 0.7403\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6359 - accuracy: 0.6710 - val_loss: 0.5779 - val_accuracy: 0.7403\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6334 - accuracy: 0.6710 - val_loss: 0.5809 - val_accuracy: 0.7403\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6295 - accuracy: 0.6710 - val_loss: 0.5763 - val_accuracy: 0.7403\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6188 - accuracy: 0.6710 - val_loss: 0.5821 - val_accuracy: 0.7403\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6389 - accuracy: 0.6710 - val_loss: 0.6058 - val_accuracy: 0.7403\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6410 - accuracy: 0.6710 - val_loss: 0.6127 - val_accuracy: 0.7403\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6422 - accuracy: 0.6710 - val_loss: 0.6087 - val_accuracy: 0.7403\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6391 - accuracy: 0.6710 - val_loss: 0.5980 - val_accuracy: 0.7403\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6323 - accuracy: 0.6710 - val_loss: 0.5647 - val_accuracy: 0.7403\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6238 - accuracy: 0.6710 - val_loss: 0.5513 - val_accuracy: 0.7403\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6017 - accuracy: 0.6710 - val_loss: 0.5264 - val_accuracy: 0.7403\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5885 - accuracy: 0.6710 - val_loss: 0.5325 - val_accuracy: 0.7403\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5674 - accuracy: 0.6710 - val_loss: 0.5589 - val_accuracy: 0.7403\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5684 - accuracy: 0.6710 - val_loss: 0.5926 - val_accuracy: 0.7403\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6291 - accuracy: 0.6710 - val_loss: 0.5640 - val_accuracy: 0.7403\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5965 - accuracy: 0.6710 - val_loss: 0.5923 - val_accuracy: 0.7403\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6260 - accuracy: 0.6710 - val_loss: 0.6336 - val_accuracy: 0.7403\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6396 - accuracy: 0.6710 - val_loss: 0.5831 - val_accuracy: 0.7403\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.5641 - accuracy: 0.6710 - val_loss: 0.6304 - val_accuracy: 0.7403\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6177 - accuracy: 0.6710 - val_loss: 0.6356 - val_accuracy: 0.7403\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6483 - accuracy: 0.6710 - val_loss: 0.6342 - val_accuracy: 0.7403\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6344 - accuracy: 0.6710 - val_loss: 0.5825 - val_accuracy: 0.7403\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5865 - accuracy: 0.6710 - val_loss: 0.4925 - val_accuracy: 0.7403\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5519 - accuracy: 0.6710 - val_loss: 0.5135 - val_accuracy: 0.7403\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5331 - accuracy: 0.6710 - val_loss: 0.4981 - val_accuracy: 0.7403\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5192 - accuracy: 0.6710 - val_loss: 0.5001 - val_accuracy: 0.7403\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.5027 - accuracy: 0.6710 - val_loss: 0.4801 - val_accuracy: 0.7403\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4865 - accuracy: 0.6710 - val_loss: 0.4699 - val_accuracy: 0.7273\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4797 - accuracy: 0.6806 - val_loss: 0.5605 - val_accuracy: 0.5584\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4911 - accuracy: 0.7516 - val_loss: 0.4840 - val_accuracy: 0.7143\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4873 - accuracy: 0.7065 - val_loss: 0.6281 - val_accuracy: 0.4675\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5415 - accuracy: 0.6194 - val_loss: 0.5172 - val_accuracy: 0.6753\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4729 - accuracy: 0.7645 - val_loss: 0.4867 - val_accuracy: 0.7013\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4599 - accuracy: 0.7871 - val_loss: 0.4630 - val_accuracy: 0.7792\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4695 - accuracy: 0.7968 - val_loss: 0.4635 - val_accuracy: 0.7662\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.4362 - accuracy: 0.7710 - val_loss: 0.4426 - val_accuracy: 0.7273\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.4048 - accuracy: 0.7806 - val_loss: 1.0554 - val_accuracy: 0.7922\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6916 - accuracy: 0.7161 - val_loss: 0.6506 - val_accuracy: 0.4675\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.6074 - accuracy: 0.6065 - val_loss: 0.5279 - val_accuracy: 0.7273\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4952 - accuracy: 0.7387 - val_loss: 0.4965 - val_accuracy: 0.7273\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4727 - accuracy: 0.7968 - val_loss: 0.4771 - val_accuracy: 0.7662\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4539 - accuracy: 0.7839 - val_loss: 0.4717 - val_accuracy: 0.7532\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.4368 - accuracy: 0.8065 - val_loss: 0.4742 - val_accuracy: 0.7403\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.4184 - accuracy: 0.8258 - val_loss: 0.4801 - val_accuracy: 0.7662\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.3662 - accuracy: 0.8258 - val_loss: 0.4743 - val_accuracy: 0.7532\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.3191 - accuracy: 0.8484 - val_loss: 0.5502 - val_accuracy: 0.7013\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.3253 - accuracy: 0.8548 - val_loss: 0.5938 - val_accuracy: 0.8182\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3753 - accuracy: 0.8548 - val_loss: 0.4692 - val_accuracy: 0.7922\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3759 - accuracy: 0.8290 - val_loss: 0.3990 - val_accuracy: 0.8052\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3243 - accuracy: 0.8355 - val_loss: 0.3708 - val_accuracy: 0.8052\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3250 - accuracy: 0.8484 - val_loss: 0.4067 - val_accuracy: 0.8052\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2961 - accuracy: 0.8710 - val_loss: 0.5240 - val_accuracy: 0.7662\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3523 - accuracy: 0.8645 - val_loss: 0.4406 - val_accuracy: 0.8182\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3841 - accuracy: 0.7903 - val_loss: 0.4997 - val_accuracy: 0.7662\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3837 - accuracy: 0.8226 - val_loss: 0.4659 - val_accuracy: 0.7922\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3551 - accuracy: 0.8290 - val_loss: 0.5209 - val_accuracy: 0.8052\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3594 - accuracy: 0.8387 - val_loss: 0.4509 - val_accuracy: 0.7922\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3586 - accuracy: 0.8677 - val_loss: 0.4542 - val_accuracy: 0.7922\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2962 - accuracy: 0.8903 - val_loss: 0.5021 - val_accuracy: 0.7532\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2387 - accuracy: 0.9032 - val_loss: 0.5117 - val_accuracy: 0.7662\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2341 - accuracy: 0.8968 - val_loss: 0.5600 - val_accuracy: 0.8052\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1675 - accuracy: 0.9323 - val_loss: 1.6384 - val_accuracy: 0.6753\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6651 - accuracy: 0.8194 - val_loss: 0.4712 - val_accuracy: 0.7662\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4468 - accuracy: 0.8258 - val_loss: 0.5553 - val_accuracy: 0.7273\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4607 - accuracy: 0.8419 - val_loss: 0.4475 - val_accuracy: 0.7403\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4003 - accuracy: 0.8226 - val_loss: 0.4550 - val_accuracy: 0.7532\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.3421 - accuracy: 0.8323 - val_loss: 0.4576 - val_accuracy: 0.7792\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3595 - accuracy: 0.8323 - val_loss: 0.4546 - val_accuracy: 0.7532\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3003 - accuracy: 0.8613 - val_loss: 0.3784 - val_accuracy: 0.8052\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2266 - accuracy: 0.8903 - val_loss: 0.4468 - val_accuracy: 0.8052\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3008 - accuracy: 0.8419 - val_loss: 0.3911 - val_accuracy: 0.7273\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2695 - accuracy: 0.8677 - val_loss: 0.4999 - val_accuracy: 0.8052\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2577 - accuracy: 0.8968 - val_loss: 0.4153 - val_accuracy: 0.7013\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2318 - accuracy: 0.8581 - val_loss: 0.5393 - val_accuracy: 0.7662\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.5393 - accuracy: 0.7662\n",
            "Test Loss: 0.5392736196517944, Test Accuracy: 0.7662337422370911\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 4s 142ms/step - loss: 23.0725 - accuracy: 0.5903 - val_loss: 0.6909 - val_accuracy: 0.6753\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.6819 - accuracy: 0.6871 - val_loss: 1.4981 - val_accuracy: 0.6753\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0909 - accuracy: 0.6871 - val_loss: 0.6830 - val_accuracy: 0.6753\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6815 - accuracy: 0.6871 - val_loss: 0.6790 - val_accuracy: 0.6753\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6755 - accuracy: 0.6871 - val_loss: 0.6684 - val_accuracy: 0.6753\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6627 - accuracy: 0.6871 - val_loss: 0.6504 - val_accuracy: 0.6753\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6406 - accuracy: 0.6871 - val_loss: 0.6232 - val_accuracy: 0.6753\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6859 - accuracy: 0.6871 - val_loss: 0.6279 - val_accuracy: 0.6753\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6222 - accuracy: 0.6871 - val_loss: 0.6322 - val_accuracy: 0.6753\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6255 - accuracy: 0.6871 - val_loss: 0.6323 - val_accuracy: 0.6753\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6251 - accuracy: 0.6871 - val_loss: 0.6315 - val_accuracy: 0.6753\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6241 - accuracy: 0.6871 - val_loss: 0.6305 - val_accuracy: 0.6753\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6221 - accuracy: 0.6871 - val_loss: 0.6302 - val_accuracy: 0.6753\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6210 - accuracy: 0.6871 - val_loss: 0.6306 - val_accuracy: 0.6753\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6218 - accuracy: 0.6871 - val_loss: 0.6315 - val_accuracy: 0.6753\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6216 - accuracy: 0.6871 - val_loss: 0.6313 - val_accuracy: 0.6753\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6216 - accuracy: 0.6871 - val_loss: 0.6307 - val_accuracy: 0.6753\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6206 - accuracy: 0.6871 - val_loss: 0.6320 - val_accuracy: 0.6753\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6202 - accuracy: 0.6871 - val_loss: 0.6301 - val_accuracy: 0.6753\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6212 - accuracy: 0.6871 - val_loss: 0.6302 - val_accuracy: 0.6753\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6213 - accuracy: 0.6871 - val_loss: 0.6294 - val_accuracy: 0.6753\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6201 - accuracy: 0.6871 - val_loss: 0.6266 - val_accuracy: 0.6753\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6165 - accuracy: 0.6871 - val_loss: 0.6205 - val_accuracy: 0.6753\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6100 - accuracy: 0.6871 - val_loss: 0.6164 - val_accuracy: 0.6753\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6420 - accuracy: 0.6871 - val_loss: 0.6319 - val_accuracy: 0.6753\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.6265 - accuracy: 0.6871 - val_loss: 0.6338 - val_accuracy: 0.6753\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6269 - accuracy: 0.6871 - val_loss: 0.6275 - val_accuracy: 0.6753\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6204 - accuracy: 0.6871 - val_loss: 0.6252 - val_accuracy: 0.6753\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6198 - accuracy: 0.6871 - val_loss: 0.6245 - val_accuracy: 0.6753\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6168 - accuracy: 0.6871 - val_loss: 0.6191 - val_accuracy: 0.6753\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6115 - accuracy: 0.6871 - val_loss: 0.6085 - val_accuracy: 0.6753\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.6004 - accuracy: 0.6871 - val_loss: 0.8149 - val_accuracy: 0.6753\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.7149 - accuracy: 0.6871 - val_loss: 0.6361 - val_accuracy: 0.6753\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6305 - accuracy: 0.6871 - val_loss: 0.6383 - val_accuracy: 0.6753\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6329 - accuracy: 0.6871 - val_loss: 0.6379 - val_accuracy: 0.6753\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6314 - accuracy: 0.6871 - val_loss: 0.6347 - val_accuracy: 0.6753\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6268 - accuracy: 0.6871 - val_loss: 0.6312 - val_accuracy: 0.6753\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6225 - accuracy: 0.6871 - val_loss: 0.6307 - val_accuracy: 0.6753\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6230 - accuracy: 0.6871 - val_loss: 0.6331 - val_accuracy: 0.6753\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6227 - accuracy: 0.6871 - val_loss: 0.6329 - val_accuracy: 0.6753\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6223 - accuracy: 0.6871 - val_loss: 0.6319 - val_accuracy: 0.6753\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6227 - accuracy: 0.6871 - val_loss: 0.6307 - val_accuracy: 0.6753\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6214 - accuracy: 0.6871 - val_loss: 0.6307 - val_accuracy: 0.6753\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6214 - accuracy: 0.6871 - val_loss: 0.6305 - val_accuracy: 0.6753\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6215 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6216 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6217 - accuracy: 0.6871 - val_loss: 0.6305 - val_accuracy: 0.6753\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6215 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6215 - accuracy: 0.6871 - val_loss: 0.6303 - val_accuracy: 0.6753\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6220 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6220 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6217 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6214 - accuracy: 0.6871 - val_loss: 0.6306 - val_accuracy: 0.6753\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6215 - accuracy: 0.6871 - val_loss: 0.6307 - val_accuracy: 0.6753\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6217 - accuracy: 0.6871 - val_loss: 0.6310 - val_accuracy: 0.6753\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6215 - accuracy: 0.6871 - val_loss: 0.6312 - val_accuracy: 0.6753\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6216 - accuracy: 0.6871 - val_loss: 0.6312 - val_accuracy: 0.6753\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6216 - accuracy: 0.6871 - val_loss: 0.6313 - val_accuracy: 0.6753\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.6217 - accuracy: 0.6871 - val_loss: 0.6313 - val_accuracy: 0.6753\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6219 - accuracy: 0.6871 - val_loss: 0.6310 - val_accuracy: 0.6753\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6213 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6213 - accuracy: 0.6871 - val_loss: 0.6302 - val_accuracy: 0.6753\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6216 - accuracy: 0.6871 - val_loss: 0.6300 - val_accuracy: 0.6753\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6216 - accuracy: 0.6871 - val_loss: 0.6285 - val_accuracy: 0.6753\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6204 - accuracy: 0.6871 - val_loss: 0.6242 - val_accuracy: 0.6753\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6251 - accuracy: 0.6871 - val_loss: 0.6215 - val_accuracy: 0.6753\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6234 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6221 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6222 - accuracy: 0.6871 - val_loss: 0.6303 - val_accuracy: 0.6753\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6216 - accuracy: 0.6871 - val_loss: 0.6303 - val_accuracy: 0.6753\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6194 - accuracy: 0.6871 - val_loss: 0.7882 - val_accuracy: 0.6753\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6954 - accuracy: 0.6871 - val_loss: 0.6310 - val_accuracy: 0.6753\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6242 - accuracy: 0.6871 - val_loss: 0.6330 - val_accuracy: 0.6753\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6264 - accuracy: 0.6871 - val_loss: 0.6325 - val_accuracy: 0.6753\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6244 - accuracy: 0.6871 - val_loss: 0.6305 - val_accuracy: 0.6753\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6220 - accuracy: 0.6871 - val_loss: 0.6315 - val_accuracy: 0.6753\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6220 - accuracy: 0.6871 - val_loss: 0.6330 - val_accuracy: 0.6753\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6225 - accuracy: 0.6871 - val_loss: 0.6316 - val_accuracy: 0.6753\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6217 - accuracy: 0.6871 - val_loss: 0.6307 - val_accuracy: 0.6753\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6214 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6217 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6218 - accuracy: 0.6871 - val_loss: 0.6303 - val_accuracy: 0.6753\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6217 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6216 - accuracy: 0.6871 - val_loss: 0.6306 - val_accuracy: 0.6753\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6213 - accuracy: 0.6871 - val_loss: 0.6312 - val_accuracy: 0.6753\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.6214 - accuracy: 0.6871 - val_loss: 0.6321 - val_accuracy: 0.6753\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6220 - accuracy: 0.6871 - val_loss: 0.6326 - val_accuracy: 0.6753\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6223 - accuracy: 0.6871 - val_loss: 0.6322 - val_accuracy: 0.6753\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6222 - accuracy: 0.6871 - val_loss: 0.6316 - val_accuracy: 0.6753\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6218 - accuracy: 0.6871 - val_loss: 0.6311 - val_accuracy: 0.6753\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6214 - accuracy: 0.6871 - val_loss: 0.6306 - val_accuracy: 0.6753\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6215 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6221 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6221 - accuracy: 0.6871 - val_loss: 0.6303 - val_accuracy: 0.6753\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6218 - accuracy: 0.6871 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6214 - accuracy: 0.6871 - val_loss: 0.6306 - val_accuracy: 0.6753\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6213 - accuracy: 0.6871 - val_loss: 0.6312 - val_accuracy: 0.6753\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6219 - accuracy: 0.6871 - val_loss: 0.6327 - val_accuracy: 0.6753\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6224 - accuracy: 0.6871 - val_loss: 0.6327 - val_accuracy: 0.6753\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6224 - accuracy: 0.6871 - val_loss: 0.6318 - val_accuracy: 0.6753\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6318 - accuracy: 0.6753\n",
            "Test Loss: 0.6318022608757019, Test Accuracy: 0.6753246784210205\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 4s 140ms/step - loss: 61.1583 - accuracy: 0.6903 - val_loss: 0.6909 - val_accuracy: 0.6623\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6835 - accuracy: 0.6903 - val_loss: 0.9733 - val_accuracy: 0.6623\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.7543 - accuracy: 0.6903 - val_loss: 0.6812 - val_accuracy: 0.6623\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6780 - accuracy: 0.6903 - val_loss: 0.6761 - val_accuracy: 0.6623\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6707 - accuracy: 0.6903 - val_loss: 0.6651 - val_accuracy: 0.6623\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6553 - accuracy: 0.6903 - val_loss: 0.6484 - val_accuracy: 0.6623\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6339 - accuracy: 0.6903 - val_loss: 0.6385 - val_accuracy: 0.6623\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6161 - accuracy: 0.6903 - val_loss: 0.6413 - val_accuracy: 0.6623\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6107 - accuracy: 0.6903 - val_loss: 0.6321 - val_accuracy: 0.6623\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.7131 - accuracy: 0.6903 - val_loss: 0.6320 - val_accuracy: 0.6623\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.6207 - accuracy: 0.6903 - val_loss: 0.6440 - val_accuracy: 0.6623\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6324 - accuracy: 0.6903 - val_loss: 0.6470 - val_accuracy: 0.6623\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6353 - accuracy: 0.6903 - val_loss: 0.6462 - val_accuracy: 0.6623\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6333 - accuracy: 0.6903 - val_loss: 0.6437 - val_accuracy: 0.6623\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6294 - accuracy: 0.6903 - val_loss: 0.6407 - val_accuracy: 0.6623\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6231 - accuracy: 0.6903 - val_loss: 0.6395 - val_accuracy: 0.6623\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6191 - accuracy: 0.6903 - val_loss: 0.6418 - val_accuracy: 0.6623\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6206 - accuracy: 0.6903 - val_loss: 0.6470 - val_accuracy: 0.6623\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6212 - accuracy: 0.6903 - val_loss: 0.6479 - val_accuracy: 0.6623\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6214 - accuracy: 0.6903 - val_loss: 0.6461 - val_accuracy: 0.6623\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6202 - accuracy: 0.6903 - val_loss: 0.6433 - val_accuracy: 0.6623\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6187 - accuracy: 0.6903 - val_loss: 0.6413 - val_accuracy: 0.6623\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6202 - accuracy: 0.6903 - val_loss: 0.6400 - val_accuracy: 0.6623\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6192 - accuracy: 0.6903 - val_loss: 0.6402 - val_accuracy: 0.6623\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6408 - val_accuracy: 0.6623\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6188 - accuracy: 0.6903 - val_loss: 0.6422 - val_accuracy: 0.6623\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6430 - val_accuracy: 0.6623\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6193 - accuracy: 0.6903 - val_loss: 0.6426 - val_accuracy: 0.6623\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6193 - accuracy: 0.6903 - val_loss: 0.6418 - val_accuracy: 0.6623\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6418 - val_accuracy: 0.6623\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6415 - val_accuracy: 0.6623\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6416 - val_accuracy: 0.6623\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6413 - val_accuracy: 0.6623\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6415 - val_accuracy: 0.6623\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6419 - val_accuracy: 0.6623\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6419 - val_accuracy: 0.6623\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6417 - val_accuracy: 0.6623\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6415 - val_accuracy: 0.6623\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6188 - accuracy: 0.6903 - val_loss: 0.6412 - val_accuracy: 0.6623\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6410 - val_accuracy: 0.6623\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.6188 - accuracy: 0.6903 - val_loss: 0.6405 - val_accuracy: 0.6623\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6405 - val_accuracy: 0.6623\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6409 - val_accuracy: 0.6623\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6187 - accuracy: 0.6903 - val_loss: 0.6409 - val_accuracy: 0.6623\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6182 - accuracy: 0.6903 - val_loss: 0.6402 - val_accuracy: 0.6623\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6164 - accuracy: 0.6903 - val_loss: 0.6604 - val_accuracy: 0.6883\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6467 - accuracy: 0.6613 - val_loss: 0.6426 - val_accuracy: 0.6623\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6180 - accuracy: 0.6903 - val_loss: 0.6434 - val_accuracy: 0.6623\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6125 - accuracy: 0.6903 - val_loss: 0.6372 - val_accuracy: 0.6623\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6342 - accuracy: 0.6903 - val_loss: 0.6395 - val_accuracy: 0.6623\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6219 - accuracy: 0.6903 - val_loss: 0.6417 - val_accuracy: 0.6623\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6276 - accuracy: 0.6903 - val_loss: 0.6428 - val_accuracy: 0.6623\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6285 - accuracy: 0.6903 - val_loss: 0.6413 - val_accuracy: 0.6623\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6248 - accuracy: 0.6903 - val_loss: 0.6396 - val_accuracy: 0.6623\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6213 - accuracy: 0.6903 - val_loss: 0.6404 - val_accuracy: 0.6623\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6202 - accuracy: 0.6903 - val_loss: 0.6433 - val_accuracy: 0.6623\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6194 - accuracy: 0.6903 - val_loss: 0.6432 - val_accuracy: 0.6623\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6192 - accuracy: 0.6903 - val_loss: 0.6417 - val_accuracy: 0.6623\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6196 - accuracy: 0.6903 - val_loss: 0.6398 - val_accuracy: 0.6623\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6195 - accuracy: 0.6903 - val_loss: 0.6396 - val_accuracy: 0.6623\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6200 - accuracy: 0.6903 - val_loss: 0.6395 - val_accuracy: 0.6623\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6198 - accuracy: 0.6903 - val_loss: 0.6399 - val_accuracy: 0.6623\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6195 - accuracy: 0.6903 - val_loss: 0.6413 - val_accuracy: 0.6623\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6191 - accuracy: 0.6903 - val_loss: 0.6426 - val_accuracy: 0.6623\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6424 - val_accuracy: 0.6623\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6415 - val_accuracy: 0.6623\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6188 - accuracy: 0.6903 - val_loss: 0.6410 - val_accuracy: 0.6623\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6188 - accuracy: 0.6903 - val_loss: 0.6405 - val_accuracy: 0.6623\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6191 - accuracy: 0.6903 - val_loss: 0.6401 - val_accuracy: 0.6623\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6192 - accuracy: 0.6903 - val_loss: 0.6402 - val_accuracy: 0.6623\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6414 - val_accuracy: 0.6623\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6194 - accuracy: 0.6903 - val_loss: 0.6414 - val_accuracy: 0.6623\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6187 - accuracy: 0.6903 - val_loss: 0.6411 - val_accuracy: 0.6623\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6405 - val_accuracy: 0.6623\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6408 - val_accuracy: 0.6623\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6410 - val_accuracy: 0.6623\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6191 - accuracy: 0.6903 - val_loss: 0.6417 - val_accuracy: 0.6623\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6418 - val_accuracy: 0.6623\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6188 - accuracy: 0.6903 - val_loss: 0.6414 - val_accuracy: 0.6623\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6191 - accuracy: 0.6903 - val_loss: 0.6406 - val_accuracy: 0.6623\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6401 - val_accuracy: 0.6623\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6192 - accuracy: 0.6903 - val_loss: 0.6403 - val_accuracy: 0.6623\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6188 - accuracy: 0.6903 - val_loss: 0.6413 - val_accuracy: 0.6623\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6192 - accuracy: 0.6903 - val_loss: 0.6425 - val_accuracy: 0.6623\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6191 - accuracy: 0.6903 - val_loss: 0.6425 - val_accuracy: 0.6623\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6191 - accuracy: 0.6903 - val_loss: 0.6418 - val_accuracy: 0.6623\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6419 - val_accuracy: 0.6623\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6191 - accuracy: 0.6903 - val_loss: 0.6424 - val_accuracy: 0.6623\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6417 - val_accuracy: 0.6623\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6190 - accuracy: 0.6903 - val_loss: 0.6412 - val_accuracy: 0.6623\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6188 - accuracy: 0.6903 - val_loss: 0.6400 - val_accuracy: 0.6623\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6196 - accuracy: 0.6903 - val_loss: 0.6401 - val_accuracy: 0.6623\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6194 - accuracy: 0.6903 - val_loss: 0.6412 - val_accuracy: 0.6623\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6189 - accuracy: 0.6903 - val_loss: 0.6414 - val_accuracy: 0.6623\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6188 - accuracy: 0.6903 - val_loss: 0.6413 - val_accuracy: 0.6623\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6187 - accuracy: 0.6903 - val_loss: 0.6407 - val_accuracy: 0.6623\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6183 - accuracy: 0.6903 - val_loss: 0.6427 - val_accuracy: 0.6623\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6183 - accuracy: 0.6903 - val_loss: 0.6375 - val_accuracy: 0.6623\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6183 - accuracy: 0.6903 - val_loss: 0.6273 - val_accuracy: 0.6623\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6122 - accuracy: 0.6903 - val_loss: 0.6368 - val_accuracy: 0.6623\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6368 - accuracy: 0.6623\n",
            "Test Loss: 0.6367805004119873, Test Accuracy: 0.6623376607894897\n",
            "\n",
            "Average Accuracy Across All Folds: 0.7387279391288757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline + 증강 O : 0.7418238639831543"
      ],
      "metadata": {
        "id": "zuQMFbfGNnRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이거다!!!\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test))\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5TMS0hgUDeD",
        "outputId": "b9056551-2d97-4bbd-98ae-18f10e1d1ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 18s 214ms/step - loss: 16.6866 - accuracy: 0.7123 - val_loss: 0.6780 - val_accuracy: 0.6933\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6533 - accuracy: 0.7123 - val_loss: 1.0142 - val_accuracy: 0.6933\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6667 - accuracy: 0.7123 - val_loss: 0.6255 - val_accuracy: 0.6933\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6077 - accuracy: 0.7123 - val_loss: 0.6173 - val_accuracy: 0.6933\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6020 - accuracy: 0.7123 - val_loss: 0.6188 - val_accuracy: 0.6933\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6002 - accuracy: 0.7123 - val_loss: 0.6164 - val_accuracy: 0.6933\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6020 - accuracy: 0.7123 - val_loss: 0.6169 - val_accuracy: 0.6933\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6004 - accuracy: 0.7123 - val_loss: 0.6171 - val_accuracy: 0.6933\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6006 - accuracy: 0.7123 - val_loss: 0.6167 - val_accuracy: 0.6933\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6008 - accuracy: 0.7123 - val_loss: 0.6188 - val_accuracy: 0.6933\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6000 - accuracy: 0.7123 - val_loss: 0.6163 - val_accuracy: 0.6933\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.5997 - accuracy: 0.7123 - val_loss: 0.6147 - val_accuracy: 0.6933\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6007 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6008 - accuracy: 0.7123 - val_loss: 0.6177 - val_accuracy: 0.6933\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6004 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6008 - accuracy: 0.7123 - val_loss: 0.6176 - val_accuracy: 0.6933\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6004 - accuracy: 0.7123 - val_loss: 0.6177 - val_accuracy: 0.6933\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6006 - accuracy: 0.7123 - val_loss: 0.6172 - val_accuracy: 0.6933\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6002 - accuracy: 0.7123 - val_loss: 0.6170 - val_accuracy: 0.6933\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6005 - accuracy: 0.7123 - val_loss: 0.6169 - val_accuracy: 0.6933\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5997 - accuracy: 0.7123 - val_loss: 0.6233 - val_accuracy: 0.6933\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5950 - accuracy: 0.7123 - val_loss: 0.6184 - val_accuracy: 0.6933\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6038 - accuracy: 0.7123 - val_loss: 0.6164 - val_accuracy: 0.6933\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5993 - accuracy: 0.7123 - val_loss: 0.6137 - val_accuracy: 0.6933\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6013 - accuracy: 0.7123 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6017 - accuracy: 0.7123 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6001 - accuracy: 0.7123 - val_loss: 0.6181 - val_accuracy: 0.6933\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5889 - accuracy: 0.7123 - val_loss: 0.5630 - val_accuracy: 0.6933\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6078 - accuracy: 0.7123 - val_loss: 0.6103 - val_accuracy: 0.6933\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6019 - accuracy: 0.7123 - val_loss: 0.6164 - val_accuracy: 0.6933\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.5988 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6032 - accuracy: 0.7123 - val_loss: 0.6167 - val_accuracy: 0.6933\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6007 - accuracy: 0.7123 - val_loss: 0.6180 - val_accuracy: 0.6933\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6018 - accuracy: 0.7123 - val_loss: 0.6161 - val_accuracy: 0.6933\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6006 - accuracy: 0.7123 - val_loss: 0.6174 - val_accuracy: 0.6933\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5978 - accuracy: 0.7123 - val_loss: 0.6105 - val_accuracy: 0.6933\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5951 - accuracy: 0.7123 - val_loss: 0.6148 - val_accuracy: 0.6933\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6060 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6018 - accuracy: 0.7123 - val_loss: 0.6222 - val_accuracy: 0.6933\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6018 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6003 - accuracy: 0.7123 - val_loss: 0.6173 - val_accuracy: 0.6933\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6002 - accuracy: 0.7123 - val_loss: 0.6187 - val_accuracy: 0.6933\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6007 - accuracy: 0.7123 - val_loss: 0.6170 - val_accuracy: 0.6933\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6009 - accuracy: 0.7123 - val_loss: 0.6171 - val_accuracy: 0.6933\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6006 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6004 - accuracy: 0.7123 - val_loss: 0.6178 - val_accuracy: 0.6933\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6006 - accuracy: 0.7123 - val_loss: 0.6167 - val_accuracy: 0.6933\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6000 - accuracy: 0.7123 - val_loss: 0.6155 - val_accuracy: 0.6933\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6149 - accuracy: 0.7123 - val_loss: 0.6219 - val_accuracy: 0.6933\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6079 - accuracy: 0.7123 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6016 - accuracy: 0.7123 - val_loss: 0.6202 - val_accuracy: 0.6933\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6016 - accuracy: 0.7123 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6003 - accuracy: 0.7123 - val_loss: 0.6179 - val_accuracy: 0.6933\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6007 - accuracy: 0.7123 - val_loss: 0.6179 - val_accuracy: 0.6933\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6008 - accuracy: 0.7123 - val_loss: 0.6169 - val_accuracy: 0.6933\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6005 - accuracy: 0.7123 - val_loss: 0.6171 - val_accuracy: 0.6933\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6002 - accuracy: 0.7123 - val_loss: 0.6176 - val_accuracy: 0.6933\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6010 - accuracy: 0.7123 - val_loss: 0.6188 - val_accuracy: 0.6933\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6003 - accuracy: 0.7123 - val_loss: 0.6172 - val_accuracy: 0.6933\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6004 - accuracy: 0.7123 - val_loss: 0.6171 - val_accuracy: 0.6933\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6005 - accuracy: 0.7123 - val_loss: 0.6188 - val_accuracy: 0.6933\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6003 - accuracy: 0.7123 - val_loss: 0.6174 - val_accuracy: 0.6933\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6012 - accuracy: 0.7123 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6017 - accuracy: 0.7123 - val_loss: 0.6202 - val_accuracy: 0.6933\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6017 - accuracy: 0.7123 - val_loss: 0.6169 - val_accuracy: 0.6933\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6001 - accuracy: 0.7123 - val_loss: 0.6180 - val_accuracy: 0.6933\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6015 - accuracy: 0.7123 - val_loss: 0.6184 - val_accuracy: 0.6933\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6006 - accuracy: 0.7123 - val_loss: 0.6164 - val_accuracy: 0.6933\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6022 - accuracy: 0.7123 - val_loss: 0.6174 - val_accuracy: 0.6933\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6014 - accuracy: 0.7123 - val_loss: 0.6164 - val_accuracy: 0.6933\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6011 - accuracy: 0.7123 - val_loss: 0.6177 - val_accuracy: 0.6933\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6002 - accuracy: 0.7123 - val_loss: 0.6168 - val_accuracy: 0.6933\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6003 - accuracy: 0.7123 - val_loss: 0.6168 - val_accuracy: 0.6933\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6008 - accuracy: 0.7123 - val_loss: 0.6187 - val_accuracy: 0.6933\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6002 - accuracy: 0.7123 - val_loss: 0.6173 - val_accuracy: 0.6933\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6012 - accuracy: 0.7123 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6005 - accuracy: 0.7123 - val_loss: 0.6177 - val_accuracy: 0.6933\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6002 - accuracy: 0.7123 - val_loss: 0.6176 - val_accuracy: 0.6933\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6003 - accuracy: 0.7123 - val_loss: 0.6172 - val_accuracy: 0.6933\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6001 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6005 - accuracy: 0.7123 - val_loss: 0.6173 - val_accuracy: 0.6933\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6006 - accuracy: 0.7123 - val_loss: 0.6188 - val_accuracy: 0.6933\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6002 - accuracy: 0.7123 - val_loss: 0.6170 - val_accuracy: 0.6933\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6004 - accuracy: 0.7123 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6006 - accuracy: 0.7123 - val_loss: 0.6168 - val_accuracy: 0.6933\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6004 - accuracy: 0.7123 - val_loss: 0.6183 - val_accuracy: 0.6933\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6008 - accuracy: 0.7123 - val_loss: 0.6181 - val_accuracy: 0.6933\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6005 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6006 - accuracy: 0.7123 - val_loss: 0.6173 - val_accuracy: 0.6933\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6010 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6001 - accuracy: 0.7123 - val_loss: 0.6190 - val_accuracy: 0.6933\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6007 - accuracy: 0.7123 - val_loss: 0.6179 - val_accuracy: 0.6933\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6003 - accuracy: 0.7123 - val_loss: 0.6169 - val_accuracy: 0.6933\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6019 - accuracy: 0.7123 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6001 - accuracy: 0.7123 - val_loss: 0.6176 - val_accuracy: 0.6933\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6008 - accuracy: 0.7123 - val_loss: 0.6182 - val_accuracy: 0.6933\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6007 - accuracy: 0.7123 - val_loss: 0.6170 - val_accuracy: 0.6933\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6005 - accuracy: 0.7123 - val_loss: 0.6174 - val_accuracy: 0.6933\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6003 - accuracy: 0.7123 - val_loss: 0.6166 - val_accuracy: 0.6933\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.6003 - accuracy: 0.7123 - val_loss: 0.6174 - val_accuracy: 0.6933\n",
            "10/10 [==============================] - 1s 34ms/step - loss: 0.6174 - accuracy: 0.6933\n",
            "Test Loss: 0.6174343824386597, Test Accuracy: 0.6933333277702332\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 96ms/step - loss: 24.7744 - accuracy: 0.7089 - val_loss: 0.6726 - val_accuracy: 0.7067\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6285 - accuracy: 0.7089 - val_loss: 0.6169 - val_accuracy: 0.7067\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6175 - accuracy: 0.7089 - val_loss: 0.6211 - val_accuracy: 0.7067\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6053 - accuracy: 0.7089 - val_loss: 0.6001 - val_accuracy: 0.7067\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5882 - accuracy: 0.7089 - val_loss: 0.6119 - val_accuracy: 0.7067\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6019 - accuracy: 0.7089 - val_loss: 0.5850 - val_accuracy: 0.7067\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5970 - accuracy: 0.7089 - val_loss: 0.6050 - val_accuracy: 0.7067\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5930 - accuracy: 0.7089 - val_loss: 0.5881 - val_accuracy: 0.7067\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6062 - accuracy: 0.7089 - val_loss: 0.5964 - val_accuracy: 0.7067\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5818 - accuracy: 0.7089 - val_loss: 0.5980 - val_accuracy: 0.7067\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5935 - accuracy: 0.7089 - val_loss: 0.6266 - val_accuracy: 0.7067\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5937 - accuracy: 0.7089 - val_loss: 0.5483 - val_accuracy: 0.7067\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5157 - accuracy: 0.7548 - val_loss: 0.4977 - val_accuracy: 0.7967\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.4928 - accuracy: 0.7840 - val_loss: 0.4838 - val_accuracy: 0.7833\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.4538 - accuracy: 0.8215 - val_loss: 0.7010 - val_accuracy: 0.7767\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5979 - accuracy: 0.7440 - val_loss: 0.5773 - val_accuracy: 0.7067\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5465 - accuracy: 0.7148 - val_loss: 0.5300 - val_accuracy: 0.7133\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5042 - accuracy: 0.7715 - val_loss: 0.5992 - val_accuracy: 0.7200\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.4502 - accuracy: 0.8040 - val_loss: 0.8592 - val_accuracy: 0.6233\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4403 - accuracy: 0.8007 - val_loss: 0.4235 - val_accuracy: 0.7933\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3646 - accuracy: 0.8374 - val_loss: 0.4552 - val_accuracy: 0.8133\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3187 - accuracy: 0.8582 - val_loss: 0.3422 - val_accuracy: 0.8633\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.2674 - accuracy: 0.8807 - val_loss: 0.3043 - val_accuracy: 0.8767\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.2692 - accuracy: 0.8899 - val_loss: 2.2506 - val_accuracy: 0.8167\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6792 - accuracy: 0.6889 - val_loss: 0.5748 - val_accuracy: 0.7067\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5515 - accuracy: 0.7089 - val_loss: 0.5305 - val_accuracy: 0.7200\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5100 - accuracy: 0.7164 - val_loss: 0.5096 - val_accuracy: 0.7267\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.5275 - accuracy: 0.7223 - val_loss: 0.6623 - val_accuracy: 0.7233\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5373 - accuracy: 0.7223 - val_loss: 0.4889 - val_accuracy: 0.7467\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4627 - accuracy: 0.7273 - val_loss: 0.4704 - val_accuracy: 0.7633\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4456 - accuracy: 0.7957 - val_loss: 0.4282 - val_accuracy: 0.8000\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3970 - accuracy: 0.8123 - val_loss: 0.3984 - val_accuracy: 0.8300\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3519 - accuracy: 0.8424 - val_loss: 0.4110 - val_accuracy: 0.8667\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3952 - accuracy: 0.8490 - val_loss: 0.4878 - val_accuracy: 0.7800\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4932 - accuracy: 0.8048 - val_loss: 0.4539 - val_accuracy: 0.8133\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4576 - accuracy: 0.7848 - val_loss: 0.4489 - val_accuracy: 0.8233\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3937 - accuracy: 0.8357 - val_loss: 0.4061 - val_accuracy: 0.8433\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4783 - accuracy: 0.7940 - val_loss: 0.4668 - val_accuracy: 0.8100\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3819 - accuracy: 0.8382 - val_loss: 1.7097 - val_accuracy: 0.4533\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6848 - accuracy: 0.7698 - val_loss: 0.5060 - val_accuracy: 0.8133\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4732 - accuracy: 0.8215 - val_loss: 0.4342 - val_accuracy: 0.8367\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3796 - accuracy: 0.8357 - val_loss: 0.4346 - val_accuracy: 0.8133\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3500 - accuracy: 0.8549 - val_loss: 0.3667 - val_accuracy: 0.8500\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3161 - accuracy: 0.8791 - val_loss: 0.3928 - val_accuracy: 0.8500\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3077 - accuracy: 0.8724 - val_loss: 0.3214 - val_accuracy: 0.8600\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2729 - accuracy: 0.8916 - val_loss: 0.3973 - val_accuracy: 0.8333\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.3051 - accuracy: 0.8782 - val_loss: 0.3386 - val_accuracy: 0.8467\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3146 - accuracy: 0.8657 - val_loss: 0.3311 - val_accuracy: 0.8533\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2852 - accuracy: 0.8832 - val_loss: 0.2761 - val_accuracy: 0.8933\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2254 - accuracy: 0.9166 - val_loss: 0.2535 - val_accuracy: 0.8967\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2152 - accuracy: 0.9083 - val_loss: 0.5479 - val_accuracy: 0.8200\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2341 - accuracy: 0.9108 - val_loss: 0.3188 - val_accuracy: 0.8733\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.2807 - accuracy: 0.8841 - val_loss: 0.3543 - val_accuracy: 0.8533\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2308 - accuracy: 0.9074 - val_loss: 0.2688 - val_accuracy: 0.8900\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1797 - accuracy: 0.9324 - val_loss: 0.2515 - val_accuracy: 0.8933\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1589 - accuracy: 0.9425 - val_loss: 0.2588 - val_accuracy: 0.8700\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.1775 - accuracy: 0.9316 - val_loss: 0.2895 - val_accuracy: 0.8667\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.2475 - accuracy: 0.8999 - val_loss: 0.2541 - val_accuracy: 0.8867\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.2070 - accuracy: 0.9274 - val_loss: 0.2552 - val_accuracy: 0.9000\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1582 - accuracy: 0.9399 - val_loss: 0.2255 - val_accuracy: 0.9033\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.1178 - accuracy: 0.9550 - val_loss: 0.2735 - val_accuracy: 0.9033\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.1158 - accuracy: 0.9550 - val_loss: 0.2690 - val_accuracy: 0.9067\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.1047 - accuracy: 0.9725 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.1837 - accuracy: 0.9241 - val_loss: 0.2280 - val_accuracy: 0.8867\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.1998 - accuracy: 0.9308 - val_loss: 0.4675 - val_accuracy: 0.7833\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.3211 - accuracy: 0.8699 - val_loss: 0.5591 - val_accuracy: 0.7833\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3420 - accuracy: 0.8532 - val_loss: 0.3361 - val_accuracy: 0.8733\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.2890 - accuracy: 0.8774 - val_loss: 0.3482 - val_accuracy: 0.8433\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3003 - accuracy: 0.8791 - val_loss: 0.3225 - val_accuracy: 0.8900\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2580 - accuracy: 0.9033 - val_loss: 0.2853 - val_accuracy: 0.8967\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1705 - accuracy: 0.9391 - val_loss: 0.2777 - val_accuracy: 0.9033\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1685 - accuracy: 0.9349 - val_loss: 0.2978 - val_accuracy: 0.8800\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1675 - accuracy: 0.9366 - val_loss: 0.3446 - val_accuracy: 0.8867\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0963 - accuracy: 0.9675 - val_loss: 0.2170 - val_accuracy: 0.9267\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2223 - accuracy: 0.9299 - val_loss: 0.4833 - val_accuracy: 0.8233\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2898 - accuracy: 0.8774 - val_loss: 0.4028 - val_accuracy: 0.8233\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2159 - accuracy: 0.9158 - val_loss: 0.3366 - val_accuracy: 0.8400\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1724 - accuracy: 0.9258 - val_loss: 0.2802 - val_accuracy: 0.9033\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1204 - accuracy: 0.9575 - val_loss: 0.2772 - val_accuracy: 0.8933\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0973 - accuracy: 0.9691 - val_loss: 0.4805 - val_accuracy: 0.8867\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.1310 - accuracy: 0.9516 - val_loss: 0.3899 - val_accuracy: 0.8533\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.1345 - accuracy: 0.9475 - val_loss: 0.2740 - val_accuracy: 0.9167\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0909 - accuracy: 0.9700 - val_loss: 0.3811 - val_accuracy: 0.8433\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.1113 - accuracy: 0.9541 - val_loss: 0.2721 - val_accuracy: 0.9133\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0810 - accuracy: 0.9741 - val_loss: 0.2630 - val_accuracy: 0.9000\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 0.2193 - val_accuracy: 0.9267\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4349 - accuracy: 0.9741 - val_loss: 0.8151 - val_accuracy: 0.7833\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5907 - accuracy: 0.7248 - val_loss: 0.5150 - val_accuracy: 0.7167\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4323 - accuracy: 0.7848 - val_loss: 0.4677 - val_accuracy: 0.7733\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3575 - accuracy: 0.8374 - val_loss: 0.4112 - val_accuracy: 0.8300\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3152 - accuracy: 0.8599 - val_loss: 0.3706 - val_accuracy: 0.8167\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4100 - accuracy: 0.7982 - val_loss: 0.4893 - val_accuracy: 0.7267\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4685 - accuracy: 0.7573 - val_loss: 0.5086 - val_accuracy: 0.7367\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.3969 - accuracy: 0.7965 - val_loss: 0.3971 - val_accuracy: 0.7967\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3119 - accuracy: 0.8649 - val_loss: 0.3318 - val_accuracy: 0.8767\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3218 - accuracy: 0.8641 - val_loss: 0.4311 - val_accuracy: 0.8367\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.2847 - accuracy: 0.8791 - val_loss: 0.3267 - val_accuracy: 0.8667\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.2646 - accuracy: 0.8957 - val_loss: 0.3982 - val_accuracy: 0.8467\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.2595 - accuracy: 0.8832 - val_loss: 0.3403 - val_accuracy: 0.8567\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.2035 - accuracy: 0.9174 - val_loss: 0.3649 - val_accuracy: 0.8733\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3649 - accuracy: 0.8733\n",
            "Test Loss: 0.3648662567138672, Test Accuracy: 0.8733333349227905\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 96ms/step - loss: 5.7094 - accuracy: 0.6622 - val_loss: 0.6747 - val_accuracy: 0.6800\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6556 - accuracy: 0.7156 - val_loss: 0.6198 - val_accuracy: 0.6800\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6143 - accuracy: 0.7156 - val_loss: 0.6290 - val_accuracy: 0.6800\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6021 - accuracy: 0.7156 - val_loss: 0.6337 - val_accuracy: 0.6800\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5988 - accuracy: 0.7156 - val_loss: 0.6301 - val_accuracy: 0.6800\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5977 - accuracy: 0.7156 - val_loss: 0.6334 - val_accuracy: 0.6800\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5969 - accuracy: 0.7156 - val_loss: 0.6258 - val_accuracy: 0.6800\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6244 - accuracy: 0.7156 - val_loss: 0.6307 - val_accuracy: 0.6800\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5998 - accuracy: 0.7156 - val_loss: 0.6294 - val_accuracy: 0.6800\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5961 - accuracy: 0.7156 - val_loss: 0.6253 - val_accuracy: 0.6800\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5882 - accuracy: 0.7156 - val_loss: 0.6329 - val_accuracy: 0.6800\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5826 - accuracy: 0.7156 - val_loss: 0.6354 - val_accuracy: 0.6800\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6038 - accuracy: 0.7156 - val_loss: 0.6404 - val_accuracy: 0.6800\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5990 - accuracy: 0.7156 - val_loss: 0.6297 - val_accuracy: 0.6800\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5962 - accuracy: 0.7156 - val_loss: 0.6217 - val_accuracy: 0.6800\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6013 - accuracy: 0.7156 - val_loss: 0.6277 - val_accuracy: 0.6800\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5988 - accuracy: 0.7156 - val_loss: 0.6351 - val_accuracy: 0.6800\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5892 - accuracy: 0.7156 - val_loss: 0.6239 - val_accuracy: 0.6800\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6005 - accuracy: 0.7156 - val_loss: 0.6269 - val_accuracy: 0.6800\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5987 - accuracy: 0.7156 - val_loss: 0.6330 - val_accuracy: 0.6800\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5978 - accuracy: 0.7156 - val_loss: 0.6315 - val_accuracy: 0.6800\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.6276 - val_accuracy: 0.6800\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5975 - accuracy: 0.7156 - val_loss: 0.6299 - val_accuracy: 0.6800\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5980 - accuracy: 0.7156 - val_loss: 0.6326 - val_accuracy: 0.6800\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6264 - val_accuracy: 0.6800\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6045 - accuracy: 0.7156 - val_loss: 0.6294 - val_accuracy: 0.6800\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6054 - accuracy: 0.7156 - val_loss: 0.6273 - val_accuracy: 0.6800\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5974 - accuracy: 0.7156 - val_loss: 0.6361 - val_accuracy: 0.6800\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5984 - accuracy: 0.7156 - val_loss: 0.6289 - val_accuracy: 0.6800\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6295 - val_accuracy: 0.6800\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5980 - accuracy: 0.7156 - val_loss: 0.6319 - val_accuracy: 0.6800\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5975 - accuracy: 0.7156 - val_loss: 0.6278 - val_accuracy: 0.6800\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5977 - accuracy: 0.7156 - val_loss: 0.6289 - val_accuracy: 0.6800\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.6335 - val_accuracy: 0.6800\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5993 - accuracy: 0.7156 - val_loss: 0.6308 - val_accuracy: 0.6800\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5983 - accuracy: 0.7156 - val_loss: 0.6274 - val_accuracy: 0.6800\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5974 - accuracy: 0.7156 - val_loss: 0.6311 - val_accuracy: 0.6800\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5977 - accuracy: 0.7156 - val_loss: 0.6323 - val_accuracy: 0.6800\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.8224 - accuracy: 0.7156 - val_loss: 0.6303 - val_accuracy: 0.6800\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6337 - accuracy: 0.7156 - val_loss: 0.6466 - val_accuracy: 0.6800\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6191 - accuracy: 0.7156 - val_loss: 0.6268 - val_accuracy: 0.6800\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5995 - accuracy: 0.7156 - val_loss: 0.6342 - val_accuracy: 0.6800\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.6274 - val_accuracy: 0.6800\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.6314 - val_accuracy: 0.6800\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.6294 - val_accuracy: 0.6800\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6298 - val_accuracy: 0.6800\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.6303 - val_accuracy: 0.6800\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5978 - accuracy: 0.7156 - val_loss: 0.6279 - val_accuracy: 0.6800\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5974 - accuracy: 0.7156 - val_loss: 0.6297 - val_accuracy: 0.6800\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.6288 - val_accuracy: 0.6800\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5954 - accuracy: 0.7156 - val_loss: 0.6284 - val_accuracy: 0.6800\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5974 - accuracy: 0.7156 - val_loss: 0.6280 - val_accuracy: 0.6800\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5976 - accuracy: 0.7156 - val_loss: 0.6300 - val_accuracy: 0.6800\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5980 - accuracy: 0.7156 - val_loss: 0.6283 - val_accuracy: 0.6800\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.6295 - val_accuracy: 0.6800\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.6300 - val_accuracy: 0.6800\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6298 - val_accuracy: 0.6800\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.6308 - val_accuracy: 0.6800\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.6295 - val_accuracy: 0.6800\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5968 - accuracy: 0.7156 - val_loss: 0.6277 - val_accuracy: 0.6800\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5956 - accuracy: 0.7156 - val_loss: 0.6268 - val_accuracy: 0.6800\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5992 - accuracy: 0.7156 - val_loss: 0.6271 - val_accuracy: 0.6800\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5985 - accuracy: 0.7156 - val_loss: 0.6280 - val_accuracy: 0.6800\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5976 - accuracy: 0.7156 - val_loss: 0.6291 - val_accuracy: 0.6800\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.6302 - val_accuracy: 0.6800\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.6294 - val_accuracy: 0.6800\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5974 - accuracy: 0.7156 - val_loss: 0.6309 - val_accuracy: 0.6800\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6295 - val_accuracy: 0.6800\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6303 - val_accuracy: 0.6800\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.6305 - val_accuracy: 0.6800\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5974 - accuracy: 0.7156 - val_loss: 0.6288 - val_accuracy: 0.6800\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6293 - val_accuracy: 0.6800\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.6307 - val_accuracy: 0.6800\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6306 - val_accuracy: 0.6800\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6289 - val_accuracy: 0.6800\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.6293 - val_accuracy: 0.6800\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5976 - accuracy: 0.7156 - val_loss: 0.6286 - val_accuracy: 0.6800\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6296 - val_accuracy: 0.6800\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5975 - accuracy: 0.7156 - val_loss: 0.6305 - val_accuracy: 0.6800\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6297 - val_accuracy: 0.6800\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.6300 - val_accuracy: 0.6800\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.6306 - val_accuracy: 0.6800\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6305 - val_accuracy: 0.6800\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.6301 - val_accuracy: 0.6800\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.6284 - val_accuracy: 0.6800\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5946 - accuracy: 0.7156 - val_loss: 1.7973 - val_accuracy: 0.3733\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.7337 - accuracy: 0.6664 - val_loss: 0.6283 - val_accuracy: 0.6800\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6013 - accuracy: 0.7156 - val_loss: 0.6276 - val_accuracy: 0.6800\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5996 - accuracy: 0.7156 - val_loss: 0.6275 - val_accuracy: 0.6800\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5994 - accuracy: 0.7156 - val_loss: 0.6275 - val_accuracy: 0.6800\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5983 - accuracy: 0.7156 - val_loss: 0.6271 - val_accuracy: 0.6800\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5987 - accuracy: 0.7156 - val_loss: 0.6287 - val_accuracy: 0.6800\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5977 - accuracy: 0.7156 - val_loss: 0.6287 - val_accuracy: 0.6800\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.6296 - val_accuracy: 0.6800\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.6305 - val_accuracy: 0.6800\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5962 - accuracy: 0.7156 - val_loss: 0.6270 - val_accuracy: 0.6800\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.5946 - accuracy: 0.7156 - val_loss: 0.6172 - val_accuracy: 0.6800\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5942 - accuracy: 0.7156 - val_loss: 0.6369 - val_accuracy: 0.6800\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5960 - accuracy: 0.7156 - val_loss: 0.6207 - val_accuracy: 0.6800\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5969 - accuracy: 0.7156 - val_loss: 0.6316 - val_accuracy: 0.6800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6316 - accuracy: 0.6800\n",
            "Test Loss: 0.631621241569519, Test Accuracy: 0.6800000071525574\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 93ms/step - loss: 18.9979 - accuracy: 0.7039 - val_loss: 0.6714 - val_accuracy: 0.7267\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6640 - accuracy: 0.7039 - val_loss: 0.6106 - val_accuracy: 0.7267\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.6188 - accuracy: 0.7039 - val_loss: 0.5995 - val_accuracy: 0.7267\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6057 - accuracy: 0.7039 - val_loss: 0.5823 - val_accuracy: 0.7267\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6008 - accuracy: 0.7039 - val_loss: 0.7325 - val_accuracy: 0.7267\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6083 - accuracy: 0.7039 - val_loss: 0.5905 - val_accuracy: 0.7267\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5931 - accuracy: 0.7039 - val_loss: 0.6280 - val_accuracy: 0.7267\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6244 - accuracy: 0.7039 - val_loss: 0.5988 - val_accuracy: 0.7267\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6087 - accuracy: 0.7039 - val_loss: 0.5866 - val_accuracy: 0.7267\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6108 - accuracy: 0.7039 - val_loss: 0.5869 - val_accuracy: 0.7267\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6086 - accuracy: 0.7039 - val_loss: 0.5909 - val_accuracy: 0.7267\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6076 - accuracy: 0.7039 - val_loss: 0.5877 - val_accuracy: 0.7267\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6129 - accuracy: 0.7039 - val_loss: 0.5866 - val_accuracy: 0.7267\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6081 - accuracy: 0.7039 - val_loss: 0.5902 - val_accuracy: 0.7267\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6082 - accuracy: 0.7039 - val_loss: 0.5894 - val_accuracy: 0.7267\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6083 - accuracy: 0.7039 - val_loss: 0.5866 - val_accuracy: 0.7267\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6078 - accuracy: 0.7039 - val_loss: 0.5878 - val_accuracy: 0.7267\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6076 - accuracy: 0.7039 - val_loss: 0.5881 - val_accuracy: 0.7267\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6076 - accuracy: 0.7039 - val_loss: 0.5868 - val_accuracy: 0.7267\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.5984 - accuracy: 0.7039 - val_loss: 0.5923 - val_accuracy: 0.7267\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6114 - accuracy: 0.7039 - val_loss: 0.5847 - val_accuracy: 0.7267\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5983 - accuracy: 0.7039 - val_loss: 0.5532 - val_accuracy: 0.7267\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5843 - accuracy: 0.7039 - val_loss: 0.6122 - val_accuracy: 0.7267\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6195 - accuracy: 0.7039 - val_loss: 0.5952 - val_accuracy: 0.7267\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6091 - accuracy: 0.7039 - val_loss: 0.5867 - val_accuracy: 0.7267\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6088 - accuracy: 0.7039 - val_loss: 0.5873 - val_accuracy: 0.7267\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6088 - accuracy: 0.7039 - val_loss: 0.5868 - val_accuracy: 0.7267\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6080 - accuracy: 0.7039 - val_loss: 0.5908 - val_accuracy: 0.7267\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6091 - accuracy: 0.7039 - val_loss: 0.5877 - val_accuracy: 0.7267\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5881 - val_accuracy: 0.7267\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6078 - accuracy: 0.7039 - val_loss: 0.5891 - val_accuracy: 0.7267\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5878 - val_accuracy: 0.7267\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5878 - val_accuracy: 0.7267\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6074 - accuracy: 0.7039 - val_loss: 0.5868 - val_accuracy: 0.7267\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6084 - accuracy: 0.7039 - val_loss: 0.5869 - val_accuracy: 0.7267\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5882 - val_accuracy: 0.7267\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6076 - accuracy: 0.7039 - val_loss: 0.5878 - val_accuracy: 0.7267\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5880 - val_accuracy: 0.7267\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5868 - val_accuracy: 0.7267\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6079 - accuracy: 0.7039 - val_loss: 0.5883 - val_accuracy: 0.7267\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5889 - val_accuracy: 0.7267\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6076 - accuracy: 0.7039 - val_loss: 0.5875 - val_accuracy: 0.7267\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.6071 - accuracy: 0.7039 - val_loss: 0.5874 - val_accuracy: 0.7267\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.6075 - accuracy: 0.7039 - val_loss: 0.5842 - val_accuracy: 0.7267\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.5935 - accuracy: 0.7039 - val_loss: 3.4192 - val_accuracy: 0.7267\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.9387 - accuracy: 0.7039 - val_loss: 0.6196 - val_accuracy: 0.7267\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6377 - accuracy: 0.7039 - val_loss: 0.6122 - val_accuracy: 0.7267\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6165 - accuracy: 0.7039 - val_loss: 0.9468 - val_accuracy: 0.2733\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6428 - accuracy: 0.6589 - val_loss: 0.5914 - val_accuracy: 0.7267\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6087 - accuracy: 0.7039 - val_loss: 0.5895 - val_accuracy: 0.7267\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6095 - accuracy: 0.7039 - val_loss: 0.5866 - val_accuracy: 0.7267\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6083 - accuracy: 0.7039 - val_loss: 0.5855 - val_accuracy: 0.7267\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6078 - accuracy: 0.7039 - val_loss: 0.5949 - val_accuracy: 0.7267\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6131 - accuracy: 0.7039 - val_loss: 0.5928 - val_accuracy: 0.7267\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6078 - accuracy: 0.7039 - val_loss: 0.5857 - val_accuracy: 0.7267\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6055 - accuracy: 0.7039 - val_loss: 0.5787 - val_accuracy: 0.7267\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6162 - accuracy: 0.7039 - val_loss: 0.5961 - val_accuracy: 0.7267\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6118 - accuracy: 0.7039 - val_loss: 0.5879 - val_accuracy: 0.7267\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6071 - accuracy: 0.7039 - val_loss: 0.5871 - val_accuracy: 0.7267\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6061 - accuracy: 0.7039 - val_loss: 0.6021 - val_accuracy: 0.7267\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6226 - accuracy: 0.7039 - val_loss: 0.5939 - val_accuracy: 0.7267\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6089 - accuracy: 0.7039 - val_loss: 0.5886 - val_accuracy: 0.7267\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6072 - accuracy: 0.7039 - val_loss: 0.5869 - val_accuracy: 0.7267\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5864 - val_accuracy: 0.7267\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6045 - accuracy: 0.7039 - val_loss: 0.5816 - val_accuracy: 0.7267\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.7180 - accuracy: 0.7039 - val_loss: 0.5973 - val_accuracy: 0.7267\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6125 - accuracy: 0.7039 - val_loss: 0.5949 - val_accuracy: 0.7267\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6086 - accuracy: 0.7039 - val_loss: 0.5868 - val_accuracy: 0.7267\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6081 - accuracy: 0.7039 - val_loss: 0.5886 - val_accuracy: 0.7267\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6069 - accuracy: 0.7039 - val_loss: 0.5898 - val_accuracy: 0.7267\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6063 - accuracy: 0.7039 - val_loss: 0.5784 - val_accuracy: 0.7267\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6053 - accuracy: 0.7039 - val_loss: 0.5958 - val_accuracy: 0.7267\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6109 - accuracy: 0.7039 - val_loss: 0.5927 - val_accuracy: 0.7267\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6084 - accuracy: 0.7039 - val_loss: 0.5888 - val_accuracy: 0.7267\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6070 - accuracy: 0.7039 - val_loss: 0.5826 - val_accuracy: 0.7267\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6076 - accuracy: 0.7039 - val_loss: 0.5872 - val_accuracy: 0.7267\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6114 - accuracy: 0.7039 - val_loss: 0.5882 - val_accuracy: 0.7267\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6079 - accuracy: 0.7039 - val_loss: 0.5896 - val_accuracy: 0.7267\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6078 - accuracy: 0.7039 - val_loss: 0.5887 - val_accuracy: 0.7267\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6074 - accuracy: 0.7039 - val_loss: 0.5874 - val_accuracy: 0.7267\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6075 - accuracy: 0.7039 - val_loss: 0.5867 - val_accuracy: 0.7267\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6081 - accuracy: 0.7039 - val_loss: 0.5869 - val_accuracy: 0.7267\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6075 - accuracy: 0.7039 - val_loss: 0.5850 - val_accuracy: 0.7267\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6076 - accuracy: 0.7039 - val_loss: 0.5888 - val_accuracy: 0.7267\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5885 - val_accuracy: 0.7267\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6079 - accuracy: 0.7039 - val_loss: 0.5874 - val_accuracy: 0.7267\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6074 - accuracy: 0.7039 - val_loss: 0.5878 - val_accuracy: 0.7267\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6039 - accuracy: 0.7039 - val_loss: 0.5694 - val_accuracy: 0.7267\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6151 - accuracy: 0.7039 - val_loss: 0.5921 - val_accuracy: 0.7267\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6089 - accuracy: 0.7039 - val_loss: 0.5898 - val_accuracy: 0.7267\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6077 - accuracy: 0.7039 - val_loss: 0.5885 - val_accuracy: 0.7267\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6079 - accuracy: 0.7039 - val_loss: 0.5875 - val_accuracy: 0.7267\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6076 - accuracy: 0.7039 - val_loss: 0.5878 - val_accuracy: 0.7267\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6075 - accuracy: 0.7039 - val_loss: 0.5876 - val_accuracy: 0.7267\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6075 - accuracy: 0.7039 - val_loss: 0.5878 - val_accuracy: 0.7267\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6078 - accuracy: 0.7039 - val_loss: 0.5883 - val_accuracy: 0.7267\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6076 - accuracy: 0.7039 - val_loss: 0.5861 - val_accuracy: 0.7267\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6062 - accuracy: 0.7039 - val_loss: 0.5809 - val_accuracy: 0.7267\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6135 - accuracy: 0.7039 - val_loss: 0.5906 - val_accuracy: 0.7267\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6084 - accuracy: 0.7039 - val_loss: 0.5901 - val_accuracy: 0.7267\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5901 - accuracy: 0.7267\n",
            "Test Loss: 0.590121328830719, Test Accuracy: 0.7266666889190674\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 6s 244ms/step - loss: 6.7488 - accuracy: 0.6617 - val_loss: 0.6779 - val_accuracy: 0.7358\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6646 - accuracy: 0.7017 - val_loss: 0.6087 - val_accuracy: 0.7358\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6222 - accuracy: 0.7017 - val_loss: 0.5790 - val_accuracy: 0.7358\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6113 - accuracy: 0.7017 - val_loss: 0.5857 - val_accuracy: 0.7358\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6097 - accuracy: 0.7017 - val_loss: 0.5783 - val_accuracy: 0.7358\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6107 - accuracy: 0.7017 - val_loss: 0.5793 - val_accuracy: 0.7358\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5810 - val_accuracy: 0.7358\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6103 - accuracy: 0.7017 - val_loss: 0.5782 - val_accuracy: 0.7358\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6118 - accuracy: 0.7017 - val_loss: 0.5800 - val_accuracy: 0.7358\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6114 - accuracy: 0.7017 - val_loss: 0.5827 - val_accuracy: 0.7358\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5792 - val_accuracy: 0.7358\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6110 - accuracy: 0.7017 - val_loss: 0.5827 - val_accuracy: 0.7358\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6135 - accuracy: 0.7017 - val_loss: 0.5784 - val_accuracy: 0.7358\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6122 - accuracy: 0.7017 - val_loss: 0.5898 - val_accuracy: 0.7358\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6108 - accuracy: 0.7017 - val_loss: 0.5783 - val_accuracy: 0.7358\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6102 - accuracy: 0.7017 - val_loss: 0.5787 - val_accuracy: 0.7358\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5800 - val_accuracy: 0.7358\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5834 - val_accuracy: 0.7358\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6103 - accuracy: 0.7017 - val_loss: 0.5790 - val_accuracy: 0.7358\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6118 - accuracy: 0.7017 - val_loss: 0.5825 - val_accuracy: 0.7358\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6103 - accuracy: 0.7017 - val_loss: 0.5781 - val_accuracy: 0.7358\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6099 - accuracy: 0.7017 - val_loss: 0.5812 - val_accuracy: 0.7358\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6111 - accuracy: 0.7017 - val_loss: 0.5830 - val_accuracy: 0.7358\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6103 - accuracy: 0.7017 - val_loss: 0.5783 - val_accuracy: 0.7358\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5799 - val_accuracy: 0.7358\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6097 - accuracy: 0.7017 - val_loss: 0.5790 - val_accuracy: 0.7358\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6099 - accuracy: 0.7017 - val_loss: 0.5806 - val_accuracy: 0.7358\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6102 - accuracy: 0.7017 - val_loss: 0.5791 - val_accuracy: 0.7358\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6103 - accuracy: 0.7017 - val_loss: 0.5836 - val_accuracy: 0.7358\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6097 - accuracy: 0.7017 - val_loss: 0.5786 - val_accuracy: 0.7358\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5793 - val_accuracy: 0.7358\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5805 - val_accuracy: 0.7358\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6096 - accuracy: 0.7017 - val_loss: 0.5806 - val_accuracy: 0.7358\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6103 - accuracy: 0.7017 - val_loss: 0.5806 - val_accuracy: 0.7358\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6095 - accuracy: 0.7017 - val_loss: 0.5787 - val_accuracy: 0.7358\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6124 - accuracy: 0.7017 - val_loss: 0.5797 - val_accuracy: 0.7358\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6109 - accuracy: 0.7017 - val_loss: 0.5832 - val_accuracy: 0.7358\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6103 - accuracy: 0.7017 - val_loss: 0.5794 - val_accuracy: 0.7358\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6099 - accuracy: 0.7017 - val_loss: 0.5812 - val_accuracy: 0.7358\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6099 - accuracy: 0.7017 - val_loss: 0.5799 - val_accuracy: 0.7358\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6095 - accuracy: 0.7017 - val_loss: 0.5821 - val_accuracy: 0.7358\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6097 - accuracy: 0.7017 - val_loss: 0.5806 - val_accuracy: 0.7358\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5802 - val_accuracy: 0.7358\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6100 - accuracy: 0.7017 - val_loss: 0.5808 - val_accuracy: 0.7358\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6112 - accuracy: 0.7017 - val_loss: 0.5783 - val_accuracy: 0.7358\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5828 - val_accuracy: 0.7358\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6099 - accuracy: 0.7017 - val_loss: 0.5805 - val_accuracy: 0.7358\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6100 - accuracy: 0.7017 - val_loss: 0.5796 - val_accuracy: 0.7358\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5819 - val_accuracy: 0.7358\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6101 - accuracy: 0.7017 - val_loss: 0.5801 - val_accuracy: 0.7358\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5801 - val_accuracy: 0.7358\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6096 - accuracy: 0.7017 - val_loss: 0.5809 - val_accuracy: 0.7358\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6096 - accuracy: 0.7017 - val_loss: 0.5815 - val_accuracy: 0.7358\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5806 - val_accuracy: 0.7358\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5814 - val_accuracy: 0.7358\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5817 - val_accuracy: 0.7358\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6096 - accuracy: 0.7017 - val_loss: 0.5795 - val_accuracy: 0.7358\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6101 - accuracy: 0.7017 - val_loss: 0.5792 - val_accuracy: 0.7358\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5793 - val_accuracy: 0.7358\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5831 - val_accuracy: 0.7358\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6115 - accuracy: 0.7017 - val_loss: 0.5789 - val_accuracy: 0.7358\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6094 - accuracy: 0.7017 - val_loss: 0.5828 - val_accuracy: 0.7358\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6102 - accuracy: 0.7017 - val_loss: 0.5807 - val_accuracy: 0.7358\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6100 - accuracy: 0.7017 - val_loss: 0.5805 - val_accuracy: 0.7358\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6112 - accuracy: 0.7017 - val_loss: 0.5787 - val_accuracy: 0.7358\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5824 - val_accuracy: 0.7358\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6100 - accuracy: 0.7017 - val_loss: 0.5786 - val_accuracy: 0.7358\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6099 - accuracy: 0.7017 - val_loss: 0.5816 - val_accuracy: 0.7358\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6095 - accuracy: 0.7017 - val_loss: 0.5801 - val_accuracy: 0.7358\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6103 - accuracy: 0.7017 - val_loss: 0.5788 - val_accuracy: 0.7358\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6096 - accuracy: 0.7017 - val_loss: 0.5811 - val_accuracy: 0.7358\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6112 - accuracy: 0.7017 - val_loss: 0.5825 - val_accuracy: 0.7358\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6094 - accuracy: 0.7017 - val_loss: 0.5784 - val_accuracy: 0.7358\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6099 - accuracy: 0.7017 - val_loss: 0.5815 - val_accuracy: 0.7358\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6108 - accuracy: 0.7017 - val_loss: 0.5818 - val_accuracy: 0.7358\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5800 - val_accuracy: 0.7358\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6095 - accuracy: 0.7017 - val_loss: 0.5807 - val_accuracy: 0.7358\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6095 - accuracy: 0.7017 - val_loss: 0.5808 - val_accuracy: 0.7358\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6096 - accuracy: 0.7017 - val_loss: 0.5805 - val_accuracy: 0.7358\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5792 - val_accuracy: 0.7358\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6094 - accuracy: 0.7017 - val_loss: 0.5816 - val_accuracy: 0.7358\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5805 - val_accuracy: 0.7358\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5790 - val_accuracy: 0.7358\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5808 - val_accuracy: 0.7358\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6105 - accuracy: 0.7017 - val_loss: 0.5825 - val_accuracy: 0.7358\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6095 - accuracy: 0.7017 - val_loss: 0.5790 - val_accuracy: 0.7358\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6100 - accuracy: 0.7017 - val_loss: 0.5789 - val_accuracy: 0.7358\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5813 - val_accuracy: 0.7358\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6097 - accuracy: 0.7017 - val_loss: 0.5840 - val_accuracy: 0.7358\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6108 - accuracy: 0.7017 - val_loss: 0.5794 - val_accuracy: 0.7358\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6096 - accuracy: 0.7017 - val_loss: 0.5814 - val_accuracy: 0.7358\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.6110 - accuracy: 0.7017 - val_loss: 0.5820 - val_accuracy: 0.7358\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6110 - accuracy: 0.7017 - val_loss: 0.5784 - val_accuracy: 0.7358\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6096 - accuracy: 0.7017 - val_loss: 0.5811 - val_accuracy: 0.7358\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6106 - accuracy: 0.7017 - val_loss: 0.5827 - val_accuracy: 0.7358\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5796 - val_accuracy: 0.7358\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5800 - val_accuracy: 0.7358\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6104 - accuracy: 0.7017 - val_loss: 0.5803 - val_accuracy: 0.7358\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6097 - accuracy: 0.7017 - val_loss: 0.5793 - val_accuracy: 0.7358\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.6098 - accuracy: 0.7017 - val_loss: 0.5803 - val_accuracy: 0.7358\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5803 - accuracy: 0.7358\n",
            "Test Loss: 0.580276370048523, Test Accuracy: 0.735785961151123\n",
            "\n",
            "Average Accuracy Across All Folds: 0.7418238639831543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline + Random 증강 :  0.7055885910987854\n",
        "\n"
      ],
      "metadata": {
        "id": "ET90Okl8WBiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이거다!!!\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test))\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "TsF9IgfOV79G",
        "outputId": "8618b08a-360e-4d29-f36f-329c59b29f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f7de8aae810b>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 데이터 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_and_labels_parallel_argumentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 레이블 인코딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_images_and_labels_parallel_argumentation' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdamW + Random 증강 : 0.8914704561233521"
      ],
      "metadata": {
        "id": "BEPCpWdZYOJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이거다!!!\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import AdamW\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels_parallel_argumentation(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GOknshgLckT",
        "outputId": "c485fa5b-1dd3-45b8-afce-eaa38a04db72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 17s 196ms/step - loss: 0.5667 - accuracy: 0.6882 - val_loss: 0.5570 - val_accuracy: 0.6323\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5245 - accuracy: 0.6979 - val_loss: 0.5108 - val_accuracy: 0.6323\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4642 - accuracy: 0.7431 - val_loss: 0.4963 - val_accuracy: 0.8000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3920 - accuracy: 0.8110 - val_loss: 0.4706 - val_accuracy: 0.7935\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3266 - accuracy: 0.8756 - val_loss: 0.3814 - val_accuracy: 0.7871\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3495 - accuracy: 0.8514 - val_loss: 0.4219 - val_accuracy: 0.7742\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5312 - accuracy: 0.7173 - val_loss: 0.5633 - val_accuracy: 0.6323\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5068 - accuracy: 0.6979 - val_loss: 0.5255 - val_accuracy: 0.6323\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4490 - accuracy: 0.7334 - val_loss: 0.4822 - val_accuracy: 0.7613\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3859 - accuracy: 0.8368 - val_loss: 0.4981 - val_accuracy: 0.7935\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3425 - accuracy: 0.8530 - val_loss: 0.4759 - val_accuracy: 0.8194\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2715 - accuracy: 0.8901 - val_loss: 0.4073 - val_accuracy: 0.8194\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3408 - accuracy: 0.8449 - val_loss: 0.3944 - val_accuracy: 0.8000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2511 - accuracy: 0.8998 - val_loss: 0.4649 - val_accuracy: 0.8323\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1446 - accuracy: 0.9338 - val_loss: 0.3754 - val_accuracy: 0.8258\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1422 - accuracy: 0.9580 - val_loss: 0.5037 - val_accuracy: 0.8710\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1588 - accuracy: 0.9338 - val_loss: 0.3933 - val_accuracy: 0.8323\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0725 - accuracy: 0.9790 - val_loss: 0.5259 - val_accuracy: 0.8581\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1306 - accuracy: 0.9580 - val_loss: 0.4527 - val_accuracy: 0.8323\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1519 - accuracy: 0.9548 - val_loss: 0.3260 - val_accuracy: 0.8452\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0574 - accuracy: 0.9871 - val_loss: 0.6409 - val_accuracy: 0.8323\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 1.3699 - val_accuracy: 0.7613\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0975 - accuracy: 0.9596 - val_loss: 0.5300 - val_accuracy: 0.8258\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0312 - accuracy: 0.9871 - val_loss: 0.4337 - val_accuracy: 0.8710\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0135 - accuracy: 0.9935 - val_loss: 0.8465 - val_accuracy: 0.8323\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.8839\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8630 - val_accuracy: 0.8774\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 9.9251e-05 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.8839\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 5.3647e-05 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.8774\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 4.6228e-05 - accuracy: 1.0000 - val_loss: 0.8760 - val_accuracy: 0.8774\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 4.0563e-05 - accuracy: 1.0000 - val_loss: 0.8907 - val_accuracy: 0.8774\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 3.4804e-05 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.8774\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 3.1119e-05 - accuracy: 1.0000 - val_loss: 0.9170 - val_accuracy: 0.8774\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.8072e-05 - accuracy: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.8774\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 2.5312e-05 - accuracy: 1.0000 - val_loss: 0.9404 - val_accuracy: 0.8774\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.3340e-05 - accuracy: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.8774\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 2.1551e-05 - accuracy: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.8774\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 2.0098e-05 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.8774\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.8734e-05 - accuracy: 1.0000 - val_loss: 0.9729 - val_accuracy: 0.8774\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.7511e-05 - accuracy: 1.0000 - val_loss: 0.9798 - val_accuracy: 0.8774\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.6327e-05 - accuracy: 1.0000 - val_loss: 0.9870 - val_accuracy: 0.8774\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.5326e-05 - accuracy: 1.0000 - val_loss: 0.9936 - val_accuracy: 0.8774\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.4410e-05 - accuracy: 1.0000 - val_loss: 0.9993 - val_accuracy: 0.8839\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.3592e-05 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.8774\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 1.2780e-05 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.8774\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 1.1993e-05 - accuracy: 1.0000 - val_loss: 1.0188 - val_accuracy: 0.8774\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.1352e-05 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.8774\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 1.0723e-05 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 0.8774\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 1.0129e-05 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 0.8774\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 9.5273e-06 - accuracy: 1.0000 - val_loss: 1.0418 - val_accuracy: 0.8774\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0418 - accuracy: 0.8774\n",
            "Test Loss: 1.0418342351913452, Test Accuracy: 0.8774193525314331\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 5s 78ms/step - loss: 0.6472 - accuracy: 0.6769 - val_loss: 0.5658 - val_accuracy: 0.7161\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6058 - accuracy: 0.6769 - val_loss: 0.5461 - val_accuracy: 0.7161\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5689 - accuracy: 0.6769 - val_loss: 0.5933 - val_accuracy: 0.7161\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5778 - accuracy: 0.6769 - val_loss: 0.4911 - val_accuracy: 0.7161\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5176 - accuracy: 0.6769 - val_loss: 0.4331 - val_accuracy: 0.7161\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4747 - accuracy: 0.7318 - val_loss: 0.3807 - val_accuracy: 0.8323\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4406 - accuracy: 0.7900 - val_loss: 0.3178 - val_accuracy: 0.8903\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4908 - accuracy: 0.7399 - val_loss: 0.4387 - val_accuracy: 0.8452\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4163 - accuracy: 0.8239 - val_loss: 0.4241 - val_accuracy: 0.8129\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3889 - accuracy: 0.8223 - val_loss: 0.2707 - val_accuracy: 0.8903\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3158 - accuracy: 0.8546 - val_loss: 0.3278 - val_accuracy: 0.8452\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2916 - accuracy: 0.8885 - val_loss: 0.3847 - val_accuracy: 0.8258\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2195 - accuracy: 0.9144 - val_loss: 0.2322 - val_accuracy: 0.8968\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1614 - accuracy: 0.9273 - val_loss: 0.4813 - val_accuracy: 0.8000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1439 - accuracy: 0.9467 - val_loss: 0.2420 - val_accuracy: 0.8968\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1032 - accuracy: 0.9532 - val_loss: 0.4597 - val_accuracy: 0.8581\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2564 - accuracy: 0.9031 - val_loss: 0.4757 - val_accuracy: 0.7613\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3193 - accuracy: 0.8788 - val_loss: 0.3189 - val_accuracy: 0.8323\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1970 - accuracy: 0.9144 - val_loss: 0.3049 - val_accuracy: 0.8516\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1052 - accuracy: 0.9628 - val_loss: 0.2656 - val_accuracy: 0.8903\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0588 - accuracy: 0.9838 - val_loss: 0.4831 - val_accuracy: 0.8710\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.4979 - val_accuracy: 0.8903\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8903\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6454 - val_accuracy: 0.8839\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 0.6035 - val_accuracy: 0.8968\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1446 - accuracy: 0.9677 - val_loss: 0.3303 - val_accuracy: 0.8903\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2492 - accuracy: 0.9176 - val_loss: 0.2950 - val_accuracy: 0.8903\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2088 - accuracy: 0.9208 - val_loss: 0.2501 - val_accuracy: 0.8710\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0912 - accuracy: 0.9790 - val_loss: 0.3481 - val_accuracy: 0.8968\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0343 - accuracy: 0.9935 - val_loss: 0.7014 - val_accuracy: 0.8839\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.7527 - val_accuracy: 0.8323\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0368 - accuracy: 0.9838 - val_loss: 0.4720 - val_accuracy: 0.8839\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.4683 - val_accuracy: 0.8839\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.5473 - val_accuracy: 0.8710\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6168 - val_accuracy: 0.8903\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.0167e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8839\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.2269e-04 - accuracy: 1.0000 - val_loss: 0.7300 - val_accuracy: 0.8903\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 4.7719e-05 - accuracy: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.8903\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 3.5410e-05 - accuracy: 1.0000 - val_loss: 0.7397 - val_accuracy: 0.8968\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.9217e-05 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.8968\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.5934e-05 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.8968\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 2.3471e-05 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.8968\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.1435e-05 - accuracy: 1.0000 - val_loss: 0.7670 - val_accuracy: 0.8903\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.9712e-05 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.8903\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 1.8178e-05 - accuracy: 1.0000 - val_loss: 0.7803 - val_accuracy: 0.8903\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.6749e-05 - accuracy: 1.0000 - val_loss: 0.7876 - val_accuracy: 0.8903\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.5367e-05 - accuracy: 1.0000 - val_loss: 0.7942 - val_accuracy: 0.8968\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.4192e-05 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.8968\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.3008e-05 - accuracy: 1.0000 - val_loss: 0.8087 - val_accuracy: 0.8968\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 1.1890e-05 - accuracy: 1.0000 - val_loss: 0.8163 - val_accuracy: 0.8968\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8163 - accuracy: 0.8968\n",
            "Test Loss: 0.816343367099762, Test Accuracy: 0.896774172782898\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 5s 79ms/step - loss: 0.6285 - accuracy: 0.6753 - val_loss: 0.6435 - val_accuracy: 0.6516\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5942 - accuracy: 0.6931 - val_loss: 0.6046 - val_accuracy: 0.6516\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5475 - accuracy: 0.6931 - val_loss: 0.6042 - val_accuracy: 0.6516\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5089 - accuracy: 0.6931 - val_loss: 0.4866 - val_accuracy: 0.6516\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4652 - accuracy: 0.6947 - val_loss: 0.4538 - val_accuracy: 0.6839\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3975 - accuracy: 0.7997 - val_loss: 0.5327 - val_accuracy: 0.7613\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4209 - accuracy: 0.8094 - val_loss: 0.4397 - val_accuracy: 0.8258\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3497 - accuracy: 0.8659 - val_loss: 0.3293 - val_accuracy: 0.8774\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3171 - accuracy: 0.8465 - val_loss: 0.3702 - val_accuracy: 0.8065\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2362 - accuracy: 0.8821 - val_loss: 0.3467 - val_accuracy: 0.8258\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2381 - accuracy: 0.9031 - val_loss: 0.3260 - val_accuracy: 0.8645\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1606 - accuracy: 0.9499 - val_loss: 0.3772 - val_accuracy: 0.8387\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1069 - accuracy: 0.9628 - val_loss: 0.5066 - val_accuracy: 0.8903\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0976 - accuracy: 0.9725 - val_loss: 0.3578 - val_accuracy: 0.8710\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0934 - accuracy: 0.9725 - val_loss: 0.3799 - val_accuracy: 0.9032\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1265 - accuracy: 0.9499 - val_loss: 0.4159 - val_accuracy: 0.8323\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0612 - accuracy: 0.9822 - val_loss: 0.3298 - val_accuracy: 0.8968\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.5429 - val_accuracy: 0.8968\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.5540 - val_accuracy: 0.8903\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1403 - accuracy: 0.9677 - val_loss: 0.5471 - val_accuracy: 0.8516\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1276 - accuracy: 0.9661 - val_loss: 0.2890 - val_accuracy: 0.9226\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0328 - accuracy: 0.9919 - val_loss: 0.9300 - val_accuracy: 0.8774\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1017 - accuracy: 0.9725 - val_loss: 0.3519 - val_accuracy: 0.8839\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0679 - accuracy: 0.9725 - val_loss: 0.3002 - val_accuracy: 0.9097\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.4803 - val_accuracy: 0.9161\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.7502 - val_accuracy: 0.8968\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.6654 - val_accuracy: 0.9161\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0412 - accuracy: 0.9903 - val_loss: 0.5346 - val_accuracy: 0.9032\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0449 - accuracy: 0.9790 - val_loss: 0.3368 - val_accuracy: 0.9032\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1264 - accuracy: 0.9515 - val_loss: 0.2798 - val_accuracy: 0.9032\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0515 - accuracy: 0.9855 - val_loss: 0.3642 - val_accuracy: 0.8968\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.7056 - val_accuracy: 0.8903\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.7129 - val_accuracy: 0.9161\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 7.4404e-04 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.9161\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 2.4191e-04 - accuracy: 1.0000 - val_loss: 0.8134 - val_accuracy: 0.9161\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 6.5263e-05 - accuracy: 1.0000 - val_loss: 0.8304 - val_accuracy: 0.9097\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.2317e-05 - accuracy: 1.0000 - val_loss: 0.8562 - val_accuracy: 0.9097\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 1.3117e-05 - accuracy: 1.0000 - val_loss: 0.8679 - val_accuracy: 0.9097\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 1.0834e-05 - accuracy: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.9032\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 1.0044e-05 - accuracy: 1.0000 - val_loss: 0.8775 - val_accuracy: 0.9032\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 9.3590e-06 - accuracy: 1.0000 - val_loss: 0.8802 - val_accuracy: 0.9032\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 8.8651e-06 - accuracy: 1.0000 - val_loss: 0.8828 - val_accuracy: 0.9032\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 8.4346e-06 - accuracy: 1.0000 - val_loss: 0.8852 - val_accuracy: 0.9032\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 8.0866e-06 - accuracy: 1.0000 - val_loss: 0.8873 - val_accuracy: 0.9032\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 7.7387e-06 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.9032\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 7.3847e-06 - accuracy: 1.0000 - val_loss: 0.8916 - val_accuracy: 0.9032\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 7.1051e-06 - accuracy: 1.0000 - val_loss: 0.8941 - val_accuracy: 0.9032\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 6.8145e-06 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.9032\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 6.5402e-06 - accuracy: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.9032\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 6.2789e-06 - accuracy: 1.0000 - val_loss: 0.9007 - val_accuracy: 0.9032\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.9007 - accuracy: 0.9032\n",
            "Test Loss: 0.9006704092025757, Test Accuracy: 0.9032257795333862\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 5s 79ms/step - loss: 0.6026 - accuracy: 0.6817 - val_loss: 0.5632 - val_accuracy: 0.6968\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5641 - accuracy: 0.6817 - val_loss: 0.5333 - val_accuracy: 0.6968\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5135 - accuracy: 0.6817 - val_loss: 0.4912 - val_accuracy: 0.6968\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4625 - accuracy: 0.7512 - val_loss: 0.5060 - val_accuracy: 0.7742\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4578 - accuracy: 0.7997 - val_loss: 0.4269 - val_accuracy: 0.8000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3930 - accuracy: 0.8304 - val_loss: 0.3444 - val_accuracy: 0.8258\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2850 - accuracy: 0.8966 - val_loss: 0.3045 - val_accuracy: 0.8710\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2254 - accuracy: 0.9192 - val_loss: 0.8913 - val_accuracy: 0.6968\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2183 - accuracy: 0.9095 - val_loss: 0.2636 - val_accuracy: 0.8710\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1322 - accuracy: 0.9596 - val_loss: 0.5117 - val_accuracy: 0.8452\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2722 - accuracy: 0.8708 - val_loss: 0.3831 - val_accuracy: 0.8710\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2157 - accuracy: 0.9289 - val_loss: 0.3250 - val_accuracy: 0.8645\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0687 - accuracy: 0.9742 - val_loss: 0.4655 - val_accuracy: 0.8645\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1490 - accuracy: 0.9451 - val_loss: 0.3125 - val_accuracy: 0.8710\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1364 - accuracy: 0.9515 - val_loss: 0.2378 - val_accuracy: 0.9032\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0488 - accuracy: 0.9871 - val_loss: 0.3240 - val_accuracy: 0.8516\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0110 - accuracy: 0.9984 - val_loss: 0.4677 - val_accuracy: 0.9032\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.6679 - val_accuracy: 0.8839\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0369 - accuracy: 0.9855 - val_loss: 1.5710 - val_accuracy: 0.7419\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2587 - accuracy: 0.9176 - val_loss: 0.3175 - val_accuracy: 0.8452\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1254 - accuracy: 0.9693 - val_loss: 0.5721 - val_accuracy: 0.8000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0402 - accuracy: 0.9806 - val_loss: 0.3821 - val_accuracy: 0.8839\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0192 - accuracy: 0.9952 - val_loss: 0.5740 - val_accuracy: 0.8839\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0567 - accuracy: 0.9806 - val_loss: 0.4333 - val_accuracy: 0.8839\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0559 - accuracy: 0.9758 - val_loss: 0.3441 - val_accuracy: 0.8516\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0446 - accuracy: 0.9838 - val_loss: 0.4269 - val_accuracy: 0.8710\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.4107 - val_accuracy: 0.8774\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5982 - val_accuracy: 0.8516\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.8774\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 2.4233e-04 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.8839\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 2.8492e-04 - accuracy: 1.0000 - val_loss: 0.7667 - val_accuracy: 0.8903\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 1.1107e-04 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.9032\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 4.8392e-05 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8903\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 3.1576e-05 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8903\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 2.5847e-05 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8903\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 2.2041e-05 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8903\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.9848e-05 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8903\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.7989e-05 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8903\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.6711e-05 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8903\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.5394e-05 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8903\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.4417e-05 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8903\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.3519e-05 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8903\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.2705e-05 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8903\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.1976e-05 - accuracy: 1.0000 - val_loss: 0.7206 - val_accuracy: 0.8903\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.1301e-05 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.8903\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.0687e-05 - accuracy: 1.0000 - val_loss: 0.7241 - val_accuracy: 0.8903\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 1.0124e-05 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.8903\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 9.6185e-06 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.8903\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 9.1425e-06 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.8903\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 8.6915e-06 - accuracy: 1.0000 - val_loss: 0.7315 - val_accuracy: 0.8903\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7315 - accuracy: 0.8903\n",
            "Test Loss: 0.7315278649330139, Test Accuracy: 0.8903225660324097\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 221ms/step - loss: 0.6436 - accuracy: 0.6661 - val_loss: 0.5751 - val_accuracy: 0.7273\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.6163 - accuracy: 0.6742 - val_loss: 0.5454 - val_accuracy: 0.7273\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.5796 - accuracy: 0.6742 - val_loss: 0.5329 - val_accuracy: 0.7273\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.5474 - accuracy: 0.6742 - val_loss: 0.5277 - val_accuracy: 0.7273\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4888 - accuracy: 0.6742 - val_loss: 0.4410 - val_accuracy: 0.7273\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4317 - accuracy: 0.7968 - val_loss: 0.4931 - val_accuracy: 0.7792\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4414 - accuracy: 0.7952 - val_loss: 0.4102 - val_accuracy: 0.8766\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.3240 - accuracy: 0.8452 - val_loss: 0.3297 - val_accuracy: 0.8571\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2844 - accuracy: 0.8726 - val_loss: 0.6731 - val_accuracy: 0.7532\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3043 - accuracy: 0.8677 - val_loss: 0.3499 - val_accuracy: 0.8831\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.2837 - accuracy: 0.8758 - val_loss: 0.5090 - val_accuracy: 0.7078\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2402 - accuracy: 0.9129 - val_loss: 0.3619 - val_accuracy: 0.8831\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1469 - accuracy: 0.9419 - val_loss: 0.4797 - val_accuracy: 0.8961\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0938 - accuracy: 0.9694 - val_loss: 0.6129 - val_accuracy: 0.8636\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1334 - accuracy: 0.9484 - val_loss: 0.4351 - val_accuracy: 0.9091\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1496 - accuracy: 0.9403 - val_loss: 0.3401 - val_accuracy: 0.9156\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0622 - accuracy: 0.9871 - val_loss: 0.6722 - val_accuracy: 0.8247\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0217 - accuracy: 0.9903 - val_loss: 0.6907 - val_accuracy: 0.8831\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 1.3054 - val_accuracy: 0.8961\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2087 - accuracy: 0.9371 - val_loss: 0.3732 - val_accuracy: 0.8312\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1343 - accuracy: 0.9435 - val_loss: 0.5397 - val_accuracy: 0.8701\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0392 - accuracy: 0.9855 - val_loss: 0.6682 - val_accuracy: 0.8831\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.8302 - val_accuracy: 0.8896\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 1.1475 - val_accuracy: 0.8896\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0521 - accuracy: 0.9806 - val_loss: 1.4257 - val_accuracy: 0.7143\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0393 - accuracy: 0.9823 - val_loss: 0.6039 - val_accuracy: 0.8766\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.8639 - val_accuracy: 0.8766\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0224 - accuracy: 0.9919 - val_loss: 0.9016 - val_accuracy: 0.9091\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0630 - accuracy: 0.9677 - val_loss: 0.9537 - val_accuracy: 0.8506\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0564 - accuracy: 0.9790 - val_loss: 0.5806 - val_accuracy: 0.8571\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.5305 - val_accuracy: 0.8831\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.9620 - val_accuracy: 0.8636\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.9074 - val_accuracy: 0.8442\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 1.1549 - val_accuracy: 0.8182\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 7.2448e-04 - accuracy: 1.0000 - val_loss: 1.0601 - val_accuracy: 0.8701\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.3484e-04 - accuracy: 1.0000 - val_loss: 1.0473 - val_accuracy: 0.8896\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.6118e-04 - accuracy: 1.0000 - val_loss: 1.0920 - val_accuracy: 0.8896\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 5.9110e-05 - accuracy: 1.0000 - val_loss: 1.1281 - val_accuracy: 0.8896\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 4.4939e-05 - accuracy: 1.0000 - val_loss: 1.1400 - val_accuracy: 0.8896\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 3.6255e-05 - accuracy: 1.0000 - val_loss: 1.1451 - val_accuracy: 0.8896\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 3.0925e-05 - accuracy: 1.0000 - val_loss: 1.1474 - val_accuracy: 0.8896\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 2.5702e-05 - accuracy: 1.0000 - val_loss: 1.1507 - val_accuracy: 0.8896\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 2.2264e-05 - accuracy: 1.0000 - val_loss: 1.1546 - val_accuracy: 0.8896\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 1.9779e-05 - accuracy: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.8896\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.7769e-05 - accuracy: 1.0000 - val_loss: 1.1643 - val_accuracy: 0.8896\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.6345e-05 - accuracy: 1.0000 - val_loss: 1.1699 - val_accuracy: 0.8896\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.4721e-05 - accuracy: 1.0000 - val_loss: 1.1759 - val_accuracy: 0.8896\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.3525e-05 - accuracy: 1.0000 - val_loss: 1.1818 - val_accuracy: 0.8896\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.2507e-05 - accuracy: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.8896\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 1.1446e-05 - accuracy: 1.0000 - val_loss: 1.1945 - val_accuracy: 0.8896\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1945 - accuracy: 0.8896\n",
            "Test Loss: 1.194462776184082, Test Accuracy: 0.8896104097366333\n",
            "\n",
            "Average Accuracy Across All Folds: 0.8914704561233521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdamW + Random 증강 + dropout 3개 : 0.8707917928695679"
      ],
      "metadata": {
        "id": "qcjX7QpHYe5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import AdamW\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels_parallel_argumentation(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "id": "n0n6-vShXCVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798e333a-4702-4e4d-ed0c-b7a103f1694c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 8s 143ms/step - loss: 0.6304 - accuracy: 0.6737 - val_loss: 0.6207 - val_accuracy: 0.6323\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.5731 - accuracy: 0.6979 - val_loss: 0.5867 - val_accuracy: 0.6323\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.5133 - accuracy: 0.6979 - val_loss: 0.5261 - val_accuracy: 0.6323\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.4443 - accuracy: 0.6979 - val_loss: 0.5307 - val_accuracy: 0.6387\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.4184 - accuracy: 0.7528 - val_loss: 0.5049 - val_accuracy: 0.7742\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3871 - accuracy: 0.8029 - val_loss: 0.5125 - val_accuracy: 0.7806\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3706 - accuracy: 0.8788 - val_loss: 0.5866 - val_accuracy: 0.7097\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3620 - accuracy: 0.8449 - val_loss: 0.5314 - val_accuracy: 0.7226\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3542 - accuracy: 0.8837 - val_loss: 0.6703 - val_accuracy: 0.7355\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3060 - accuracy: 0.9031 - val_loss: 0.4859 - val_accuracy: 0.8129\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2339 - accuracy: 0.9596 - val_loss: 0.5436 - val_accuracy: 0.8065\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2536 - accuracy: 0.9289 - val_loss: 0.5151 - val_accuracy: 0.7419\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3318 - accuracy: 0.8498 - val_loss: 0.5120 - val_accuracy: 0.7806\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2388 - accuracy: 0.9160 - val_loss: 0.4448 - val_accuracy: 0.7935\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1391 - accuracy: 0.9532 - val_loss: 0.6072 - val_accuracy: 0.8323\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0753 - accuracy: 0.9774 - val_loss: 0.6095 - val_accuracy: 0.8000\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0321 - accuracy: 0.9952 - val_loss: 0.5894 - val_accuracy: 0.8645\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.8385 - val_accuracy: 0.8516\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1246 - accuracy: 0.9661 - val_loss: 0.8112 - val_accuracy: 0.8129\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0836 - accuracy: 0.9774 - val_loss: 0.4791 - val_accuracy: 0.8129\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1116 - accuracy: 0.9645 - val_loss: 0.5900 - val_accuracy: 0.8516\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0506 - accuracy: 0.9855 - val_loss: 0.6601 - val_accuracy: 0.8581\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0354 - accuracy: 0.9903 - val_loss: 0.6575 - val_accuracy: 0.8452\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 1.3508 - val_accuracy: 0.7677\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1314 - accuracy: 0.9564 - val_loss: 0.5339 - val_accuracy: 0.8387\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0407 - accuracy: 0.9935 - val_loss: 0.8696 - val_accuracy: 0.7871\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0157 - accuracy: 0.9968 - val_loss: 0.8554 - val_accuracy: 0.8581\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1117 - val_accuracy: 0.8516\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 3.0250e-04 - accuracy: 1.0000 - val_loss: 1.3964 - val_accuracy: 0.8323\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.6571e-04 - accuracy: 1.0000 - val_loss: 1.4960 - val_accuracy: 0.8194\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.7335e-04 - accuracy: 1.0000 - val_loss: 1.4697 - val_accuracy: 0.8323\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.2176e-05 - accuracy: 1.0000 - val_loss: 1.4450 - val_accuracy: 0.8452\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 4.3492e-05 - accuracy: 1.0000 - val_loss: 1.4372 - val_accuracy: 0.8452\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 3.6328e-05 - accuracy: 1.0000 - val_loss: 1.4351 - val_accuracy: 0.8452\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 3.0153e-05 - accuracy: 1.0000 - val_loss: 1.4365 - val_accuracy: 0.8452\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.6566e-05 - accuracy: 1.0000 - val_loss: 1.4383 - val_accuracy: 0.8516\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 2.4162e-05 - accuracy: 1.0000 - val_loss: 1.4419 - val_accuracy: 0.8516\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.3062e-05 - accuracy: 1.0000 - val_loss: 1.4457 - val_accuracy: 0.8516\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.5271e-05 - accuracy: 1.0000 - val_loss: 1.4496 - val_accuracy: 0.8516\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.9217e-05 - accuracy: 1.0000 - val_loss: 1.4541 - val_accuracy: 0.8516\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.8747e-05 - accuracy: 1.0000 - val_loss: 1.4592 - val_accuracy: 0.8516\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.7608e-05 - accuracy: 1.0000 - val_loss: 1.4640 - val_accuracy: 0.8516\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.9980e-05 - accuracy: 1.0000 - val_loss: 1.4694 - val_accuracy: 0.8516\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.6359e-05 - accuracy: 1.0000 - val_loss: 1.4745 - val_accuracy: 0.8516\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.2291e-05 - accuracy: 1.0000 - val_loss: 1.4788 - val_accuracy: 0.8516\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 1.3148e-05 - accuracy: 1.0000 - val_loss: 1.4832 - val_accuracy: 0.8516\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 1.4696e-05 - accuracy: 1.0000 - val_loss: 1.4879 - val_accuracy: 0.8516\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.6320e-06 - accuracy: 1.0000 - val_loss: 1.4932 - val_accuracy: 0.8516\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.0520e-05 - accuracy: 1.0000 - val_loss: 1.4978 - val_accuracy: 0.8516\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.1692e-06 - accuracy: 1.0000 - val_loss: 1.5023 - val_accuracy: 0.8516\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.3030e-05 - accuracy: 1.0000 - val_loss: 1.5079 - val_accuracy: 0.8516\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 9.5819e-06 - accuracy: 1.0000 - val_loss: 1.5145 - val_accuracy: 0.8516\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.4544e-06 - accuracy: 1.0000 - val_loss: 1.5197 - val_accuracy: 0.8516\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 9.0630e-06 - accuracy: 1.0000 - val_loss: 1.5251 - val_accuracy: 0.8581\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.1492e-06 - accuracy: 1.0000 - val_loss: 1.5301 - val_accuracy: 0.8581\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.2621e-06 - accuracy: 1.0000 - val_loss: 1.5348 - val_accuracy: 0.8581\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.6549e-06 - accuracy: 1.0000 - val_loss: 1.5403 - val_accuracy: 0.8581\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 7.8253e-06 - accuracy: 1.0000 - val_loss: 1.5463 - val_accuracy: 0.8581\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.4818e-06 - accuracy: 1.0000 - val_loss: 1.5516 - val_accuracy: 0.8581\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.9969e-06 - accuracy: 1.0000 - val_loss: 1.5564 - val_accuracy: 0.8581\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.2788e-06 - accuracy: 1.0000 - val_loss: 1.5611 - val_accuracy: 0.8581\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.2963e-06 - accuracy: 1.0000 - val_loss: 1.5663 - val_accuracy: 0.8581\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.1860e-06 - accuracy: 1.0000 - val_loss: 1.5718 - val_accuracy: 0.8581\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.8403e-06 - accuracy: 1.0000 - val_loss: 1.5766 - val_accuracy: 0.8581\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.8576e-06 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.8581\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.0259e-06 - accuracy: 1.0000 - val_loss: 1.5870 - val_accuracy: 0.8581\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.7448e-06 - accuracy: 1.0000 - val_loss: 1.5934 - val_accuracy: 0.8581\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.9830e-06 - accuracy: 1.0000 - val_loss: 1.6003 - val_accuracy: 0.8581\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.6992e-06 - accuracy: 1.0000 - val_loss: 1.6060 - val_accuracy: 0.8581\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.1442e-06 - accuracy: 1.0000 - val_loss: 1.6107 - val_accuracy: 0.8581\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.3111e-06 - accuracy: 1.0000 - val_loss: 1.6159 - val_accuracy: 0.8581\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.6874e-06 - accuracy: 1.0000 - val_loss: 1.6219 - val_accuracy: 0.8581\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.2976e-06 - accuracy: 1.0000 - val_loss: 1.6276 - val_accuracy: 0.8581\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.6188e-06 - accuracy: 1.0000 - val_loss: 1.6346 - val_accuracy: 0.8581\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.2445e-06 - accuracy: 1.0000 - val_loss: 1.6413 - val_accuracy: 0.8581\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.9729e-06 - accuracy: 1.0000 - val_loss: 1.6477 - val_accuracy: 0.8581\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.3688e-06 - accuracy: 1.0000 - val_loss: 1.6536 - val_accuracy: 0.8581\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.8959e-06 - accuracy: 1.0000 - val_loss: 1.6601 - val_accuracy: 0.8581\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.1511e-06 - accuracy: 1.0000 - val_loss: 1.6654 - val_accuracy: 0.8581\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.8991e-06 - accuracy: 1.0000 - val_loss: 1.6721 - val_accuracy: 0.8581\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.6847e-06 - accuracy: 1.0000 - val_loss: 1.6795 - val_accuracy: 0.8581\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.1874e-06 - accuracy: 1.0000 - val_loss: 1.6859 - val_accuracy: 0.8581\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.2201e-06 - accuracy: 1.0000 - val_loss: 1.6914 - val_accuracy: 0.8581\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.0920e-06 - accuracy: 1.0000 - val_loss: 1.6972 - val_accuracy: 0.8581\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.7096e-06 - accuracy: 1.0000 - val_loss: 1.7027 - val_accuracy: 0.8581\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.8666e-06 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.8581\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.0583e-06 - accuracy: 1.0000 - val_loss: 1.7148 - val_accuracy: 0.8581\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.0664e-06 - accuracy: 1.0000 - val_loss: 1.7213 - val_accuracy: 0.8581\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.1599e-06 - accuracy: 1.0000 - val_loss: 1.7271 - val_accuracy: 0.8581\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.2418e-06 - accuracy: 1.0000 - val_loss: 1.7327 - val_accuracy: 0.8581\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.5328e-06 - accuracy: 1.0000 - val_loss: 1.7393 - val_accuracy: 0.8581\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.0215e-06 - accuracy: 1.0000 - val_loss: 1.7441 - val_accuracy: 0.8581\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.4006e-06 - accuracy: 1.0000 - val_loss: 1.7496 - val_accuracy: 0.8581\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.4813e-06 - accuracy: 1.0000 - val_loss: 1.7553 - val_accuracy: 0.8581\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.7628e-06 - accuracy: 1.0000 - val_loss: 1.7607 - val_accuracy: 0.8581\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.3296e-06 - accuracy: 1.0000 - val_loss: 1.7665 - val_accuracy: 0.8581\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.1697e-06 - accuracy: 1.0000 - val_loss: 1.7731 - val_accuracy: 0.8581\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.3851e-06 - accuracy: 1.0000 - val_loss: 1.7792 - val_accuracy: 0.8581\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.8764e-06 - accuracy: 1.0000 - val_loss: 1.7846 - val_accuracy: 0.8581\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.5284e-06 - accuracy: 1.0000 - val_loss: 1.7895 - val_accuracy: 0.8581\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.7895 - accuracy: 0.8581\n",
            "Test Loss: 1.789489984512329, Test Accuracy: 0.8580645322799683\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 85ms/step - loss: 0.6333 - accuracy: 0.6511 - val_loss: 0.5469 - val_accuracy: 0.7161\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5802 - accuracy: 0.6769 - val_loss: 0.5216 - val_accuracy: 0.7161\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.5336 - accuracy: 0.6769 - val_loss: 0.4329 - val_accuracy: 0.7161\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5061 - accuracy: 0.6785 - val_loss: 0.4351 - val_accuracy: 0.7161\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5189 - accuracy: 0.6931 - val_loss: 0.4206 - val_accuracy: 0.7613\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.4576 - accuracy: 0.7706 - val_loss: 0.3835 - val_accuracy: 0.8323\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4190 - accuracy: 0.8174 - val_loss: 0.3716 - val_accuracy: 0.8516\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4340 - accuracy: 0.8320 - val_loss: 0.3904 - val_accuracy: 0.7935\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3828 - accuracy: 0.8417 - val_loss: 0.3607 - val_accuracy: 0.8774\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3305 - accuracy: 0.9111 - val_loss: 0.3546 - val_accuracy: 0.8387\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2995 - accuracy: 0.9321 - val_loss: 0.3601 - val_accuracy: 0.8710\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.2441 - accuracy: 0.9580 - val_loss: 0.7458 - val_accuracy: 0.8581\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2197 - accuracy: 0.9208 - val_loss: 0.6414 - val_accuracy: 0.8065\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2577 - accuracy: 0.9144 - val_loss: 0.3931 - val_accuracy: 0.8258\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1643 - accuracy: 0.9580 - val_loss: 0.4232 - val_accuracy: 0.8645\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1194 - accuracy: 0.9628 - val_loss: 0.5877 - val_accuracy: 0.8645\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0508 - accuracy: 0.9903 - val_loss: 0.4849 - val_accuracy: 0.8645\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0778 - accuracy: 0.9742 - val_loss: 0.7285 - val_accuracy: 0.8452\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0488 - accuracy: 0.9838 - val_loss: 0.4804 - val_accuracy: 0.8710\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0461 - accuracy: 0.9838 - val_loss: 0.4157 - val_accuracy: 0.8710\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0239 - accuracy: 0.9952 - val_loss: 0.5959 - val_accuracy: 0.8839\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8943 - val_accuracy: 0.8774\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 3.4430e-04 - accuracy: 1.0000 - val_loss: 1.0855 - val_accuracy: 0.8839\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.0520e-04 - accuracy: 1.0000 - val_loss: 1.0822 - val_accuracy: 0.8774\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 8.3133e-05 - accuracy: 1.0000 - val_loss: 1.0838 - val_accuracy: 0.8774\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 5.9459e-05 - accuracy: 1.0000 - val_loss: 1.1108 - val_accuracy: 0.8839\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.0127e-05 - accuracy: 1.0000 - val_loss: 1.1378 - val_accuracy: 0.8839\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.6794e-05 - accuracy: 1.0000 - val_loss: 1.1578 - val_accuracy: 0.8774\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.7531e-05 - accuracy: 1.0000 - val_loss: 1.1727 - val_accuracy: 0.8774\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.7009e-05 - accuracy: 1.0000 - val_loss: 1.1856 - val_accuracy: 0.8774\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.1281e-05 - accuracy: 1.0000 - val_loss: 1.1974 - val_accuracy: 0.8774\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.3373e-05 - accuracy: 1.0000 - val_loss: 1.2082 - val_accuracy: 0.8774\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 9.7435e-06 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.8774\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0377e-05 - accuracy: 1.0000 - val_loss: 1.2325 - val_accuracy: 0.8774\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.0890e-05 - accuracy: 1.0000 - val_loss: 1.2441 - val_accuracy: 0.8774\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 7.5990e-06 - accuracy: 1.0000 - val_loss: 1.2547 - val_accuracy: 0.8774\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.1027e-06 - accuracy: 1.0000 - val_loss: 1.2650 - val_accuracy: 0.8839\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 8.1605e-06 - accuracy: 1.0000 - val_loss: 1.2761 - val_accuracy: 0.8839\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 9.0042e-06 - accuracy: 1.0000 - val_loss: 1.2880 - val_accuracy: 0.8839\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.8605e-06 - accuracy: 1.0000 - val_loss: 1.2982 - val_accuracy: 0.8839\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 8.1078e-06 - accuracy: 1.0000 - val_loss: 1.3082 - val_accuracy: 0.8839\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.9253e-06 - accuracy: 1.0000 - val_loss: 1.3208 - val_accuracy: 0.8774\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.9889e-06 - accuracy: 1.0000 - val_loss: 1.3334 - val_accuracy: 0.8774\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.6600e-06 - accuracy: 1.0000 - val_loss: 1.3441 - val_accuracy: 0.8774\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.0163e-06 - accuracy: 1.0000 - val_loss: 1.3524 - val_accuracy: 0.8774\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.0113e-06 - accuracy: 1.0000 - val_loss: 1.3598 - val_accuracy: 0.8774\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.6624e-06 - accuracy: 1.0000 - val_loss: 1.3684 - val_accuracy: 0.8774\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.2812e-06 - accuracy: 1.0000 - val_loss: 1.3784 - val_accuracy: 0.8774\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.4463e-06 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.8774\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.2749e-06 - accuracy: 1.0000 - val_loss: 1.3938 - val_accuracy: 0.8774\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.6620e-06 - accuracy: 1.0000 - val_loss: 1.4016 - val_accuracy: 0.8774\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.8443e-06 - accuracy: 1.0000 - val_loss: 1.4077 - val_accuracy: 0.8774\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.8716e-06 - accuracy: 1.0000 - val_loss: 1.4131 - val_accuracy: 0.8774\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.9883e-06 - accuracy: 1.0000 - val_loss: 1.4193 - val_accuracy: 0.8774\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.6574e-06 - accuracy: 1.0000 - val_loss: 1.4275 - val_accuracy: 0.8774\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.7850e-06 - accuracy: 1.0000 - val_loss: 1.4376 - val_accuracy: 0.8774\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.1372e-06 - accuracy: 1.0000 - val_loss: 1.4458 - val_accuracy: 0.8774\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.6933e-06 - accuracy: 1.0000 - val_loss: 1.4525 - val_accuracy: 0.8774\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.5065e-06 - accuracy: 1.0000 - val_loss: 1.4575 - val_accuracy: 0.8774\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.4396e-06 - accuracy: 1.0000 - val_loss: 1.4632 - val_accuracy: 0.8774\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.5338e-06 - accuracy: 1.0000 - val_loss: 1.4695 - val_accuracy: 0.8774\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.7692e-06 - accuracy: 1.0000 - val_loss: 1.4767 - val_accuracy: 0.8839\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.4250e-06 - accuracy: 1.0000 - val_loss: 1.4822 - val_accuracy: 0.8839\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0593e-06 - accuracy: 1.0000 - val_loss: 1.4874 - val_accuracy: 0.8839\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.0764e-06 - accuracy: 1.0000 - val_loss: 1.4941 - val_accuracy: 0.8839\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.2383e-06 - accuracy: 1.0000 - val_loss: 1.4995 - val_accuracy: 0.8839\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.3608e-06 - accuracy: 1.0000 - val_loss: 1.5046 - val_accuracy: 0.8839\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0131e-06 - accuracy: 1.0000 - val_loss: 1.5087 - val_accuracy: 0.8839\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.2634e-07 - accuracy: 1.0000 - val_loss: 1.5125 - val_accuracy: 0.8839\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.1592e-07 - accuracy: 1.0000 - val_loss: 1.5157 - val_accuracy: 0.8839\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 7.7507e-07 - accuracy: 1.0000 - val_loss: 1.5187 - val_accuracy: 0.8839\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.7887e-06 - accuracy: 1.0000 - val_loss: 1.5228 - val_accuracy: 0.8839\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.1164e-06 - accuracy: 1.0000 - val_loss: 1.5286 - val_accuracy: 0.8839\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.8479e-07 - accuracy: 1.0000 - val_loss: 1.5331 - val_accuracy: 0.8839\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.3549e-06 - accuracy: 1.0000 - val_loss: 1.5384 - val_accuracy: 0.8839\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.7180e-07 - accuracy: 1.0000 - val_loss: 1.5438 - val_accuracy: 0.8839\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0985e-06 - accuracy: 1.0000 - val_loss: 1.5483 - val_accuracy: 0.8839\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 9.2642e-07 - accuracy: 1.0000 - val_loss: 1.5525 - val_accuracy: 0.8839\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0957e-06 - accuracy: 1.0000 - val_loss: 1.5577 - val_accuracy: 0.8839\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.4744e-07 - accuracy: 1.0000 - val_loss: 1.5616 - val_accuracy: 0.8839\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.3325e-07 - accuracy: 1.0000 - val_loss: 1.5648 - val_accuracy: 0.8839\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.1581e-06 - accuracy: 1.0000 - val_loss: 1.5687 - val_accuracy: 0.8839\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.2518e-06 - accuracy: 1.0000 - val_loss: 1.5735 - val_accuracy: 0.8839\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.6415e-07 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.8839\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.0992e-06 - accuracy: 1.0000 - val_loss: 1.5836 - val_accuracy: 0.8839\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.5930e-07 - accuracy: 1.0000 - val_loss: 1.5881 - val_accuracy: 0.8839\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.0520e-07 - accuracy: 1.0000 - val_loss: 1.5915 - val_accuracy: 0.8839\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.4820e-07 - accuracy: 1.0000 - val_loss: 1.5953 - val_accuracy: 0.8839\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.6864e-07 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.8839\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.0086e-06 - accuracy: 1.0000 - val_loss: 1.6029 - val_accuracy: 0.8839\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.4945e-06 - accuracy: 1.0000 - val_loss: 1.6073 - val_accuracy: 0.8839\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.2242e-07 - accuracy: 1.0000 - val_loss: 1.6113 - val_accuracy: 0.8839\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 7.5925e-07 - accuracy: 1.0000 - val_loss: 1.6150 - val_accuracy: 0.8839\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.5154e-07 - accuracy: 1.0000 - val_loss: 1.6187 - val_accuracy: 0.8839\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.2664e-07 - accuracy: 1.0000 - val_loss: 1.6225 - val_accuracy: 0.8839\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 9.3557e-07 - accuracy: 1.0000 - val_loss: 1.6266 - val_accuracy: 0.8839\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 7.2482e-07 - accuracy: 1.0000 - val_loss: 1.6308 - val_accuracy: 0.8839\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.8163e-07 - accuracy: 1.0000 - val_loss: 1.6342 - val_accuracy: 0.8839\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.2469e-07 - accuracy: 1.0000 - val_loss: 1.6365 - val_accuracy: 0.8839\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.4370e-07 - accuracy: 1.0000 - val_loss: 1.6388 - val_accuracy: 0.8839\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.6388 - accuracy: 0.8839\n",
            "Test Loss: 1.6387650966644287, Test Accuracy: 0.8838709592819214\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 83ms/step - loss: 0.6145 - accuracy: 0.6753 - val_loss: 0.6188 - val_accuracy: 0.6516\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5725 - accuracy: 0.6931 - val_loss: 0.6048 - val_accuracy: 0.6516\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.5402 - accuracy: 0.6931 - val_loss: 0.5527 - val_accuracy: 0.6516\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4839 - accuracy: 0.6931 - val_loss: 0.4994 - val_accuracy: 0.6516\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4408 - accuracy: 0.7124 - val_loss: 0.5131 - val_accuracy: 0.7290\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.3998 - accuracy: 0.8110 - val_loss: 0.5561 - val_accuracy: 0.7548\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4488 - accuracy: 0.8255 - val_loss: 0.4641 - val_accuracy: 0.7226\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3950 - accuracy: 0.8061 - val_loss: 0.4395 - val_accuracy: 0.8516\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3486 - accuracy: 0.8885 - val_loss: 0.4460 - val_accuracy: 0.8065\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3418 - accuracy: 0.8885 - val_loss: 0.4327 - val_accuracy: 0.8452\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2957 - accuracy: 0.9031 - val_loss: 0.5312 - val_accuracy: 0.8645\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2554 - accuracy: 0.9451 - val_loss: 0.4685 - val_accuracy: 0.8903\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2407 - accuracy: 0.9225 - val_loss: 0.4239 - val_accuracy: 0.8774\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1476 - accuracy: 0.9515 - val_loss: 0.4367 - val_accuracy: 0.8774\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0987 - accuracy: 0.9596 - val_loss: 0.4179 - val_accuracy: 0.8774\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1222 - accuracy: 0.9499 - val_loss: 0.4819 - val_accuracy: 0.8774\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1411 - accuracy: 0.9451 - val_loss: 0.4112 - val_accuracy: 0.8581\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0613 - accuracy: 0.9822 - val_loss: 0.6661 - val_accuracy: 0.8774\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0313 - accuracy: 0.9855 - val_loss: 0.5839 - val_accuracy: 0.8903\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.5884 - val_accuracy: 0.8839\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 0.7080 - val_accuracy: 0.8968\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0266 - accuracy: 0.9935 - val_loss: 1.0628 - val_accuracy: 0.8323\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1577 - accuracy: 0.9499 - val_loss: 0.3940 - val_accuracy: 0.8710\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0794 - accuracy: 0.9790 - val_loss: 0.5911 - val_accuracy: 0.8774\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0259 - accuracy: 0.9935 - val_loss: 0.9093 - val_accuracy: 0.8452\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.9791 - val_accuracy: 0.8710\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0471 - accuracy: 0.9871 - val_loss: 0.7280 - val_accuracy: 0.8903\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0359 - accuracy: 0.9855 - val_loss: 0.5766 - val_accuracy: 0.8645\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0561 - accuracy: 0.9758 - val_loss: 0.7179 - val_accuracy: 0.8194\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0508 - accuracy: 0.9838 - val_loss: 0.6418 - val_accuracy: 0.8903\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0297 - accuracy: 0.9871 - val_loss: 0.5324 - val_accuracy: 0.8839\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 0.8839\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.8774\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0024 - accuracy: 0.9984 - val_loss: 1.2385 - val_accuracy: 0.8710\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0566 - accuracy: 0.9887 - val_loss: 1.1219 - val_accuracy: 0.8258\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.5847 - val_accuracy: 0.8710\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.5847 - val_accuracy: 0.8839\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.8968\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0018 - accuracy: 0.9984 - val_loss: 0.8540 - val_accuracy: 0.8774\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8840 - val_accuracy: 0.8774\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.7575e-05 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.8903\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0014 - accuracy: 0.9984 - val_loss: 0.8927 - val_accuracy: 0.8774\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.1240e-04 - accuracy: 1.0000 - val_loss: 0.9816 - val_accuracy: 0.8710\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.2594e-04 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.8903\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.5571e-05 - accuracy: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.8903\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.1411e-05 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.8903\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.9984e-05 - accuracy: 1.0000 - val_loss: 0.9961 - val_accuracy: 0.8839\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.8458e-05 - accuracy: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.8903\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.6605e-05 - accuracy: 1.0000 - val_loss: 1.0059 - val_accuracy: 0.8903\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.3674e-05 - accuracy: 1.0000 - val_loss: 1.0107 - val_accuracy: 0.8903\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.1838e-05 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 0.8839\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.6236e-05 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.8839\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.0415e-05 - accuracy: 1.0000 - val_loss: 1.0220 - val_accuracy: 0.8839\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.4296e-05 - accuracy: 1.0000 - val_loss: 1.0252 - val_accuracy: 0.8839\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.2388e-05 - accuracy: 1.0000 - val_loss: 1.0281 - val_accuracy: 0.8839\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.5814e-05 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.8839\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 9.9720e-06 - accuracy: 1.0000 - val_loss: 1.0358 - val_accuracy: 0.8839\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0168e-05 - accuracy: 1.0000 - val_loss: 1.0389 - val_accuracy: 0.8839\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.1362e-05 - accuracy: 1.0000 - val_loss: 1.0420 - val_accuracy: 0.8839\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 8.9796e-06 - accuracy: 1.0000 - val_loss: 1.0447 - val_accuracy: 0.8839\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0543e-05 - accuracy: 1.0000 - val_loss: 1.0475 - val_accuracy: 0.8839\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.3101e-06 - accuracy: 1.0000 - val_loss: 1.0501 - val_accuracy: 0.8839\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0419e-05 - accuracy: 1.0000 - val_loss: 1.0527 - val_accuracy: 0.8839\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.1139e-05 - accuracy: 1.0000 - val_loss: 1.0558 - val_accuracy: 0.8839\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.9162e-06 - accuracy: 1.0000 - val_loss: 1.0585 - val_accuracy: 0.8839\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0318e-05 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 0.8839\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.0194e-05 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.8903\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.2901e-05 - accuracy: 1.0000 - val_loss: 1.0676 - val_accuracy: 0.8903\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.9857e-06 - accuracy: 1.0000 - val_loss: 1.0706 - val_accuracy: 0.8903\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.7283e-06 - accuracy: 1.0000 - val_loss: 1.0731 - val_accuracy: 0.8903\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.2878e-06 - accuracy: 1.0000 - val_loss: 1.0755 - val_accuracy: 0.8903\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.2340e-06 - accuracy: 1.0000 - val_loss: 1.0777 - val_accuracy: 0.8903\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 7.3628e-06 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.8903\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.9906e-06 - accuracy: 1.0000 - val_loss: 1.0832 - val_accuracy: 0.8903\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.4591e-06 - accuracy: 1.0000 - val_loss: 1.0856 - val_accuracy: 0.8903\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.1234e-06 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.8903\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 9.4239e-06 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.8903\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.3852e-06 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.8903\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 4.7802e-06 - accuracy: 1.0000 - val_loss: 1.0956 - val_accuracy: 0.8903\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.6078e-06 - accuracy: 1.0000 - val_loss: 1.0979 - val_accuracy: 0.8903\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.4475e-06 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.8903\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.9906e-06 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.8903\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.6063e-06 - accuracy: 1.0000 - val_loss: 1.1036 - val_accuracy: 0.8903\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.6200e-06 - accuracy: 1.0000 - val_loss: 1.1053 - val_accuracy: 0.8903\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.5239e-06 - accuracy: 1.0000 - val_loss: 1.1072 - val_accuracy: 0.8839\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.2240e-06 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.8839\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.9753e-06 - accuracy: 1.0000 - val_loss: 1.1115 - val_accuracy: 0.8839\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.5166e-06 - accuracy: 1.0000 - val_loss: 1.1136 - val_accuracy: 0.8839\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.8814e-06 - accuracy: 1.0000 - val_loss: 1.1154 - val_accuracy: 0.8839\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.8386e-06 - accuracy: 1.0000 - val_loss: 1.1170 - val_accuracy: 0.8839\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.0504e-06 - accuracy: 1.0000 - val_loss: 1.1190 - val_accuracy: 0.8839\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.3497e-06 - accuracy: 1.0000 - val_loss: 1.1209 - val_accuracy: 0.8839\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.5018e-06 - accuracy: 1.0000 - val_loss: 1.1232 - val_accuracy: 0.8839\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.8067e-06 - accuracy: 1.0000 - val_loss: 1.1251 - val_accuracy: 0.8839\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.1478e-06 - accuracy: 1.0000 - val_loss: 1.1269 - val_accuracy: 0.8839\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.8093e-06 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.8839\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.5186e-06 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.8839\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.1465e-06 - accuracy: 1.0000 - val_loss: 1.1314 - val_accuracy: 0.8839\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.9405e-06 - accuracy: 1.0000 - val_loss: 1.1331 - val_accuracy: 0.8839\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.2836e-06 - accuracy: 1.0000 - val_loss: 1.1345 - val_accuracy: 0.8839\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1345 - accuracy: 0.8839\n",
            "Test Loss: 1.1345313787460327, Test Accuracy: 0.8838709592819214\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 83ms/step - loss: 0.6610 - accuracy: 0.6591 - val_loss: 0.6196 - val_accuracy: 0.6968\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.5951 - accuracy: 0.6817 - val_loss: 0.5842 - val_accuracy: 0.6968\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5645 - accuracy: 0.6817 - val_loss: 0.5238 - val_accuracy: 0.6968\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4996 - accuracy: 0.6817 - val_loss: 0.6447 - val_accuracy: 0.6968\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5817 - accuracy: 0.6817 - val_loss: 0.5013 - val_accuracy: 0.6968\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4768 - accuracy: 0.6817 - val_loss: 0.4749 - val_accuracy: 0.6968\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.4859 - accuracy: 0.7189 - val_loss: 0.4221 - val_accuracy: 0.7742\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4296 - accuracy: 0.7916 - val_loss: 0.3997 - val_accuracy: 0.8194\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4027 - accuracy: 0.8320 - val_loss: 0.3919 - val_accuracy: 0.8194\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3912 - accuracy: 0.8433 - val_loss: 0.4153 - val_accuracy: 0.8516\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3553 - accuracy: 0.8740 - val_loss: 0.4078 - val_accuracy: 0.8581\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3452 - accuracy: 0.8708 - val_loss: 0.5782 - val_accuracy: 0.5677\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4203 - accuracy: 0.8094 - val_loss: 0.4481 - val_accuracy: 0.8000\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.3523 - accuracy: 0.8901 - val_loss: 0.3821 - val_accuracy: 0.7935\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2792 - accuracy: 0.9128 - val_loss: 0.3693 - val_accuracy: 0.8516\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1588 - accuracy: 0.9451 - val_loss: 0.3660 - val_accuracy: 0.8774\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2204 - accuracy: 0.9063 - val_loss: 0.3323 - val_accuracy: 0.8581\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1760 - accuracy: 0.9354 - val_loss: 0.4446 - val_accuracy: 0.8323\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1336 - accuracy: 0.9499 - val_loss: 0.2950 - val_accuracy: 0.8710\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0959 - accuracy: 0.9709 - val_loss: 0.4358 - val_accuracy: 0.8710\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.5206 - val_accuracy: 0.8710\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 0.3461 - val_accuracy: 0.8710\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.6923 - val_accuracy: 0.8516\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0163 - accuracy: 0.9984 - val_loss: 0.4671 - val_accuracy: 0.8968\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0431 - accuracy: 0.9871 - val_loss: 1.2290 - val_accuracy: 0.7677\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0965 - accuracy: 0.9612 - val_loss: 0.3400 - val_accuracy: 0.8774\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0599 - accuracy: 0.9838 - val_loss: 0.2859 - val_accuracy: 0.9097\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0127 - accuracy: 0.9935 - val_loss: 0.4293 - val_accuracy: 0.9032\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0392 - val_accuracy: 0.8387\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9954 - val_accuracy: 0.8581\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 8.2370e-05 - accuracy: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.8581\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.6666e-04 - accuracy: 1.0000 - val_loss: 1.7279 - val_accuracy: 0.8323\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.2071e-04 - accuracy: 1.0000 - val_loss: 1.7059 - val_accuracy: 0.8387\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.6548e-05 - accuracy: 1.0000 - val_loss: 1.4493 - val_accuracy: 0.8452\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.5610e-05 - accuracy: 1.0000 - val_loss: 1.3427 - val_accuracy: 0.8516\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.2572e-05 - accuracy: 1.0000 - val_loss: 1.2907 - val_accuracy: 0.8516\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 8.6822e-06 - accuracy: 1.0000 - val_loss: 1.2660 - val_accuracy: 0.8516\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.7220e-06 - accuracy: 1.0000 - val_loss: 1.2511 - val_accuracy: 0.8516\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 5.1605e-06 - accuracy: 1.0000 - val_loss: 1.2411 - val_accuracy: 0.8516\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.6002e-06 - accuracy: 1.0000 - val_loss: 1.2330 - val_accuracy: 0.8452\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.7093e-06 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.8452\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.1681e-06 - accuracy: 1.0000 - val_loss: 1.2161 - val_accuracy: 0.8452\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.9481e-06 - accuracy: 1.0000 - val_loss: 1.2108 - val_accuracy: 0.8452\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.1048e-06 - accuracy: 1.0000 - val_loss: 1.2045 - val_accuracy: 0.8452\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.0945e-06 - accuracy: 1.0000 - val_loss: 1.1981 - val_accuracy: 0.8452\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.9572e-06 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.8452\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.8169e-06 - accuracy: 1.0000 - val_loss: 1.1872 - val_accuracy: 0.8452\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.7256e-06 - accuracy: 1.0000 - val_loss: 1.1834 - val_accuracy: 0.8452\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.0402e-06 - accuracy: 1.0000 - val_loss: 1.1781 - val_accuracy: 0.8452\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.1823e-06 - accuracy: 1.0000 - val_loss: 1.1741 - val_accuracy: 0.8452\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.6090e-06 - accuracy: 1.0000 - val_loss: 1.1691 - val_accuracy: 0.8452\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.4817e-06 - accuracy: 1.0000 - val_loss: 1.1667 - val_accuracy: 0.8452\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.4701e-06 - accuracy: 1.0000 - val_loss: 1.1634 - val_accuracy: 0.8452\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.8873e-06 - accuracy: 1.0000 - val_loss: 1.1621 - val_accuracy: 0.8452\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.2222e-06 - accuracy: 1.0000 - val_loss: 1.1591 - val_accuracy: 0.8452\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.1086e-06 - accuracy: 1.0000 - val_loss: 1.1568 - val_accuracy: 0.8516\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.4665e-06 - accuracy: 1.0000 - val_loss: 1.1544 - val_accuracy: 0.8516\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.0359e-06 - accuracy: 1.0000 - val_loss: 1.1510 - val_accuracy: 0.8516\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.8551e-06 - accuracy: 1.0000 - val_loss: 1.1488 - val_accuracy: 0.8516\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.4915e-06 - accuracy: 1.0000 - val_loss: 1.1469 - val_accuracy: 0.8581\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.3483e-06 - accuracy: 1.0000 - val_loss: 1.1441 - val_accuracy: 0.8581\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.4464e-06 - accuracy: 1.0000 - val_loss: 1.1404 - val_accuracy: 0.8581\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.9342e-06 - accuracy: 1.0000 - val_loss: 1.1381 - val_accuracy: 0.8581\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.4518e-06 - accuracy: 1.0000 - val_loss: 1.1335 - val_accuracy: 0.8581\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.1164e-06 - accuracy: 1.0000 - val_loss: 1.1318 - val_accuracy: 0.8581\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.3515e-06 - accuracy: 1.0000 - val_loss: 1.1298 - val_accuracy: 0.8581\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.5657e-06 - accuracy: 1.0000 - val_loss: 1.1275 - val_accuracy: 0.8581\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 3.0891e-06 - accuracy: 1.0000 - val_loss: 1.1247 - val_accuracy: 0.8581\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.9311e-06 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.8581\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 4.1430e-06 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.8581\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.5448e-06 - accuracy: 1.0000 - val_loss: 1.1176 - val_accuracy: 0.8581\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.5574e-06 - accuracy: 1.0000 - val_loss: 1.1157 - val_accuracy: 0.8581\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.8342e-06 - accuracy: 1.0000 - val_loss: 1.1131 - val_accuracy: 0.8581\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.9004e-06 - accuracy: 1.0000 - val_loss: 1.1120 - val_accuracy: 0.8581\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.7374e-06 - accuracy: 1.0000 - val_loss: 1.1110 - val_accuracy: 0.8581\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.9434e-06 - accuracy: 1.0000 - val_loss: 1.1097 - val_accuracy: 0.8581\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.0215e-06 - accuracy: 1.0000 - val_loss: 1.1074 - val_accuracy: 0.8581\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.6573e-06 - accuracy: 1.0000 - val_loss: 1.1060 - val_accuracy: 0.8581\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.4724e-06 - accuracy: 1.0000 - val_loss: 1.1042 - val_accuracy: 0.8581\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.4176e-06 - accuracy: 1.0000 - val_loss: 1.1027 - val_accuracy: 0.8581\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.8552e-06 - accuracy: 1.0000 - val_loss: 1.1011 - val_accuracy: 0.8581\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.0739e-06 - accuracy: 1.0000 - val_loss: 1.1000 - val_accuracy: 0.8581\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.8740e-06 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.8581\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.6748e-06 - accuracy: 1.0000 - val_loss: 1.0970 - val_accuracy: 0.8581\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.4739e-06 - accuracy: 1.0000 - val_loss: 1.0960 - val_accuracy: 0.8645\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.2946e-06 - accuracy: 1.0000 - val_loss: 1.0943 - val_accuracy: 0.8645\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.9160e-06 - accuracy: 1.0000 - val_loss: 1.0931 - val_accuracy: 0.8645\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.6723e-06 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.8645\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.9666e-06 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.8645\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.1158e-06 - accuracy: 1.0000 - val_loss: 1.0926 - val_accuracy: 0.8645\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.9784e-06 - accuracy: 1.0000 - val_loss: 1.0913 - val_accuracy: 0.8645\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.1831e-06 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.8645\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.6583e-06 - accuracy: 1.0000 - val_loss: 1.0896 - val_accuracy: 0.8645\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.5339e-06 - accuracy: 1.0000 - val_loss: 1.0887 - val_accuracy: 0.8645\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 9.3659e-07 - accuracy: 1.0000 - val_loss: 1.0876 - val_accuracy: 0.8645\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.3032e-06 - accuracy: 1.0000 - val_loss: 1.0870 - val_accuracy: 0.8645\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.7593e-06 - accuracy: 1.0000 - val_loss: 1.0860 - val_accuracy: 0.8645\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.4971e-06 - accuracy: 1.0000 - val_loss: 1.0850 - val_accuracy: 0.8645\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.4816e-06 - accuracy: 1.0000 - val_loss: 1.0851 - val_accuracy: 0.8645\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 9.8274e-07 - accuracy: 1.0000 - val_loss: 1.0849 - val_accuracy: 0.8645\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0849 - accuracy: 0.8645\n",
            "Test Loss: 1.0849214792251587, Test Accuracy: 0.8645161390304565\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 6s 151ms/step - loss: 0.6593 - accuracy: 0.6403 - val_loss: 0.5555 - val_accuracy: 0.7273\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.6058 - accuracy: 0.6742 - val_loss: 0.5531 - val_accuracy: 0.7273\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5719 - accuracy: 0.6742 - val_loss: 0.5307 - val_accuracy: 0.7273\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5305 - accuracy: 0.6742 - val_loss: 0.5104 - val_accuracy: 0.7273\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5355 - accuracy: 0.6742 - val_loss: 0.5340 - val_accuracy: 0.7013\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.4936 - accuracy: 0.7226 - val_loss: 0.4918 - val_accuracy: 0.7208\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4987 - accuracy: 0.7339 - val_loss: 0.5606 - val_accuracy: 0.7078\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4730 - accuracy: 0.7532 - val_loss: 0.5122 - val_accuracy: 0.7338\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4487 - accuracy: 0.7903 - val_loss: 0.4442 - val_accuracy: 0.8052\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4025 - accuracy: 0.8290 - val_loss: 0.4606 - val_accuracy: 0.7727\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4144 - accuracy: 0.8081 - val_loss: 0.4594 - val_accuracy: 0.7987\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3624 - accuracy: 0.8694 - val_loss: 0.5830 - val_accuracy: 0.7792\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4001 - accuracy: 0.8387 - val_loss: 0.4620 - val_accuracy: 0.7792\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3279 - accuracy: 0.8839 - val_loss: 0.4968 - val_accuracy: 0.8377\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2586 - accuracy: 0.9306 - val_loss: 0.4433 - val_accuracy: 0.8766\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1610 - accuracy: 0.9484 - val_loss: 1.1247 - val_accuracy: 0.7727\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2448 - accuracy: 0.8968 - val_loss: 0.4443 - val_accuracy: 0.8247\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1380 - accuracy: 0.9484 - val_loss: 0.5055 - val_accuracy: 0.8896\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0632 - accuracy: 0.9774 - val_loss: 0.8388 - val_accuracy: 0.8506\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1403 - accuracy: 0.9468 - val_loss: 0.5276 - val_accuracy: 0.8506\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1381 - accuracy: 0.9403 - val_loss: 0.5162 - val_accuracy: 0.8571\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0456 - accuracy: 0.9871 - val_loss: 0.7655 - val_accuracy: 0.8701\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0207 - accuracy: 0.9952 - val_loss: 0.9080 - val_accuracy: 0.8571\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2265 - accuracy: 0.9387 - val_loss: 0.4298 - val_accuracy: 0.8571\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1413 - accuracy: 0.9565 - val_loss: 0.4664 - val_accuracy: 0.8571\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0883 - accuracy: 0.9774 - val_loss: 0.7035 - val_accuracy: 0.8636\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3530 - accuracy: 0.8645 - val_loss: 0.4446 - val_accuracy: 0.8377\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1763 - accuracy: 0.9419 - val_loss: 0.4358 - val_accuracy: 0.8636\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0565 - accuracy: 0.9871 - val_loss: 0.8882 - val_accuracy: 0.8442\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0143 - accuracy: 0.9935 - val_loss: 1.0475 - val_accuracy: 0.8896\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.9176e-04 - accuracy: 1.0000 - val_loss: 1.1789 - val_accuracy: 0.8831\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 1.2139 - val_accuracy: 0.8766\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 1.3319 - val_accuracy: 0.8701\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 1.7505 - val_accuracy: 0.8247\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 1.2985 - val_accuracy: 0.8766\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0240 - accuracy: 0.9935 - val_loss: 1.5527 - val_accuracy: 0.7987\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 1.0218 - val_accuracy: 0.8571\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 1.0798 - val_accuracy: 0.8506\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0105 - accuracy: 0.9935 - val_loss: 1.0236 - val_accuracy: 0.8766\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.9730 - val_accuracy: 0.8766\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0107 - accuracy: 0.9935 - val_loss: 0.6057 - val_accuracy: 0.9286\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 1.2582 - val_accuracy: 0.8701\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 1.1432 - val_accuracy: 0.8052\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 1.0303 - val_accuracy: 0.8701\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0547 - accuracy: 0.9839 - val_loss: 0.7112 - val_accuracy: 0.8312\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.8571\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8898 - val_accuracy: 0.8506\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.4260e-04 - accuracy: 1.0000 - val_loss: 1.0547 - val_accuracy: 0.8506\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.4981e-04 - accuracy: 1.0000 - val_loss: 1.1465 - val_accuracy: 0.8377\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.0082e-04 - accuracy: 1.0000 - val_loss: 1.1825 - val_accuracy: 0.8442\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 8.4653e-05 - accuracy: 1.0000 - val_loss: 1.1931 - val_accuracy: 0.8506\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.3987e-05 - accuracy: 1.0000 - val_loss: 1.1980 - val_accuracy: 0.8571\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.6616e-05 - accuracy: 1.0000 - val_loss: 1.2025 - val_accuracy: 0.8506\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 5.1654e-05 - accuracy: 1.0000 - val_loss: 1.2075 - val_accuracy: 0.8571\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.4013e-05 - accuracy: 1.0000 - val_loss: 1.2174 - val_accuracy: 0.8571\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.9335e-05 - accuracy: 1.0000 - val_loss: 1.2253 - val_accuracy: 0.8571\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.8285e-05 - accuracy: 1.0000 - val_loss: 1.2317 - val_accuracy: 0.8571\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.8616e-05 - accuracy: 1.0000 - val_loss: 1.2381 - val_accuracy: 0.8571\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.4073e-05 - accuracy: 1.0000 - val_loss: 1.2450 - val_accuracy: 0.8571\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.5799e-05 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.8506\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.0687e-05 - accuracy: 1.0000 - val_loss: 1.2586 - val_accuracy: 0.8506\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.7716e-05 - accuracy: 1.0000 - val_loss: 1.2659 - val_accuracy: 0.8506\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.0285e-05 - accuracy: 1.0000 - val_loss: 1.2733 - val_accuracy: 0.8506\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.0585e-05 - accuracy: 1.0000 - val_loss: 1.2815 - val_accuracy: 0.8506\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.1320e-05 - accuracy: 1.0000 - val_loss: 1.2898 - val_accuracy: 0.8506\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.2975e-05 - accuracy: 1.0000 - val_loss: 1.2974 - val_accuracy: 0.8506\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0474e-05 - accuracy: 1.0000 - val_loss: 1.3033 - val_accuracy: 0.8506\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 7.1532e-06 - accuracy: 1.0000 - val_loss: 1.3089 - val_accuracy: 0.8506\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.2949e-05 - accuracy: 1.0000 - val_loss: 1.3141 - val_accuracy: 0.8506\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 9.4916e-06 - accuracy: 1.0000 - val_loss: 1.3206 - val_accuracy: 0.8506\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.4395e-05 - accuracy: 1.0000 - val_loss: 1.3277 - val_accuracy: 0.8506\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.2993e-05 - accuracy: 1.0000 - val_loss: 1.3355 - val_accuracy: 0.8571\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.4296e-06 - accuracy: 1.0000 - val_loss: 1.3423 - val_accuracy: 0.8571\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.0219e-05 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.8571\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.0201e-05 - accuracy: 1.0000 - val_loss: 1.3547 - val_accuracy: 0.8571\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.8463e-06 - accuracy: 1.0000 - val_loss: 1.3620 - val_accuracy: 0.8571\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.4244e-05 - accuracy: 1.0000 - val_loss: 1.3731 - val_accuracy: 0.8571\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 7.7835e-06 - accuracy: 1.0000 - val_loss: 1.3829 - val_accuracy: 0.8571\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 8.9844e-06 - accuracy: 1.0000 - val_loss: 1.3918 - val_accuracy: 0.8571\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.3436e-06 - accuracy: 1.0000 - val_loss: 1.3986 - val_accuracy: 0.8636\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.8109e-06 - accuracy: 1.0000 - val_loss: 1.4035 - val_accuracy: 0.8636\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.3316e-06 - accuracy: 1.0000 - val_loss: 1.4093 - val_accuracy: 0.8636\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 6.6078e-06 - accuracy: 1.0000 - val_loss: 1.4155 - val_accuracy: 0.8636\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.2737e-06 - accuracy: 1.0000 - val_loss: 1.4218 - val_accuracy: 0.8636\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.6572e-06 - accuracy: 1.0000 - val_loss: 1.4274 - val_accuracy: 0.8636\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.3069e-06 - accuracy: 1.0000 - val_loss: 1.4334 - val_accuracy: 0.8636\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.1371e-06 - accuracy: 1.0000 - val_loss: 1.4394 - val_accuracy: 0.8636\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.6523e-06 - accuracy: 1.0000 - val_loss: 1.4443 - val_accuracy: 0.8636\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.1878e-06 - accuracy: 1.0000 - val_loss: 1.4491 - val_accuracy: 0.8636\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 5.7785e-06 - accuracy: 1.0000 - val_loss: 1.4558 - val_accuracy: 0.8636\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.7101e-06 - accuracy: 1.0000 - val_loss: 1.4611 - val_accuracy: 0.8636\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 3.0324e-06 - accuracy: 1.0000 - val_loss: 1.4661 - val_accuracy: 0.8636\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.5763e-06 - accuracy: 1.0000 - val_loss: 1.4707 - val_accuracy: 0.8636\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.9503e-06 - accuracy: 1.0000 - val_loss: 1.4751 - val_accuracy: 0.8636\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.6156e-06 - accuracy: 1.0000 - val_loss: 1.4798 - val_accuracy: 0.8636\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.3695e-06 - accuracy: 1.0000 - val_loss: 1.4842 - val_accuracy: 0.8636\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 6.4008e-06 - accuracy: 1.0000 - val_loss: 1.4898 - val_accuracy: 0.8636\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 2.4805e-06 - accuracy: 1.0000 - val_loss: 1.4959 - val_accuracy: 0.8636\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 4.0643e-06 - accuracy: 1.0000 - val_loss: 1.5017 - val_accuracy: 0.8636\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 2.1030e-06 - accuracy: 1.0000 - val_loss: 1.5073 - val_accuracy: 0.8636\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.5073 - accuracy: 0.8636\n",
            "Test Loss: 1.5072619915008545, Test Accuracy: 0.8636363744735718\n",
            "\n",
            "Average Accuracy Across All Folds: 0.8707917928695679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 규제 추가\n"
      ],
      "metadata": {
        "id": "U5JgflcDGMBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdamW + Random 증강 + L2규제 + dropout 3개 :0.825571846961975"
      ],
      "metadata": {
        "id": "61siA6GjHb7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import AdamW\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "id": "2Le-6nUE3XBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3503c7b2-4a96-4136-941d-a3141d942b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 16s 105ms/step - loss: 48.7425 - accuracy: 0.6672 - val_loss: 46.2649 - val_accuracy: 0.6323\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.3580 - accuracy: 0.6979 - val_loss: 41.9837 - val_accuracy: 0.6323\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 40.1918 - accuracy: 0.6979 - val_loss: 37.9993 - val_accuracy: 0.6323\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 36.3433 - accuracy: 0.6979 - val_loss: 34.3142 - val_accuracy: 0.6323\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 32.8182 - accuracy: 0.6979 - val_loss: 31.1015 - val_accuracy: 0.6323\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 29.6872 - accuracy: 0.6979 - val_loss: 27.9880 - val_accuracy: 0.6323\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 26.6702 - accuracy: 0.6979 - val_loss: 25.1647 - val_accuracy: 0.6323\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 23.9643 - accuracy: 0.6979 - val_loss: 22.6331 - val_accuracy: 0.6323\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.5524 - accuracy: 0.7237 - val_loss: 20.3517 - val_accuracy: 0.6903\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 19.3588 - accuracy: 0.7948 - val_loss: 18.3144 - val_accuracy: 0.7871\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 17.4314 - accuracy: 0.8142 - val_loss: 16.5543 - val_accuracy: 0.6710\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.7477 - accuracy: 0.6979 - val_loss: 14.7536 - val_accuracy: 0.7355\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.0695 - accuracy: 0.7512 - val_loss: 13.2115 - val_accuracy: 0.7290\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 12.5692 - accuracy: 0.7754 - val_loss: 11.8544 - val_accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 11.2726 - accuracy: 0.7851 - val_loss: 10.6366 - val_accuracy: 0.8258\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.0333 - accuracy: 0.8530 - val_loss: 9.5177 - val_accuracy: 0.7935\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 8.9523 - accuracy: 0.8675 - val_loss: 8.5397 - val_accuracy: 0.8129\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.9849 - accuracy: 0.8934 - val_loss: 7.7759 - val_accuracy: 0.7613\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.1860 - accuracy: 0.8481 - val_loss: 6.8543 - val_accuracy: 0.8065\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.3986 - accuracy: 0.8805 - val_loss: 6.1860 - val_accuracy: 0.7871\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.6756 - accuracy: 0.8901 - val_loss: 5.4488 - val_accuracy: 0.8516\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.0817 - accuracy: 0.9128 - val_loss: 4.8946 - val_accuracy: 0.7613\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.5133 - accuracy: 0.8950 - val_loss: 4.3564 - val_accuracy: 0.8516\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.9245 - accuracy: 0.9564 - val_loss: 4.5653 - val_accuracy: 0.8129\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6275 - accuracy: 0.9176 - val_loss: 3.5686 - val_accuracy: 0.7097\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.2683 - accuracy: 0.8530 - val_loss: 3.1304 - val_accuracy: 0.8129\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.7795 - accuracy: 0.9338 - val_loss: 3.5520 - val_accuracy: 0.7355\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.5018 - accuracy: 0.9160 - val_loss: 2.5609 - val_accuracy: 0.8194\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.1864 - accuracy: 0.9548 - val_loss: 2.4680 - val_accuracy: 0.8258\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.8948 - accuracy: 0.9742 - val_loss: 2.1528 - val_accuracy: 0.8581\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.6642 - accuracy: 0.9838 - val_loss: 2.2247 - val_accuracy: 0.8645\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5433 - accuracy: 0.9435 - val_loss: 1.7971 - val_accuracy: 0.8387\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3186 - accuracy: 0.9758 - val_loss: 1.6628 - val_accuracy: 0.8516\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.1332 - accuracy: 0.9935 - val_loss: 1.6208 - val_accuracy: 0.8645\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9943 - accuracy: 0.9952 - val_loss: 1.7141 - val_accuracy: 0.8323\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.9570 - accuracy: 0.9709 - val_loss: 1.4664 - val_accuracy: 0.8258\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8302 - accuracy: 0.9855 - val_loss: 1.4267 - val_accuracy: 0.8194\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7439 - accuracy: 0.9742 - val_loss: 1.1412 - val_accuracy: 0.8516\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6292 - accuracy: 0.9935 - val_loss: 1.3203 - val_accuracy: 0.8194\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5412 - accuracy: 0.9984 - val_loss: 1.5085 - val_accuracy: 0.8452\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4768 - accuracy: 1.0000 - val_loss: 1.2894 - val_accuracy: 0.8387\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4210 - accuracy: 1.0000 - val_loss: 1.1554 - val_accuracy: 0.8581\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3719 - accuracy: 1.0000 - val_loss: 1.1798 - val_accuracy: 0.8452\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3290 - accuracy: 1.0000 - val_loss: 1.1850 - val_accuracy: 0.8452\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2914 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 0.8452\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2582 - accuracy: 1.0000 - val_loss: 1.1054 - val_accuracy: 0.8452\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2290 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.8516\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2032 - accuracy: 1.0000 - val_loss: 1.0726 - val_accuracy: 0.8516\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1804 - accuracy: 1.0000 - val_loss: 1.0994 - val_accuracy: 0.8516\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1602 - accuracy: 1.0000 - val_loss: 1.1058 - val_accuracy: 0.8516\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1424 - accuracy: 1.0000 - val_loss: 1.1095 - val_accuracy: 0.8516\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1267 - accuracy: 1.0000 - val_loss: 1.1032 - val_accuracy: 0.8516\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1128 - accuracy: 1.0000 - val_loss: 1.0849 - val_accuracy: 0.8452\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1004 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.8516\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 0.8516\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 1.0106 - val_accuracy: 0.8516\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.8516\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.9456 - val_accuracy: 0.8516\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.8516\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.8516\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.9821 - val_accuracy: 0.8516\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 1.0503 - val_accuracy: 0.8452\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.8516\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.8581\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.1333 - val_accuracy: 0.8387\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.8581\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.8581\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.9880 - val_accuracy: 0.8581\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.9589 - val_accuracy: 0.8581\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.8581\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.0195 - val_accuracy: 0.8581\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.9929 - val_accuracy: 0.8581\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.1021 - val_accuracy: 0.8387\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.8645\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.8645\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.0306 - val_accuracy: 0.8710\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.8645\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.9757 - val_accuracy: 0.8710\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.9292 - val_accuracy: 0.8710\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.8710\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.8710\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9023 - val_accuracy: 0.8774\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9791 - val_accuracy: 0.8710\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.8710\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9162 - val_accuracy: 0.8774\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.9328 - val_accuracy: 0.8581\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9868 - val_accuracy: 0.8774\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.8516\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.8710\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9996 - val_accuracy: 0.8839\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2834 - val_accuracy: 0.8710\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2733 - val_accuracy: 0.8645\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1302 - val_accuracy: 0.8710\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0182 - val_accuracy: 0.8710\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.8645\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.8710\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.8710\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0077 - val_accuracy: 0.8645\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9667 - val_accuracy: 0.8645\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9341 - val_accuracy: 0.8645\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9341 - accuracy: 0.8645\n",
            "Test Loss: 0.9340657591819763, Test Accuracy: 0.8645161390304565\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 49ms/step - loss: 48.6350 - accuracy: 0.6656 - val_loss: 45.9498 - val_accuracy: 0.7161\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 44.0749 - accuracy: 0.6769 - val_loss: 41.6094 - val_accuracy: 0.7161\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 39.8281 - accuracy: 0.6769 - val_loss: 37.5100 - val_accuracy: 0.7161\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 35.9163 - accuracy: 0.6898 - val_loss: 33.8653 - val_accuracy: 0.8387\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 32.3782 - accuracy: 0.7593 - val_loss: 30.4955 - val_accuracy: 0.8581\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 29.1070 - accuracy: 0.7997 - val_loss: 27.3496 - val_accuracy: 0.8452\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 26.1722 - accuracy: 0.8142 - val_loss: 24.5925 - val_accuracy: 0.8387\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 23.4792 - accuracy: 0.8449 - val_loss: 22.0610 - val_accuracy: 0.8710\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.0509 - accuracy: 0.8530 - val_loss: 19.7696 - val_accuracy: 0.8516\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 18.8921 - accuracy: 0.8368 - val_loss: 17.8573 - val_accuracy: 0.7871\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 16.8656 - accuracy: 0.8853 - val_loss: 15.9107 - val_accuracy: 0.8581\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.0797 - accuracy: 0.9192 - val_loss: 14.1948 - val_accuracy: 0.8516\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.4495 - accuracy: 0.9176 - val_loss: 12.9246 - val_accuracy: 0.8581\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 11.9933 - accuracy: 0.9386 - val_loss: 11.3482 - val_accuracy: 0.8516\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.6393 - accuracy: 0.9645 - val_loss: 10.2794 - val_accuracy: 0.8903\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.3852 - accuracy: 0.9725 - val_loss: 9.0499 - val_accuracy: 0.8774\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.6901 - accuracy: 0.8158 - val_loss: 8.0843 - val_accuracy: 0.8452\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.6582 - accuracy: 0.8708 - val_loss: 7.1656 - val_accuracy: 0.8839\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.7229 - accuracy: 0.9435 - val_loss: 6.5270 - val_accuracy: 0.8581\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.9075 - accuracy: 0.9661 - val_loss: 5.7223 - val_accuracy: 0.8839\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.2344 - accuracy: 0.9693 - val_loss: 5.0729 - val_accuracy: 0.8839\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.5962 - accuracy: 0.9887 - val_loss: 4.7089 - val_accuracy: 0.8710\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.0727 - accuracy: 0.9838 - val_loss: 4.2656 - val_accuracy: 0.8645\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6010 - accuracy: 0.9822 - val_loss: 3.8112 - val_accuracy: 0.8581\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.1715 - accuracy: 0.9935 - val_loss: 3.4047 - val_accuracy: 0.8774\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.7978 - accuracy: 0.9919 - val_loss: 3.1744 - val_accuracy: 0.9032\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.5338 - accuracy: 0.9725 - val_loss: 2.7888 - val_accuracy: 0.8839\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.3713 - accuracy: 0.9273 - val_loss: 2.3034 - val_accuracy: 0.8710\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.9752 - accuracy: 0.9742 - val_loss: 2.1971 - val_accuracy: 0.8710\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7048 - accuracy: 0.9952 - val_loss: 2.5775 - val_accuracy: 0.8839\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.5492 - accuracy: 0.9790 - val_loss: 1.9099 - val_accuracy: 0.8839\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3819 - accuracy: 0.9790 - val_loss: 1.5699 - val_accuracy: 0.8581\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1826 - accuracy: 0.9968 - val_loss: 1.5593 - val_accuracy: 0.8774\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0279 - accuracy: 0.9968 - val_loss: 1.6662 - val_accuracy: 0.8710\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.9329 - accuracy: 0.9871 - val_loss: 1.2711 - val_accuracy: 0.8839\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.8213 - accuracy: 0.9871 - val_loss: 1.4541 - val_accuracy: 0.8645\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7184 - accuracy: 0.9935 - val_loss: 1.0882 - val_accuracy: 0.8839\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6194 - accuracy: 1.0000 - val_loss: 1.0608 - val_accuracy: 0.8774\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5407 - accuracy: 1.0000 - val_loss: 1.2540 - val_accuracy: 0.8645\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4753 - accuracy: 1.0000 - val_loss: 1.2902 - val_accuracy: 0.8516\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4183 - accuracy: 1.0000 - val_loss: 1.2221 - val_accuracy: 0.8516\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3680 - accuracy: 1.0000 - val_loss: 1.1247 - val_accuracy: 0.8710\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3238 - accuracy: 1.0000 - val_loss: 1.0466 - val_accuracy: 0.8645\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2851 - accuracy: 1.0000 - val_loss: 1.0003 - val_accuracy: 0.8645\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2511 - accuracy: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.8645\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.9838 - val_accuracy: 0.8645\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1948 - accuracy: 1.0000 - val_loss: 0.9841 - val_accuracy: 0.8645\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1717 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.8645\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1515 - accuracy: 1.0000 - val_loss: 0.9256 - val_accuracy: 0.8645\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1337 - accuracy: 1.0000 - val_loss: 0.8877 - val_accuracy: 0.8645\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1181 - accuracy: 1.0000 - val_loss: 0.8520 - val_accuracy: 0.8645\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 0.8320 - val_accuracy: 0.8645\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.8645\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.7809 - val_accuracy: 0.8645\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8645\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.8710\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.7846 - val_accuracy: 0.8645\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.7665 - val_accuracy: 0.8645\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.7888 - val_accuracy: 0.8645\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 0.8645\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.7685 - val_accuracy: 0.8645\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.8645\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.8581\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8645\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8645\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8710\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.8645\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.7375 - val_accuracy: 0.8645\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.8645\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.8645\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.8710\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8710\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8710\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8645\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.8710\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.8710\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8645\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6580 - val_accuracy: 0.8710\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.8645\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8645\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8645\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.8710\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8710\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 0.8710\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.8710\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8710\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8710\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.8710\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9706 - val_accuracy: 0.8710\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9032 - val_accuracy: 0.8710\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8248 - val_accuracy: 0.8774\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7711 - val_accuracy: 0.8710\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7671 - val_accuracy: 0.8710\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7630 - val_accuracy: 0.8710\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8710\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8710\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8100 - val_accuracy: 0.8774\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 0.8710\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.8774\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8774\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7096 - accuracy: 0.8774\n",
            "Test Loss: 0.7095650434494019, Test Accuracy: 0.8774193525314331\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 50ms/step - loss: 48.6509 - accuracy: 0.6721 - val_loss: 46.1275 - val_accuracy: 0.6516\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.2087 - accuracy: 0.6931 - val_loss: 41.8491 - val_accuracy: 0.6516\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 40.0654 - accuracy: 0.6931 - val_loss: 37.8558 - val_accuracy: 0.6516\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 36.1909 - accuracy: 0.6931 - val_loss: 34.2253 - val_accuracy: 0.6516\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 32.6638 - accuracy: 0.6931 - val_loss: 30.8156 - val_accuracy: 0.6516\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 29.4160 - accuracy: 0.6995 - val_loss: 27.7046 - val_accuracy: 0.7032\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 26.4573 - accuracy: 0.7383 - val_loss: 24.9190 - val_accuracy: 0.7484\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 23.7732 - accuracy: 0.7690 - val_loss: 22.3929 - val_accuracy: 0.7742\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.3426 - accuracy: 0.8191 - val_loss: 20.0761 - val_accuracy: 0.8065\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.1188 - accuracy: 0.8433 - val_loss: 18.0018 - val_accuracy: 0.8452\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 17.1500 - accuracy: 0.8627 - val_loss: 16.1916 - val_accuracy: 0.7806\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 15.3372 - accuracy: 0.8708 - val_loss: 14.4709 - val_accuracy: 0.8645\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.7117 - accuracy: 0.8885 - val_loss: 13.0118 - val_accuracy: 0.8452\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 12.2191 - accuracy: 0.9338 - val_loss: 11.5613 - val_accuracy: 0.9032\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.9014 - accuracy: 0.9435 - val_loss: 10.3439 - val_accuracy: 0.9097\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.6709 - accuracy: 0.9742 - val_loss: 9.2446 - val_accuracy: 0.8774\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.6196 - accuracy: 0.9628 - val_loss: 8.8389 - val_accuracy: 0.8194\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.8427 - accuracy: 0.8611 - val_loss: 7.4696 - val_accuracy: 0.8129\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.9336 - accuracy: 0.9063 - val_loss: 6.6061 - val_accuracy: 0.8903\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.0616 - accuracy: 0.9580 - val_loss: 5.8106 - val_accuracy: 0.9226\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.3116 - accuracy: 0.9838 - val_loss: 5.3646 - val_accuracy: 0.8903\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.6944 - accuracy: 0.9887 - val_loss: 4.9574 - val_accuracy: 0.8774\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.1594 - accuracy: 0.9887 - val_loss: 4.3974 - val_accuracy: 0.8968\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.7392 - accuracy: 0.9693 - val_loss: 3.7893 - val_accuracy: 0.8710\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.3358 - accuracy: 0.9612 - val_loss: 3.3130 - val_accuracy: 0.8839\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.8999 - accuracy: 0.9887 - val_loss: 3.1157 - val_accuracy: 0.8968\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.5779 - accuracy: 0.9855 - val_loss: 2.9146 - val_accuracy: 0.8516\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.2849 - accuracy: 0.9855 - val_loss: 2.3934 - val_accuracy: 0.9097\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.0605 - accuracy: 0.9709 - val_loss: 2.1426 - val_accuracy: 0.9097\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.9294 - accuracy: 0.9370 - val_loss: 2.1103 - val_accuracy: 0.7742\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.7475 - accuracy: 0.9289 - val_loss: 1.8014 - val_accuracy: 0.8516\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.4436 - accuracy: 0.9742 - val_loss: 1.7626 - val_accuracy: 0.8839\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.2545 - accuracy: 0.9871 - val_loss: 1.6286 - val_accuracy: 0.8903\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.1830 - accuracy: 0.9693 - val_loss: 1.4681 - val_accuracy: 0.8194\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0220 - accuracy: 0.9790 - val_loss: 1.1312 - val_accuracy: 0.9032\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.8592 - accuracy: 0.9968 - val_loss: 1.1893 - val_accuracy: 0.9097\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7414 - accuracy: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.9032\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6538 - accuracy: 1.0000 - val_loss: 1.0755 - val_accuracy: 0.9097\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5768 - accuracy: 1.0000 - val_loss: 1.0740 - val_accuracy: 0.8903\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5090 - accuracy: 1.0000 - val_loss: 0.9749 - val_accuracy: 0.8968\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4492 - accuracy: 1.0000 - val_loss: 0.8743 - val_accuracy: 0.8968\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3968 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.9097\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3506 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.9097\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3099 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.9097\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2741 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.9097\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2425 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 0.9097\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.6187 - val_accuracy: 0.9097\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1901 - accuracy: 1.0000 - val_loss: 0.5921 - val_accuracy: 0.9097\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1685 - accuracy: 1.0000 - val_loss: 0.5704 - val_accuracy: 0.9097\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1494 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.9097\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.9097\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1179 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.9097\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9161\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9161\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.9161\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.9226\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9161\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.9161\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9161\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9161\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9161\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.9161\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9161\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9161\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9161\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9226\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9226\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.9097\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0242 - accuracy: 0.9984 - val_loss: 0.7396 - val_accuracy: 0.8774\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0650 - accuracy: 0.9871 - val_loss: 0.7713 - val_accuracy: 0.8129\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1885 - accuracy: 0.9596 - val_loss: 0.3766 - val_accuracy: 0.9097\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1158 - accuracy: 0.9790 - val_loss: 0.4614 - val_accuracy: 0.8968\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0779 - accuracy: 0.9919 - val_loss: 0.6197 - val_accuracy: 0.8774\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0888 - accuracy: 0.9838 - val_loss: 0.3439 - val_accuracy: 0.9226\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1138 - accuracy: 0.9742 - val_loss: 0.5412 - val_accuracy: 0.8645\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0566 - accuracy: 0.9952 - val_loss: 0.7204 - val_accuracy: 0.8774\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0374 - accuracy: 0.9984 - val_loss: 0.9198 - val_accuracy: 0.8710\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0537 - accuracy: 0.9935 - val_loss: 1.1917 - val_accuracy: 0.8323\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0704 - accuracy: 0.9838 - val_loss: 0.4138 - val_accuracy: 0.8839\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0523 - accuracy: 0.9903 - val_loss: 0.3764 - val_accuracy: 0.9032\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0237 - accuracy: 0.9984 - val_loss: 0.5041 - val_accuracy: 0.8968\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0339 - accuracy: 0.9952 - val_loss: 0.6937 - val_accuracy: 0.9032\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0376 - accuracy: 0.9952 - val_loss: 0.5435 - val_accuracy: 0.8710\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0428 - accuracy: 0.9935 - val_loss: 0.5600 - val_accuracy: 0.8516\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0400 - accuracy: 0.9952 - val_loss: 0.6720 - val_accuracy: 0.8645\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0273 - accuracy: 0.9968 - val_loss: 0.6031 - val_accuracy: 0.9032\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0221 - accuracy: 0.9968 - val_loss: 0.7094 - val_accuracy: 0.8516\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0179 - accuracy: 0.9984 - val_loss: 0.5791 - val_accuracy: 0.8839\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.8968\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.8968\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.6228 - val_accuracy: 0.9032\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6037 - val_accuracy: 0.9097\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5865 - val_accuracy: 0.9097\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 0.9097\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.9097\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.9097\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5606 - val_accuracy: 0.9097\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5648 - val_accuracy: 0.9097\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.9097\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5684 - val_accuracy: 0.9032\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5684 - accuracy: 0.9032\n",
            "Test Loss: 0.5684426426887512, Test Accuracy: 0.9032257795333862\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 49ms/step - loss: 48.6488 - accuracy: 0.6785 - val_loss: 46.0768 - val_accuracy: 0.6968\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.1886 - accuracy: 0.6817 - val_loss: 41.7747 - val_accuracy: 0.6968\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 40.0235 - accuracy: 0.6817 - val_loss: 37.8074 - val_accuracy: 0.6968\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 36.1814 - accuracy: 0.6817 - val_loss: 34.1092 - val_accuracy: 0.6968\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 32.6306 - accuracy: 0.6817 - val_loss: 30.8483 - val_accuracy: 0.6968\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 29.4196 - accuracy: 0.6817 - val_loss: 27.6920 - val_accuracy: 0.6968\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 26.4704 - accuracy: 0.6817 - val_loss: 24.9065 - val_accuracy: 0.6968\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 23.7595 - accuracy: 0.6817 - val_loss: 22.3505 - val_accuracy: 0.7032\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.3548 - accuracy: 0.7367 - val_loss: 20.0570 - val_accuracy: 0.7677\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.1526 - accuracy: 0.7641 - val_loss: 18.0094 - val_accuracy: 0.7613\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 17.1325 - accuracy: 0.8158 - val_loss: 16.1249 - val_accuracy: 0.8129\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.3356 - accuracy: 0.8417 - val_loss: 14.4688 - val_accuracy: 0.8387\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.7162 - accuracy: 0.8643 - val_loss: 13.0446 - val_accuracy: 0.6387\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 12.3574 - accuracy: 0.7286 - val_loss: 11.6005 - val_accuracy: 0.7677\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 10.9796 - accuracy: 0.8627 - val_loss: 10.4155 - val_accuracy: 0.8258\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.8003 - accuracy: 0.8481 - val_loss: 9.2759 - val_accuracy: 0.8387\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.6984 - accuracy: 0.9128 - val_loss: 8.2607 - val_accuracy: 0.7806\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.7455 - accuracy: 0.9273 - val_loss: 7.5186 - val_accuracy: 0.8387\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.8590 - accuracy: 0.9451 - val_loss: 6.5970 - val_accuracy: 0.8258\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.0709 - accuracy: 0.9532 - val_loss: 6.3148 - val_accuracy: 0.8387\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.3226 - accuracy: 0.9661 - val_loss: 5.2531 - val_accuracy: 0.8387\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.6736 - accuracy: 0.9822 - val_loss: 5.1696 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.3379 - accuracy: 0.8950 - val_loss: 4.1606 - val_accuracy: 0.8129\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.7921 - accuracy: 0.9289 - val_loss: 3.7751 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.3086 - accuracy: 0.9580 - val_loss: 3.4058 - val_accuracy: 0.8516\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.8587 - accuracy: 0.9903 - val_loss: 3.1129 - val_accuracy: 0.8774\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.5293 - accuracy: 0.9903 - val_loss: 2.8289 - val_accuracy: 0.8839\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.2146 - accuracy: 0.9952 - val_loss: 2.7881 - val_accuracy: 0.8516\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.9575 - accuracy: 0.9968 - val_loss: 2.4674 - val_accuracy: 0.8581\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7236 - accuracy: 0.9952 - val_loss: 2.0307 - val_accuracy: 0.9032\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5291 - accuracy: 0.9935 - val_loss: 2.3708 - val_accuracy: 0.8774\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.4592 - accuracy: 0.9467 - val_loss: 1.6367 - val_accuracy: 0.7677\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.2588 - accuracy: 0.9742 - val_loss: 2.3735 - val_accuracy: 0.7677\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0964 - accuracy: 0.9806 - val_loss: 1.4514 - val_accuracy: 0.8387\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9337 - accuracy: 0.9919 - val_loss: 1.3060 - val_accuracy: 0.8710\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8202 - accuracy: 0.9952 - val_loss: 1.5318 - val_accuracy: 0.8387\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7267 - accuracy: 0.9968 - val_loss: 1.4784 - val_accuracy: 0.8516\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6502 - accuracy: 0.9903 - val_loss: 1.0147 - val_accuracy: 0.8968\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5716 - accuracy: 0.9935 - val_loss: 0.9246 - val_accuracy: 0.8645\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4884 - accuracy: 1.0000 - val_loss: 1.1033 - val_accuracy: 0.8839\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4291 - accuracy: 1.0000 - val_loss: 1.0917 - val_accuracy: 0.8710\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3772 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.8839\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3321 - accuracy: 1.0000 - val_loss: 0.9526 - val_accuracy: 0.8968\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2922 - accuracy: 1.0000 - val_loss: 0.8543 - val_accuracy: 0.8903\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2574 - accuracy: 1.0000 - val_loss: 0.7942 - val_accuracy: 0.8903\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2269 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8903\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2000 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.8903\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1766 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8903\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1558 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8839\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1376 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.8839\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1216 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8839\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1075 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.8839\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.8839\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8903\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8839\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8774\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8774\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.7033 - val_accuracy: 0.8774\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8774\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.8968\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.6554 - val_accuracy: 0.8903\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.8839\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.8903\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.6291 - val_accuracy: 0.8903\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.8903\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.8903\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.8968\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 0.8839\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.8839\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.8903\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.8903\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.8774\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.8968\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6314 - val_accuracy: 0.8839\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 0.8774\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6275 - val_accuracy: 0.8774\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.8968\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6059 - val_accuracy: 0.8710\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.8774\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 0.8774\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.8903\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6153 - val_accuracy: 0.8839\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.8774\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.8516\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.8710\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 1.2782 - val_accuracy: 0.8774\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3713 - accuracy: 0.7399 - val_loss: 0.6284 - val_accuracy: 0.6000\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6387 - accuracy: 0.6834 - val_loss: 0.6639 - val_accuracy: 0.7355\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6619 - accuracy: 0.6834 - val_loss: 0.6610 - val_accuracy: 0.6968\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6401 - accuracy: 0.6866 - val_loss: 0.6538 - val_accuracy: 0.7032\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6254 - accuracy: 0.6898 - val_loss: 0.6404 - val_accuracy: 0.7097\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5990 - accuracy: 0.7092 - val_loss: 0.6258 - val_accuracy: 0.7097\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5836 - accuracy: 0.7011 - val_loss: 0.6164 - val_accuracy: 0.6710\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5672 - accuracy: 0.7157 - val_loss: 0.6083 - val_accuracy: 0.6839\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5539 - accuracy: 0.7254 - val_loss: 0.5977 - val_accuracy: 0.7226\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5297 - accuracy: 0.7528 - val_loss: 0.5864 - val_accuracy: 0.6903\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4985 - accuracy: 0.7884 - val_loss: 0.5885 - val_accuracy: 0.7355\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4845 - accuracy: 0.7803 - val_loss: 0.6359 - val_accuracy: 0.5742\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5132 - accuracy: 0.7431 - val_loss: 0.5843 - val_accuracy: 0.6774\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4758 - accuracy: 0.7900 - val_loss: 0.5771 - val_accuracy: 0.6645\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5771 - accuracy: 0.6645\n",
            "Test Loss: 0.5771434903144836, Test Accuracy: 0.6645161509513855\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 102ms/step - loss: 48.6777 - accuracy: 0.6645 - val_loss: 46.0864 - val_accuracy: 0.7273\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.2965 - accuracy: 0.6742 - val_loss: 41.8858 - val_accuracy: 0.7273\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 40.1718 - accuracy: 0.6742 - val_loss: 37.9253 - val_accuracy: 0.7273\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 36.3051 - accuracy: 0.6742 - val_loss: 34.2333 - val_accuracy: 0.7273\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 32.7480 - accuracy: 0.7081 - val_loss: 30.8697 - val_accuracy: 0.7857\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 29.4898 - accuracy: 0.7774 - val_loss: 27.7869 - val_accuracy: 0.8052\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 26.5369 - accuracy: 0.8097 - val_loss: 25.0469 - val_accuracy: 0.6948\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 23.8678 - accuracy: 0.7935 - val_loss: 22.5495 - val_accuracy: 0.7857\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.4891 - accuracy: 0.7516 - val_loss: 20.2107 - val_accuracy: 0.7792\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.2092 - accuracy: 0.8339 - val_loss: 18.0918 - val_accuracy: 0.7922\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 17.2126 - accuracy: 0.8339 - val_loss: 16.2540 - val_accuracy: 0.7987\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 15.4037 - accuracy: 0.8774 - val_loss: 14.6148 - val_accuracy: 0.8247\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.7732 - accuracy: 0.8661 - val_loss: 13.0278 - val_accuracy: 0.8117\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 12.2911 - accuracy: 0.8952 - val_loss: 11.7384 - val_accuracy: 0.8247\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.9715 - accuracy: 0.9081 - val_loss: 10.4222 - val_accuracy: 0.7792\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.7598 - accuracy: 0.9194 - val_loss: 9.5045 - val_accuracy: 0.8377\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 8.7080 - accuracy: 0.8968 - val_loss: 8.5499 - val_accuracy: 0.7013\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.7129 - accuracy: 0.9081 - val_loss: 7.5126 - val_accuracy: 0.8766\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 6.7837 - accuracy: 0.9565 - val_loss: 6.7375 - val_accuracy: 0.8571\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.9741 - accuracy: 0.9726 - val_loss: 6.3722 - val_accuracy: 0.7857\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.5790 - accuracy: 0.8839 - val_loss: 5.3247 - val_accuracy: 0.7792\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.8908 - accuracy: 0.8968 - val_loss: 4.7274 - val_accuracy: 0.8182\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 4.2118 - accuracy: 0.9677 - val_loss: 4.3764 - val_accuracy: 0.8701\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 3.7961 - accuracy: 0.9403 - val_loss: 3.8542 - val_accuracy: 0.8571\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.3193 - accuracy: 0.9694 - val_loss: 3.4071 - val_accuracy: 0.8831\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.8873 - accuracy: 0.9903 - val_loss: 3.4843 - val_accuracy: 0.8377\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.5275 - accuracy: 0.9968 - val_loss: 3.4637 - val_accuracy: 0.8701\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.2471 - accuracy: 0.9919 - val_loss: 2.8586 - val_accuracy: 0.8701\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.9865 - accuracy: 0.9919 - val_loss: 2.5139 - val_accuracy: 0.8571\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.7778 - accuracy: 0.9855 - val_loss: 2.1631 - val_accuracy: 0.8312\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.5527 - accuracy: 0.9919 - val_loss: 1.9799 - val_accuracy: 0.8506\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.3482 - accuracy: 1.0000 - val_loss: 2.1145 - val_accuracy: 0.8766\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1853 - accuracy: 1.0000 - val_loss: 2.2111 - val_accuracy: 0.8117\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0432 - accuracy: 1.0000 - val_loss: 2.0493 - val_accuracy: 0.8247\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9176 - accuracy: 1.0000 - val_loss: 1.8219 - val_accuracy: 0.8442\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.8069 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.8506\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7096 - accuracy: 1.0000 - val_loss: 1.5062 - val_accuracy: 0.8571\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6240 - accuracy: 1.0000 - val_loss: 1.3957 - val_accuracy: 0.8636\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5487 - accuracy: 1.0000 - val_loss: 1.3159 - val_accuracy: 0.8571\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4826 - accuracy: 1.0000 - val_loss: 1.2625 - val_accuracy: 0.8571\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4244 - accuracy: 1.0000 - val_loss: 1.2178 - val_accuracy: 0.8636\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3732 - accuracy: 1.0000 - val_loss: 1.1702 - val_accuracy: 0.8636\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3283 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.8636\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2888 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.8636\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2543 - accuracy: 1.0000 - val_loss: 1.0768 - val_accuracy: 0.8961\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2240 - accuracy: 1.0000 - val_loss: 1.0286 - val_accuracy: 0.8831\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1972 - accuracy: 1.0000 - val_loss: 1.0082 - val_accuracy: 0.8247\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1737 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.8636\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1531 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.8896\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1351 - accuracy: 1.0000 - val_loss: 0.9190 - val_accuracy: 0.8571\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 0.9018 - val_accuracy: 0.8701\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1051 - accuracy: 1.0000 - val_loss: 0.8860 - val_accuracy: 0.8831\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.8593 - val_accuracy: 0.8831\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.8385 - val_accuracy: 0.8766\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.8228 - val_accuracy: 0.8506\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.8896\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.8571\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.8896\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.8156 - val_accuracy: 0.8896\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.8896\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.8896\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.8896\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.7971 - val_accuracy: 0.8896\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.8896\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.8766\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.8896\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.8831\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.8831\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.8506\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.8175 - val_accuracy: 0.8896\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.7876 - val_accuracy: 0.8701\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.7683 - val_accuracy: 0.8831\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.8896\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7670 - val_accuracy: 0.8831\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.8831\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.8831\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.8766\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7846 - val_accuracy: 0.8831\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7755 - val_accuracy: 0.8831\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7692 - val_accuracy: 0.8831\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.8896\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8166 - val_accuracy: 0.8506\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8471 - val_accuracy: 0.8896\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7859 - val_accuracy: 0.8961\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7025 - accuracy: 0.8887 - val_loss: 0.8770 - val_accuracy: 0.3701\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7738 - accuracy: 0.5452 - val_loss: 0.6756 - val_accuracy: 0.7273\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6933 - accuracy: 0.6823 - val_loss: 0.6595 - val_accuracy: 0.7143\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6452 - accuracy: 0.7468 - val_loss: 0.6261 - val_accuracy: 0.6753\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5677 - accuracy: 0.7774 - val_loss: 0.5977 - val_accuracy: 0.7468\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5028 - accuracy: 0.8161 - val_loss: 0.5889 - val_accuracy: 0.7273\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5318 - accuracy: 0.7710 - val_loss: 0.6791 - val_accuracy: 0.6169\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5281 - accuracy: 0.7935 - val_loss: 0.5829 - val_accuracy: 0.7143\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4609 - accuracy: 0.8323 - val_loss: 0.5202 - val_accuracy: 0.7922\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3737 - accuracy: 0.8581 - val_loss: 0.4839 - val_accuracy: 0.8377\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.3317 - accuracy: 0.8806 - val_loss: 0.6261 - val_accuracy: 0.7403\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3455 - accuracy: 0.8694 - val_loss: 0.4885 - val_accuracy: 0.7662\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2787 - accuracy: 0.9145 - val_loss: 0.5363 - val_accuracy: 0.8247\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2246 - accuracy: 0.9323 - val_loss: 0.7425 - val_accuracy: 0.7857\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2408 - accuracy: 0.9290 - val_loss: 0.5847 - val_accuracy: 0.8117\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2085 - accuracy: 0.9419 - val_loss: 0.8242 - val_accuracy: 0.8182\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8242 - accuracy: 0.8182\n",
            "Test Loss: 0.8241695165634155, Test Accuracy: 0.8181818127632141\n",
            "\n",
            "Average Accuracy Across All Folds: 0.825571846961975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 증강 + dropout추가 + *L2규제*"
      ],
      "metadata": {
        "id": "83ifCkmVIVUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdamW + Random 증강 + L2규제 + dropout 6개 : 0.9095182180404663"
      ],
      "metadata": {
        "id": "T_c3iHisYyPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import AdamW\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJCVZUIfGQmp",
        "outputId": "7b9ec6c7-7f4f-4cc0-b14b-b2a52fff71be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 49ms/step - loss: 48.8317 - accuracy: 0.6931 - val_loss: 46.4679 - val_accuracy: 0.6323\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 44.6285 - accuracy: 0.6979 - val_loss: 42.3824 - val_accuracy: 0.6323\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 40.6059 - accuracy: 0.6979 - val_loss: 38.5333 - val_accuracy: 0.6323\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 36.8267 - accuracy: 0.6979 - val_loss: 34.8817 - val_accuracy: 0.6323\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 33.3177 - accuracy: 0.6979 - val_loss: 31.5314 - val_accuracy: 0.7742\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 30.1027 - accuracy: 0.7706 - val_loss: 28.5102 - val_accuracy: 0.7935\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 27.1733 - accuracy: 0.8352 - val_loss: 25.7173 - val_accuracy: 0.7226\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 24.5525 - accuracy: 0.7948 - val_loss: 23.2116 - val_accuracy: 0.8194\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 22.0804 - accuracy: 0.8433 - val_loss: 20.9123 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.8733 - accuracy: 0.8465 - val_loss: 18.7928 - val_accuracy: 0.8000\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 17.8357 - accuracy: 0.8934 - val_loss: 16.9144 - val_accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 16.0077 - accuracy: 0.9176 - val_loss: 15.2542 - val_accuracy: 0.8129\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.3495 - accuracy: 0.9273 - val_loss: 13.6303 - val_accuracy: 0.8452\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 12.8510 - accuracy: 0.9451 - val_loss: 12.2648 - val_accuracy: 0.8452\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 11.4730 - accuracy: 0.9564 - val_loss: 11.0701 - val_accuracy: 0.8194\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.2940 - accuracy: 0.9451 - val_loss: 9.8610 - val_accuracy: 0.8323\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.1629 - accuracy: 0.9677 - val_loss: 8.8134 - val_accuracy: 0.8581\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 8.1749 - accuracy: 0.9790 - val_loss: 7.8771 - val_accuracy: 0.8194\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.2675 - accuracy: 0.9855 - val_loss: 7.1460 - val_accuracy: 0.8516\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.4577 - accuracy: 0.9968 - val_loss: 6.3361 - val_accuracy: 0.8710\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.7497 - accuracy: 0.9887 - val_loss: 6.0248 - val_accuracy: 0.8387\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.1245 - accuracy: 0.9806 - val_loss: 5.1365 - val_accuracy: 0.8258\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.5945 - accuracy: 0.9499 - val_loss: 4.5665 - val_accuracy: 0.7806\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.1170 - accuracy: 0.9402 - val_loss: 4.2942 - val_accuracy: 0.7935\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.5885 - accuracy: 0.9806 - val_loss: 3.6183 - val_accuracy: 0.8839\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.1604 - accuracy: 0.9984 - val_loss: 3.2854 - val_accuracy: 0.8774\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.7967 - accuracy: 0.9984 - val_loss: 3.1473 - val_accuracy: 0.8516\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.4715 - accuracy: 0.9984 - val_loss: 2.8226 - val_accuracy: 0.8581\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.1824 - accuracy: 0.9984 - val_loss: 2.4447 - val_accuracy: 0.8645\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.9225 - accuracy: 0.9984 - val_loss: 2.2898 - val_accuracy: 0.8645\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.6841 - accuracy: 0.9984 - val_loss: 2.2394 - val_accuracy: 0.8581\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.4797 - accuracy: 0.9984 - val_loss: 2.1000 - val_accuracy: 0.8516\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3025 - accuracy: 0.9984 - val_loss: 1.9153 - val_accuracy: 0.8516\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.1422 - accuracy: 1.0000 - val_loss: 1.5099 - val_accuracy: 0.8839\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0039 - accuracy: 1.0000 - val_loss: 1.7044 - val_accuracy: 0.8516\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.2999 - accuracy: 0.8304 - val_loss: 1.2963 - val_accuracy: 0.7613\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1490 - accuracy: 0.8611 - val_loss: 1.1836 - val_accuracy: 0.8194\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0166 - accuracy: 0.9128 - val_loss: 1.0713 - val_accuracy: 0.8323\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8402 - accuracy: 0.9532 - val_loss: 1.0093 - val_accuracy: 0.8581\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7001 - accuracy: 0.9742 - val_loss: 0.9087 - val_accuracy: 0.8645\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5834 - accuracy: 0.9935 - val_loss: 0.8651 - val_accuracy: 0.8710\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5119 - accuracy: 0.9952 - val_loss: 0.8318 - val_accuracy: 0.8645\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4598 - accuracy: 0.9903 - val_loss: 0.7469 - val_accuracy: 0.8645\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4177 - accuracy: 0.9919 - val_loss: 0.7160 - val_accuracy: 0.8452\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3902 - accuracy: 0.9774 - val_loss: 0.6444 - val_accuracy: 0.8452\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3298 - accuracy: 0.9935 - val_loss: 0.5975 - val_accuracy: 0.8645\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2950 - accuracy: 0.9952 - val_loss: 0.7212 - val_accuracy: 0.8581\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2607 - accuracy: 0.9952 - val_loss: 0.6510 - val_accuracy: 0.8645\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2244 - accuracy: 1.0000 - val_loss: 0.5603 - val_accuracy: 0.8903\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2007 - accuracy: 1.0000 - val_loss: 0.5897 - val_accuracy: 0.8903\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.8968\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1599 - accuracy: 1.0000 - val_loss: 0.5356 - val_accuracy: 0.9032\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.5331 - val_accuracy: 0.9032\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1290 - accuracy: 1.0000 - val_loss: 0.5209 - val_accuracy: 0.9032\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.9032\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.9032\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9032\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.9032\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.8903\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.8968\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.8968\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.8968\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.8774\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.8774\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.8774\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.5365 - val_accuracy: 0.8774\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.5503 - val_accuracy: 0.8710\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.8774\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.5701 - val_accuracy: 0.8774\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.8710\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 0.8774\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.8710\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.5628 - val_accuracy: 0.8774\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 0.8710\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.8774\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5749 - val_accuracy: 0.8645\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.8710\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.8710\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.8774\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.8903\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5287 - val_accuracy: 0.8774\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.8774\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.8903\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.8839\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.8839\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.8839\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.8839\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.8839\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.8839\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.8839\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.8774\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.8839\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.8839\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.8774\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5185 - val_accuracy: 0.8710\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8839\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.8839\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 0.8839\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.8903\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 0.8839\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5604 - accuracy: 0.8839\n",
            "Test Loss: 0.5603930354118347, Test Accuracy: 0.8838709592819214\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 49ms/step - loss: 48.9589 - accuracy: 0.6688 - val_loss: 46.5821 - val_accuracy: 0.7161\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.8231 - accuracy: 0.6769 - val_loss: 42.5200 - val_accuracy: 0.7161\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 40.8266 - accuracy: 0.6769 - val_loss: 38.6806 - val_accuracy: 0.7161\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 37.0529 - accuracy: 0.6769 - val_loss: 35.0476 - val_accuracy: 0.7161\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 33.5677 - accuracy: 0.6769 - val_loss: 31.6502 - val_accuracy: 0.7161\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 30.3281 - accuracy: 0.6769 - val_loss: 28.6906 - val_accuracy: 0.7871\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 27.4116 - accuracy: 0.6898 - val_loss: 25.8834 - val_accuracy: 0.8387\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 24.7124 - accuracy: 0.7496 - val_loss: 23.2625 - val_accuracy: 0.8516\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 22.2501 - accuracy: 0.7819 - val_loss: 20.9645 - val_accuracy: 0.8452\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 20.0003 - accuracy: 0.8320 - val_loss: 18.8386 - val_accuracy: 0.8839\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 17.9835 - accuracy: 0.8595 - val_loss: 16.8970 - val_accuracy: 0.8903\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 16.1665 - accuracy: 0.8659 - val_loss: 15.2367 - val_accuracy: 0.8516\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.5127 - accuracy: 0.8885 - val_loss: 13.6357 - val_accuracy: 0.8323\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.0160 - accuracy: 0.8481 - val_loss: 12.2119 - val_accuracy: 0.9226\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 11.6101 - accuracy: 0.9176 - val_loss: 10.9533 - val_accuracy: 0.8710\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 10.3905 - accuracy: 0.9370 - val_loss: 9.8530 - val_accuracy: 0.8839\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.3087 - accuracy: 0.8966 - val_loss: 8.7838 - val_accuracy: 0.8516\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 8.2762 - accuracy: 0.9515 - val_loss: 7.8030 - val_accuracy: 0.8968\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.3553 - accuracy: 0.9677 - val_loss: 6.9562 - val_accuracy: 0.9355\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.5401 - accuracy: 0.9790 - val_loss: 6.1925 - val_accuracy: 0.9161\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.8317 - accuracy: 0.9774 - val_loss: 5.5787 - val_accuracy: 0.8774\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.2041 - accuracy: 0.9580 - val_loss: 5.0032 - val_accuracy: 0.8581\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.5944 - accuracy: 0.9871 - val_loss: 4.3790 - val_accuracy: 0.9355\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.0644 - accuracy: 0.9935 - val_loss: 3.9046 - val_accuracy: 0.9032\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.5979 - accuracy: 0.9952 - val_loss: 3.5470 - val_accuracy: 0.9097\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.1829 - accuracy: 0.9935 - val_loss: 3.2336 - val_accuracy: 0.9032\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.8116 - accuracy: 0.9935 - val_loss: 2.8323 - val_accuracy: 0.9290\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.4571 - accuracy: 0.9968 - val_loss: 2.5087 - val_accuracy: 0.9161\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.2214 - accuracy: 0.9871 - val_loss: 2.3047 - val_accuracy: 0.8710\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.9925 - accuracy: 0.9661 - val_loss: 2.0273 - val_accuracy: 0.8903\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7472 - accuracy: 0.9822 - val_loss: 1.7108 - val_accuracy: 0.9484\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5429 - accuracy: 0.9887 - val_loss: 1.6811 - val_accuracy: 0.9161\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.4826 - accuracy: 0.9483 - val_loss: 1.4321 - val_accuracy: 0.9226\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3165 - accuracy: 0.9451 - val_loss: 1.3494 - val_accuracy: 0.8839\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0917 - accuracy: 0.9968 - val_loss: 1.2824 - val_accuracy: 0.8968\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9695 - accuracy: 0.9822 - val_loss: 1.2970 - val_accuracy: 0.8839\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8872 - accuracy: 0.9790 - val_loss: 0.9717 - val_accuracy: 0.9097\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7722 - accuracy: 0.9855 - val_loss: 0.8729 - val_accuracy: 0.8903\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6522 - accuracy: 0.9984 - val_loss: 0.7577 - val_accuracy: 0.9419\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5700 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.9484\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5036 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.9161\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4452 - accuracy: 1.0000 - val_loss: 0.6610 - val_accuracy: 0.9097\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3938 - accuracy: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.9097\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3483 - accuracy: 1.0000 - val_loss: 0.5380 - val_accuracy: 0.9226\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3083 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9290\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2731 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9226\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2420 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9290\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9290\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1904 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9290\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.1690 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9290\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1500 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9290\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9290\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9290\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1052 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9355\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9290\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9226\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9355\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.9226\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9161\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.8774\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1005 - accuracy: 0.9903 - val_loss: 0.2349 - val_accuracy: 0.9355\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0904 - accuracy: 0.9887 - val_loss: 0.4286 - val_accuracy: 0.8645\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0670 - accuracy: 0.9968 - val_loss: 0.3104 - val_accuracy: 0.9419\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0725 - accuracy: 0.9903 - val_loss: 0.7798 - val_accuracy: 0.8194\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1369 - accuracy: 0.9758 - val_loss: 0.2338 - val_accuracy: 0.9290\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0643 - accuracy: 0.9919 - val_loss: 0.2739 - val_accuracy: 0.9226\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0825 - accuracy: 0.9887 - val_loss: 0.3420 - val_accuracy: 0.8968\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0587 - accuracy: 0.9935 - val_loss: 0.2209 - val_accuracy: 0.9419\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0420 - accuracy: 0.9984 - val_loss: 0.3991 - val_accuracy: 0.8903\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0458 - accuracy: 0.9935 - val_loss: 0.3486 - val_accuracy: 0.8903\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0472 - accuracy: 0.9952 - val_loss: 0.3004 - val_accuracy: 0.9032\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0594 - accuracy: 0.9871 - val_loss: 0.2995 - val_accuracy: 0.8968\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0712 - accuracy: 0.9822 - val_loss: 0.2103 - val_accuracy: 0.9226\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0315 - accuracy: 0.9968 - val_loss: 0.2674 - val_accuracy: 0.9419\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9161\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9097\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9097\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9097\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9161\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9355\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9355\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9355\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9419\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9419\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9484\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9484\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9419\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9484\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9419\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9355\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9355\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9355\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9355\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9355\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9355\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9355\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9355\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9419\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9419\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9484\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2591 - accuracy: 0.9484\n",
            "Test Loss: 0.2590939998626709, Test Accuracy: 0.948387086391449\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 55ms/step - loss: 48.8974 - accuracy: 0.6850 - val_loss: 46.5663 - val_accuracy: 0.6516\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.7400 - accuracy: 0.6931 - val_loss: 42.5128 - val_accuracy: 0.6516\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 40.7859 - accuracy: 0.6931 - val_loss: 38.7035 - val_accuracy: 0.6516\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 37.0666 - accuracy: 0.6931 - val_loss: 35.1891 - val_accuracy: 0.6516\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 33.6195 - accuracy: 0.6931 - val_loss: 31.8304 - val_accuracy: 0.6516\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 30.3974 - accuracy: 0.6931 - val_loss: 28.7433 - val_accuracy: 0.7097\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 27.4692 - accuracy: 0.7108 - val_loss: 25.9569 - val_accuracy: 0.8323\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 24.7815 - accuracy: 0.8013 - val_loss: 23.4088 - val_accuracy: 0.7677\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 22.3623 - accuracy: 0.8223 - val_loss: 21.2242 - val_accuracy: 0.8387\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 20.1733 - accuracy: 0.8304 - val_loss: 19.0623 - val_accuracy: 0.8516\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 18.1551 - accuracy: 0.8530 - val_loss: 17.1126 - val_accuracy: 0.7935\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 16.3113 - accuracy: 0.8465 - val_loss: 15.3772 - val_accuracy: 0.8194\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.6390 - accuracy: 0.8740 - val_loss: 13.8269 - val_accuracy: 0.8774\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.1182 - accuracy: 0.9079 - val_loss: 12.4164 - val_accuracy: 0.8839\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 11.8093 - accuracy: 0.8708 - val_loss: 11.1336 - val_accuracy: 0.8903\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.5442 - accuracy: 0.9176 - val_loss: 9.9647 - val_accuracy: 0.8903\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 9.4220 - accuracy: 0.9111 - val_loss: 8.9212 - val_accuracy: 0.8968\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.4133 - accuracy: 0.9418 - val_loss: 8.1238 - val_accuracy: 0.7871\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.5840 - accuracy: 0.8950 - val_loss: 7.3054 - val_accuracy: 0.8516\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 6.8405 - accuracy: 0.8708 - val_loss: 6.4728 - val_accuracy: 0.8387\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.0512 - accuracy: 0.9144 - val_loss: 5.7628 - val_accuracy: 0.8581\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.3507 - accuracy: 0.9580 - val_loss: 5.1485 - val_accuracy: 0.8774\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.7686 - accuracy: 0.9612 - val_loss: 4.7097 - val_accuracy: 0.8645\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.2264 - accuracy: 0.9822 - val_loss: 4.1380 - val_accuracy: 0.8839\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.7308 - accuracy: 0.9952 - val_loss: 3.6990 - val_accuracy: 0.8968\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.3105 - accuracy: 0.9984 - val_loss: 3.2936 - val_accuracy: 0.9032\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.9310 - accuracy: 0.9984 - val_loss: 3.0483 - val_accuracy: 0.8903\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.5957 - accuracy: 0.9984 - val_loss: 2.6909 - val_accuracy: 0.8968\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.2952 - accuracy: 0.9984 - val_loss: 2.4410 - val_accuracy: 0.8903\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.0233 - accuracy: 0.9984 - val_loss: 2.3102 - val_accuracy: 0.8839\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7757 - accuracy: 0.9935 - val_loss: 2.0783 - val_accuracy: 0.9161\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.6778 - accuracy: 0.9596 - val_loss: 1.7658 - val_accuracy: 0.8774\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5049 - accuracy: 0.9467 - val_loss: 1.5889 - val_accuracy: 0.8710\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.2854 - accuracy: 0.9855 - val_loss: 1.5048 - val_accuracy: 0.8774\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1064 - accuracy: 0.9952 - val_loss: 1.5309 - val_accuracy: 0.8710\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0204 - accuracy: 0.9790 - val_loss: 1.3023 - val_accuracy: 0.8774\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9575 - accuracy: 0.9693 - val_loss: 1.1108 - val_accuracy: 0.8581\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8105 - accuracy: 0.9838 - val_loss: 1.0706 - val_accuracy: 0.9097\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6949 - accuracy: 0.9919 - val_loss: 1.0610 - val_accuracy: 0.8774\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6343 - accuracy: 0.9838 - val_loss: 1.0338 - val_accuracy: 0.8581\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5981 - accuracy: 0.9742 - val_loss: 0.7303 - val_accuracy: 0.9161\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4903 - accuracy: 0.9919 - val_loss: 0.7289 - val_accuracy: 0.9032\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4272 - accuracy: 0.9968 - val_loss: 0.9021 - val_accuracy: 0.8903\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3850 - accuracy: 0.9952 - val_loss: 0.9168 - val_accuracy: 0.8968\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3529 - accuracy: 0.9935 - val_loss: 0.5856 - val_accuracy: 0.9226\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2988 - accuracy: 0.9984 - val_loss: 0.5962 - val_accuracy: 0.8968\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2674 - accuracy: 0.9984 - val_loss: 0.6806 - val_accuracy: 0.8903\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2322 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.8968\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.8903\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1834 - accuracy: 1.0000 - val_loss: 0.6032 - val_accuracy: 0.8839\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1627 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.9032\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1446 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9097\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1286 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9161\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1146 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9161\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1021 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.9161\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9161\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.9161\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9161\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.9161\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9161\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9161\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9161\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9226\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9226\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.9226\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9226\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9226\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.9226\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9161\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9226\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9226\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9226\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9226\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9161\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9032\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9161\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9161\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.9161\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.9161\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9290\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9226\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9226\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1326 - accuracy: 0.9822 - val_loss: 0.7365 - val_accuracy: 0.8194\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5372 - accuracy: 0.8433 - val_loss: 0.4714 - val_accuracy: 0.8129\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3098 - accuracy: 0.9321 - val_loss: 0.3950 - val_accuracy: 0.8968\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2230 - accuracy: 0.9742 - val_loss: 0.3592 - val_accuracy: 0.8968\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1382 - accuracy: 0.9903 - val_loss: 0.5866 - val_accuracy: 0.8774\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1566 - accuracy: 0.9790 - val_loss: 0.3780 - val_accuracy: 0.8774\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0988 - accuracy: 0.9855 - val_loss: 0.3583 - val_accuracy: 0.9097\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8968\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.5967 - val_accuracy: 0.8903\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.8710\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.8774\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.5853 - val_accuracy: 0.8774\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.5650 - val_accuracy: 0.8839\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.5634 - val_accuracy: 0.9032\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.5613 - val_accuracy: 0.8968\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.5572 - val_accuracy: 0.8968\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.5616 - val_accuracy: 0.8839\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.9032\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.9032\n",
            "Test Loss: 0.5912331938743591, Test Accuracy: 0.9032257795333862\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 50ms/step - loss: 49.0558 - accuracy: 0.6624 - val_loss: 46.7503 - val_accuracy: 0.6968\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.8905 - accuracy: 0.6817 - val_loss: 42.6257 - val_accuracy: 0.6968\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 40.8557 - accuracy: 0.6817 - val_loss: 38.6996 - val_accuracy: 0.6968\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 37.0457 - accuracy: 0.6817 - val_loss: 35.0438 - val_accuracy: 0.6968\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 33.5635 - accuracy: 0.6947 - val_loss: 31.9055 - val_accuracy: 0.5097\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 30.4683 - accuracy: 0.6963 - val_loss: 28.6789 - val_accuracy: 0.6968\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 27.5079 - accuracy: 0.6817 - val_loss: 25.9571 - val_accuracy: 0.6968\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 24.7970 - accuracy: 0.6979 - val_loss: 23.4225 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 22.3416 - accuracy: 0.7609 - val_loss: 21.2778 - val_accuracy: 0.6258\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 20.2029 - accuracy: 0.7754 - val_loss: 18.9890 - val_accuracy: 0.7742\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 18.1506 - accuracy: 0.7868 - val_loss: 17.0928 - val_accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 16.3139 - accuracy: 0.8207 - val_loss: 15.3723 - val_accuracy: 0.8129\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.6588 - accuracy: 0.8546 - val_loss: 13.8288 - val_accuracy: 0.8258\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.1645 - accuracy: 0.8449 - val_loss: 12.4585 - val_accuracy: 0.8194\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 11.7834 - accuracy: 0.8821 - val_loss: 11.1094 - val_accuracy: 0.8516\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 10.5516 - accuracy: 0.9015 - val_loss: 9.9626 - val_accuracy: 0.8323\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.4138 - accuracy: 0.9338 - val_loss: 8.9091 - val_accuracy: 0.8710\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 8.4060 - accuracy: 0.9499 - val_loss: 7.9690 - val_accuracy: 0.8516\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.5392 - accuracy: 0.9273 - val_loss: 7.1359 - val_accuracy: 0.8710\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.7105 - accuracy: 0.9435 - val_loss: 6.4156 - val_accuracy: 0.8452\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.9748 - accuracy: 0.9661 - val_loss: 5.7280 - val_accuracy: 0.8710\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.3132 - accuracy: 0.9693 - val_loss: 5.1085 - val_accuracy: 0.8710\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.7356 - accuracy: 0.9742 - val_loss: 4.6213 - val_accuracy: 0.8258\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.2565 - accuracy: 0.9354 - val_loss: 4.1063 - val_accuracy: 0.8129\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.7934 - accuracy: 0.9499 - val_loss: 3.6790 - val_accuracy: 0.8516\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.3791 - accuracy: 0.9467 - val_loss: 3.3254 - val_accuracy: 0.8645\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.9581 - accuracy: 0.9774 - val_loss: 2.9141 - val_accuracy: 0.8645\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.6061 - accuracy: 0.9919 - val_loss: 2.6436 - val_accuracy: 0.8645\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.3013 - accuracy: 0.9935 - val_loss: 2.3250 - val_accuracy: 0.8968\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.0338 - accuracy: 0.9952 - val_loss: 2.1028 - val_accuracy: 0.8774\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7925 - accuracy: 0.9952 - val_loss: 1.8728 - val_accuracy: 0.8645\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5729 - accuracy: 0.9952 - val_loss: 1.7192 - val_accuracy: 0.8903\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3820 - accuracy: 0.9952 - val_loss: 1.5999 - val_accuracy: 0.8903\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.2198 - accuracy: 0.9952 - val_loss: 1.3839 - val_accuracy: 0.8774\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0739 - accuracy: 0.9952 - val_loss: 1.2882 - val_accuracy: 0.9032\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9859 - accuracy: 0.9806 - val_loss: 1.2187 - val_accuracy: 0.8452\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.9264 - accuracy: 0.9628 - val_loss: 1.0336 - val_accuracy: 0.8774\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7967 - accuracy: 0.9822 - val_loss: 0.8952 - val_accuracy: 0.8968\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6706 - accuracy: 0.9952 - val_loss: 0.9197 - val_accuracy: 0.8968\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6188 - accuracy: 0.9838 - val_loss: 1.0733 - val_accuracy: 0.8323\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6508 - accuracy: 0.9435 - val_loss: 0.7159 - val_accuracy: 0.8968\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5053 - accuracy: 0.9806 - val_loss: 0.6353 - val_accuracy: 0.9032\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4096 - accuracy: 0.9984 - val_loss: 0.6610 - val_accuracy: 0.8903\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3874 - accuracy: 0.9887 - val_loss: 0.6838 - val_accuracy: 0.8774\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4015 - accuracy: 0.9661 - val_loss: 0.4850 - val_accuracy: 0.9032\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3184 - accuracy: 0.9887 - val_loss: 0.4400 - val_accuracy: 0.8968\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2584 - accuracy: 0.9984 - val_loss: 0.6016 - val_accuracy: 0.8839\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2441 - accuracy: 0.9935 - val_loss: 0.4339 - val_accuracy: 0.9226\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3361 - accuracy: 0.9483 - val_loss: 0.4854 - val_accuracy: 0.8581\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2578 - accuracy: 0.9838 - val_loss: 0.3719 - val_accuracy: 0.9032\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2009 - accuracy: 0.9855 - val_loss: 0.5259 - val_accuracy: 0.8774\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1635 - accuracy: 0.9919 - val_loss: 0.4758 - val_accuracy: 0.8839\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1366 - accuracy: 0.9984 - val_loss: 0.2848 - val_accuracy: 0.9097\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1162 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.9032\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9032\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9032\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9097\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9097\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9097\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9097\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9161\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9161\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9097\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9097\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9097\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9097\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9161\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9161\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9161\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9097\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9097\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9097\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9097\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1681 - val_accuracy: 0.9097\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9097\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9226\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9161\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9161\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9226\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9097\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9161\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9226\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9097\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9161\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9097\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9355\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.5626 - val_accuracy: 0.9290\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0956 - accuracy: 0.9887 - val_loss: 0.3747 - val_accuracy: 0.8452\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1302 - accuracy: 0.9677 - val_loss: 0.3321 - val_accuracy: 0.8645\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1239 - accuracy: 0.9806 - val_loss: 0.4709 - val_accuracy: 0.8710\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1383 - accuracy: 0.9693 - val_loss: 0.3558 - val_accuracy: 0.8645\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0627 - accuracy: 0.9952 - val_loss: 0.2491 - val_accuracy: 0.9226\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9290\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9355\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9355\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9355\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9355\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9355\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9355\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9355\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2130 - accuracy: 0.9355\n",
            "Test Loss: 0.21303460001945496, Test Accuracy: 0.9354838728904724\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 48ms/step - loss: 48.9740 - accuracy: 0.6710 - val_loss: 46.7117 - val_accuracy: 0.7273\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.9385 - accuracy: 0.6742 - val_loss: 42.7052 - val_accuracy: 0.7273\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 41.0374 - accuracy: 0.6742 - val_loss: 38.9070 - val_accuracy: 0.7273\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 37.3536 - accuracy: 0.6742 - val_loss: 35.3612 - val_accuracy: 0.7273\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 33.9348 - accuracy: 0.6742 - val_loss: 32.0970 - val_accuracy: 0.7273\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 30.7497 - accuracy: 0.6758 - val_loss: 29.0244 - val_accuracy: 0.7273\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 27.8425 - accuracy: 0.6919 - val_loss: 26.3758 - val_accuracy: 0.7468\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 25.1609 - accuracy: 0.7419 - val_loss: 23.8646 - val_accuracy: 0.6688\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 22.7477 - accuracy: 0.7758 - val_loss: 21.5295 - val_accuracy: 0.7143\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 20.4994 - accuracy: 0.8161 - val_loss: 19.4271 - val_accuracy: 0.7273\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 18.4642 - accuracy: 0.8129 - val_loss: 17.4896 - val_accuracy: 0.7727\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 16.5946 - accuracy: 0.8661 - val_loss: 15.7305 - val_accuracy: 0.8182\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.9219 - accuracy: 0.8790 - val_loss: 14.1213 - val_accuracy: 0.8766\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.4176 - accuracy: 0.8742 - val_loss: 12.7175 - val_accuracy: 0.8442\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 12.0328 - accuracy: 0.9032 - val_loss: 11.4373 - val_accuracy: 0.8182\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 10.7708 - accuracy: 0.9145 - val_loss: 10.3167 - val_accuracy: 0.8312\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.6826 - accuracy: 0.8952 - val_loss: 9.2831 - val_accuracy: 0.7597\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.6309 - accuracy: 0.9323 - val_loss: 8.2876 - val_accuracy: 0.8377\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.6955 - accuracy: 0.9516 - val_loss: 7.4907 - val_accuracy: 0.8571\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.8645 - accuracy: 0.9613 - val_loss: 6.7403 - val_accuracy: 0.7857\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.1593 - accuracy: 0.9516 - val_loss: 6.1173 - val_accuracy: 0.8377\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 5.4857 - accuracy: 0.9548 - val_loss: 5.4116 - val_accuracy: 0.8506\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 4.8688 - accuracy: 0.9758 - val_loss: 4.8823 - val_accuracy: 0.8117\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 4.3304 - accuracy: 0.9758 - val_loss: 4.4483 - val_accuracy: 0.8117\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.8382 - accuracy: 0.9823 - val_loss: 4.2830 - val_accuracy: 0.8442\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.4264 - accuracy: 0.9774 - val_loss: 3.7477 - val_accuracy: 0.8377\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 3.0131 - accuracy: 0.9935 - val_loss: 3.2290 - val_accuracy: 0.8506\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.6674 - accuracy: 0.9952 - val_loss: 2.9974 - val_accuracy: 0.8636\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.3511 - accuracy: 0.9968 - val_loss: 2.8202 - val_accuracy: 0.8961\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.0639 - accuracy: 0.9968 - val_loss: 2.7389 - val_accuracy: 0.8961\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.8563 - accuracy: 0.9839 - val_loss: 2.4453 - val_accuracy: 0.8766\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.0458 - accuracy: 0.8258 - val_loss: 2.2117 - val_accuracy: 0.6688\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.7132 - accuracy: 0.8984 - val_loss: 1.8278 - val_accuracy: 0.8312\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5018 - accuracy: 0.9677 - val_loss: 1.7252 - val_accuracy: 0.8052\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3258 - accuracy: 0.9871 - val_loss: 1.6635 - val_accuracy: 0.7987\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1793 - accuracy: 0.9919 - val_loss: 1.5664 - val_accuracy: 0.8442\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0569 - accuracy: 0.9952 - val_loss: 1.5152 - val_accuracy: 0.8442\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9428 - accuracy: 0.9984 - val_loss: 1.4378 - val_accuracy: 0.8506\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8475 - accuracy: 0.9984 - val_loss: 1.3395 - val_accuracy: 0.8766\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.7635 - accuracy: 0.9984 - val_loss: 1.2447 - val_accuracy: 0.8701\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6882 - accuracy: 0.9984 - val_loss: 1.1833 - val_accuracy: 0.8766\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6184 - accuracy: 0.9984 - val_loss: 1.2240 - val_accuracy: 0.8636\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5554 - accuracy: 0.9984 - val_loss: 1.2249 - val_accuracy: 0.8896\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4984 - accuracy: 0.9984 - val_loss: 1.2671 - val_accuracy: 0.8831\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4531 - accuracy: 0.9952 - val_loss: 1.3514 - val_accuracy: 0.8442\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5242 - accuracy: 0.9597 - val_loss: 1.1541 - val_accuracy: 0.7403\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5041 - accuracy: 0.9371 - val_loss: 0.8516 - val_accuracy: 0.8117\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3943 - accuracy: 0.9871 - val_loss: 0.8465 - val_accuracy: 0.8312\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3293 - accuracy: 0.9968 - val_loss: 0.7816 - val_accuracy: 0.8961\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2875 - accuracy: 0.9984 - val_loss: 0.9010 - val_accuracy: 0.8766\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2586 - accuracy: 1.0000 - val_loss: 0.9195 - val_accuracy: 0.8896\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2356 - accuracy: 1.0000 - val_loss: 0.9051 - val_accuracy: 0.8961\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.8442\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1957 - accuracy: 1.0000 - val_loss: 0.9228 - val_accuracy: 0.8636\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1787 - accuracy: 1.0000 - val_loss: 0.8514 - val_accuracy: 0.8896\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1638 - accuracy: 1.0000 - val_loss: 0.8553 - val_accuracy: 0.8701\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1503 - accuracy: 1.0000 - val_loss: 0.8616 - val_accuracy: 0.8571\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1379 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.8636\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1269 - accuracy: 1.0000 - val_loss: 0.8287 - val_accuracy: 0.8571\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1168 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.8636\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.7936 - val_accuracy: 0.8766\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0994 - accuracy: 1.0000 - val_loss: 0.7816 - val_accuracy: 0.8766\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.8831\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.8896\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8831\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.8701\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0855 - accuracy: 0.9952 - val_loss: 0.6852 - val_accuracy: 0.8377\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0793 - accuracy: 0.9968 - val_loss: 0.6156 - val_accuracy: 0.8896\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0827 - accuracy: 0.9952 - val_loss: 0.6069 - val_accuracy: 0.8766\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0840 - accuracy: 0.9935 - val_loss: 0.7497 - val_accuracy: 0.8506\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1034 - accuracy: 0.9790 - val_loss: 0.7923 - val_accuracy: 0.8506\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0733 - accuracy: 0.9952 - val_loss: 0.6247 - val_accuracy: 0.8571\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0662 - accuracy: 0.9952 - val_loss: 0.6165 - val_accuracy: 0.8701\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1064 - accuracy: 0.9806 - val_loss: 0.4546 - val_accuracy: 0.8701\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0845 - accuracy: 0.9903 - val_loss: 0.5574 - val_accuracy: 0.8571\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0587 - accuracy: 0.9968 - val_loss: 0.7734 - val_accuracy: 0.8247\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0590 - accuracy: 0.9968 - val_loss: 0.8214 - val_accuracy: 0.8571\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0483 - accuracy: 0.9984 - val_loss: 0.8250 - val_accuracy: 0.8442\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0542 - accuracy: 0.9952 - val_loss: 1.0208 - val_accuracy: 0.7662\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0704 - accuracy: 0.9887 - val_loss: 0.8581 - val_accuracy: 0.8052\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0523 - accuracy: 0.9968 - val_loss: 0.5870 - val_accuracy: 0.8701\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0529 - accuracy: 0.9952 - val_loss: 0.6550 - val_accuracy: 0.8636\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0610 - accuracy: 0.9919 - val_loss: 0.5384 - val_accuracy: 0.8831\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0517 - accuracy: 0.9952 - val_loss: 0.6457 - val_accuracy: 0.7922\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0418 - accuracy: 0.9984 - val_loss: 0.6911 - val_accuracy: 0.8571\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.8181 - val_accuracy: 0.8377\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0312 - accuracy: 0.9984 - val_loss: 0.8196 - val_accuracy: 0.8571\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0308 - accuracy: 0.9968 - val_loss: 0.9088 - val_accuracy: 0.8571\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0484 - accuracy: 0.9903 - val_loss: 0.7961 - val_accuracy: 0.8506\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0435 - accuracy: 0.9919 - val_loss: 0.6867 - val_accuracy: 0.8636\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0259 - accuracy: 0.9984 - val_loss: 0.9232 - val_accuracy: 0.8442\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.0142 - val_accuracy: 0.8636\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0312 - accuracy: 0.9935 - val_loss: 0.9146 - val_accuracy: 0.8442\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0940 - accuracy: 0.9774 - val_loss: 0.6472 - val_accuracy: 0.8377\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0971 - accuracy: 0.9758 - val_loss: 0.6476 - val_accuracy: 0.8442\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0619 - accuracy: 0.9839 - val_loss: 0.6511 - val_accuracy: 0.8766\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0317 - accuracy: 0.9952 - val_loss: 1.1798 - val_accuracy: 0.7857\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0518 - accuracy: 0.9887 - val_loss: 0.7571 - val_accuracy: 0.8636\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0286 - accuracy: 0.9984 - val_loss: 0.9146 - val_accuracy: 0.7922\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.9260 - val_accuracy: 0.8766\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9260 - accuracy: 0.8766\n",
            "Test Loss: 0.9259754419326782, Test Accuracy: 0.8766233921051025\n",
            "\n",
            "Average Accuracy Across All Folds: 0.9095182180404663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdamW + Random 증강 + L2규제 + dropout 6개 + epoch 100 -> 200 : 0.8489317059516907"
      ],
      "metadata": {
        "id": "A3iSigTwaFhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import AdamW\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruQsjOPGH2Mr",
        "outputId": "39668455-4673-4e5c-a42c-a581e86f3939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 51ms/step - loss: 48.7980 - accuracy: 0.6753 - val_loss: 46.3353 - val_accuracy: 0.6323\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.4183 - accuracy: 0.6979 - val_loss: 42.1271 - val_accuracy: 0.6323\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 40.2994 - accuracy: 0.6979 - val_loss: 38.0978 - val_accuracy: 0.6323\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 36.4451 - accuracy: 0.6979 - val_loss: 34.4329 - val_accuracy: 0.6323\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 32.8932 - accuracy: 0.6979 - val_loss: 31.0752 - val_accuracy: 0.6323\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 29.6127 - accuracy: 0.6979 - val_loss: 28.0503 - val_accuracy: 0.6581\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 26.6919 - accuracy: 0.7383 - val_loss: 25.1901 - val_accuracy: 0.7290\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 23.9964 - accuracy: 0.7690 - val_loss: 22.6926 - val_accuracy: 0.7935\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.5566 - accuracy: 0.8384 - val_loss: 20.4149 - val_accuracy: 0.7935\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.4379 - accuracy: 0.7609 - val_loss: 18.3492 - val_accuracy: 0.7032\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 17.3981 - accuracy: 0.8045 - val_loss: 16.4720 - val_accuracy: 0.7742\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 15.5655 - accuracy: 0.8643 - val_loss: 14.7415 - val_accuracy: 0.8452\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.9393 - accuracy: 0.8756 - val_loss: 13.2030 - val_accuracy: 0.8258\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 12.4415 - accuracy: 0.9047 - val_loss: 11.9560 - val_accuracy: 0.7548\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 11.1417 - accuracy: 0.9095 - val_loss: 10.5822 - val_accuracy: 0.8323\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.9095 - accuracy: 0.9273 - val_loss: 9.5041 - val_accuracy: 0.8387\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.8067 - accuracy: 0.9580 - val_loss: 8.5082 - val_accuracy: 0.8581\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.8229 - accuracy: 0.9790 - val_loss: 7.8418 - val_accuracy: 0.8452\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.9469 - accuracy: 0.9871 - val_loss: 6.8291 - val_accuracy: 0.8323\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.1856 - accuracy: 0.9822 - val_loss: 6.1722 - val_accuracy: 0.8000\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.4797 - accuracy: 0.9855 - val_loss: 5.5319 - val_accuracy: 0.8452\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.9499 - accuracy: 0.9241 - val_loss: 4.8743 - val_accuracy: 0.7613\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.3613 - accuracy: 0.9483 - val_loss: 4.2971 - val_accuracy: 0.8516\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.8237 - accuracy: 0.9806 - val_loss: 3.8890 - val_accuracy: 0.8323\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.3796 - accuracy: 0.9855 - val_loss: 3.5009 - val_accuracy: 0.8516\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.0057 - accuracy: 0.9709 - val_loss: 3.6736 - val_accuracy: 0.7806\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.6770 - accuracy: 0.9661 - val_loss: 2.8508 - val_accuracy: 0.7742\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.3832 - accuracy: 0.9515 - val_loss: 2.7173 - val_accuracy: 0.8452\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.0640 - accuracy: 0.9822 - val_loss: 2.5034 - val_accuracy: 0.8258\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7978 - accuracy: 0.9984 - val_loss: 2.2423 - val_accuracy: 0.8581\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5800 - accuracy: 0.9984 - val_loss: 1.9855 - val_accuracy: 0.8452\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3860 - accuracy: 0.9984 - val_loss: 1.9683 - val_accuracy: 0.8452\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.2059 - accuracy: 0.9968 - val_loss: 2.4669 - val_accuracy: 0.8387\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0955 - accuracy: 0.9855 - val_loss: 1.5439 - val_accuracy: 0.8065\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9714 - accuracy: 0.9871 - val_loss: 1.3357 - val_accuracy: 0.8645\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8364 - accuracy: 0.9919 - val_loss: 1.6377 - val_accuracy: 0.8581\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7548 - accuracy: 0.9919 - val_loss: 1.2560 - val_accuracy: 0.8323\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6530 - accuracy: 0.9935 - val_loss: 1.4311 - val_accuracy: 0.8258\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5727 - accuracy: 0.9968 - val_loss: 1.0689 - val_accuracy: 0.8452\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5024 - accuracy: 0.9968 - val_loss: 1.1573 - val_accuracy: 0.8452\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4292 - accuracy: 0.9984 - val_loss: 1.0321 - val_accuracy: 0.8516\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3729 - accuracy: 1.0000 - val_loss: 1.2373 - val_accuracy: 0.8452\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3268 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.8516\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2863 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 0.8516\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2503 - accuracy: 1.0000 - val_loss: 1.1554 - val_accuracy: 0.8516\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.0705 - val_accuracy: 0.8516\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1921 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.8452\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1684 - accuracy: 1.0000 - val_loss: 0.8995 - val_accuracy: 0.8516\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1475 - accuracy: 1.0000 - val_loss: 0.8816 - val_accuracy: 0.8452\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1296 - accuracy: 1.0000 - val_loss: 0.8691 - val_accuracy: 0.8452\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1135 - accuracy: 1.0000 - val_loss: 0.8621 - val_accuracy: 0.8516\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0999 - accuracy: 1.0000 - val_loss: 0.8783 - val_accuracy: 0.8452\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.8452\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.8352 - val_accuracy: 0.8581\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.8263 - val_accuracy: 0.8516\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.8152 - val_accuracy: 0.8516\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.8581\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.8516\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.7928 - val_accuracy: 0.8581\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.8516\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.8516\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.8516\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.8516\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.8516\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.8581\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.8417 - val_accuracy: 0.8387\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.8452\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.7737 - val_accuracy: 0.8516\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.7823 - val_accuracy: 0.8452\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.8516\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7739 - val_accuracy: 0.8387\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.8452\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8452\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.7823 - val_accuracy: 0.8452\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.8452\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.8516\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8178 - val_accuracy: 0.8516\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.8516\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.8516\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7758 - val_accuracy: 0.8516\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7828 - val_accuracy: 0.8516\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.8516\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.8516\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7756 - val_accuracy: 0.8516\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8586 - val_accuracy: 0.8516\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8890 - val_accuracy: 0.8581\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.2562 - accuracy: 0.7754 - val_loss: 0.7399 - val_accuracy: 0.6323\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7093 - accuracy: 0.6979 - val_loss: 0.7728 - val_accuracy: 0.6323\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7637 - accuracy: 0.7027 - val_loss: 0.7841 - val_accuracy: 0.6387\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7356 - accuracy: 0.7027 - val_loss: 0.7336 - val_accuracy: 0.6903\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6600 - accuracy: 0.7593 - val_loss: 0.7537 - val_accuracy: 0.7032\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7135 - accuracy: 0.7367 - val_loss: 0.7690 - val_accuracy: 0.6710\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6281 - accuracy: 0.7819 - val_loss: 0.6353 - val_accuracy: 0.7871\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5710 - accuracy: 0.8094 - val_loss: 0.6579 - val_accuracy: 0.7806\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5187 - accuracy: 0.8562 - val_loss: 0.6046 - val_accuracy: 0.7935\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4886 - accuracy: 0.8675 - val_loss: 0.6069 - val_accuracy: 0.7935\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4559 - accuracy: 0.8805 - val_loss: 0.6007 - val_accuracy: 0.8194\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4349 - accuracy: 0.8998 - val_loss: 0.6330 - val_accuracy: 0.7742\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4233 - accuracy: 0.9079 - val_loss: 0.5822 - val_accuracy: 0.8194\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3664 - accuracy: 0.9225 - val_loss: 0.5671 - val_accuracy: 0.8258\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4502 - accuracy: 0.8724 - val_loss: 0.6048 - val_accuracy: 0.8387\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4143 - accuracy: 0.8756 - val_loss: 0.5954 - val_accuracy: 0.7548\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3579 - accuracy: 0.9160 - val_loss: 0.5359 - val_accuracy: 0.8258\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3014 - accuracy: 0.9354 - val_loss: 0.5630 - val_accuracy: 0.8258\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2850 - accuracy: 0.9354 - val_loss: 0.5370 - val_accuracy: 0.8194\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3220 - accuracy: 0.9241 - val_loss: 0.5667 - val_accuracy: 0.8387\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3058 - accuracy: 0.9289 - val_loss: 0.6349 - val_accuracy: 0.8258\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2716 - accuracy: 0.9338 - val_loss: 0.6893 - val_accuracy: 0.7355\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2638 - accuracy: 0.9402 - val_loss: 0.5389 - val_accuracy: 0.8323\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1997 - accuracy: 0.9645 - val_loss: 0.5684 - val_accuracy: 0.8387\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1598 - accuracy: 0.9806 - val_loss: 0.7305 - val_accuracy: 0.8065\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1793 - accuracy: 0.9661 - val_loss: 0.8003 - val_accuracy: 0.8000\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2229 - accuracy: 0.9370 - val_loss: 0.5824 - val_accuracy: 0.8194\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1848 - accuracy: 0.9661 - val_loss: 0.5024 - val_accuracy: 0.8065\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1553 - accuracy: 0.9790 - val_loss: 0.6141 - val_accuracy: 0.8516\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1231 - accuracy: 0.9871 - val_loss: 0.6565 - val_accuracy: 0.8065\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1090 - accuracy: 0.9887 - val_loss: 0.7702 - val_accuracy: 0.8194\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1820 - accuracy: 0.9677 - val_loss: 0.5581 - val_accuracy: 0.8065\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1617 - accuracy: 0.9661 - val_loss: 0.5421 - val_accuracy: 0.8387\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1268 - accuracy: 0.9855 - val_loss: 0.6764 - val_accuracy: 0.8452\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1449 - accuracy: 0.9693 - val_loss: 0.6243 - val_accuracy: 0.8645\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1047 - accuracy: 0.9903 - val_loss: 0.5771 - val_accuracy: 0.8323\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1231 - accuracy: 0.9758 - val_loss: 1.0267 - val_accuracy: 0.7871\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1708 - accuracy: 0.9742 - val_loss: 0.4487 - val_accuracy: 0.8387\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0885 - accuracy: 0.9968 - val_loss: 0.6125 - val_accuracy: 0.8452\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.8452\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.8459 - val_accuracy: 0.8258\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.8258\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.8581 - val_accuracy: 0.8452\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.8875 - val_accuracy: 0.8516\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.8906 - val_accuracy: 0.8452\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.8323\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.8941 - val_accuracy: 0.8323\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.9149 - val_accuracy: 0.8387\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.9350 - val_accuracy: 0.8387\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.8452\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.9440 - val_accuracy: 0.8581\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.9538 - val_accuracy: 0.8516\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.8452\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.8387\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.9822 - val_accuracy: 0.8387\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 1.0007 - val_accuracy: 0.8387\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 1.0190 - val_accuracy: 0.8387\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 1.0406 - val_accuracy: 0.8387\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.8387\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.8387\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 1.1126 - val_accuracy: 0.8387\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.8387\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 1.1724 - val_accuracy: 0.8387\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 1.1970 - val_accuracy: 0.8387\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 1.2284 - val_accuracy: 0.8387\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 1.2365 - val_accuracy: 0.8387\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.8516\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.2687 - val_accuracy: 0.8516\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.2654 - val_accuracy: 0.8516\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 1.2869 - val_accuracy: 0.8516\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 1.3175 - val_accuracy: 0.8516\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 1.2888 - val_accuracy: 0.8516\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.2339 - val_accuracy: 0.8323\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.2625 - val_accuracy: 0.8323\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.3156 - val_accuracy: 0.8516\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.3167 - val_accuracy: 0.8516\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.3227 - val_accuracy: 0.8516\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.2792 - val_accuracy: 0.8258\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.2193 - val_accuracy: 0.8452\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.2733 - val_accuracy: 0.8323\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.3438 - val_accuracy: 0.8516\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.3069 - val_accuracy: 0.8452\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.2227 - val_accuracy: 0.8387\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.2815 - val_accuracy: 0.8452\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.2856 - val_accuracy: 0.8516\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.1789 - val_accuracy: 0.8387\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.1761 - val_accuracy: 0.8452\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.2093 - val_accuracy: 0.8452\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.2631 - val_accuracy: 0.8323\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.2419 - val_accuracy: 0.8323\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.2793 - val_accuracy: 0.8387\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.2540 - val_accuracy: 0.8516\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.1195 - val_accuracy: 0.8452\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.1477 - val_accuracy: 0.8516\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.2207 - val_accuracy: 0.8323\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.1378 - val_accuracy: 0.8452\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.1810 - val_accuracy: 0.8194\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.1951 - val_accuracy: 0.8323\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.1364 - val_accuracy: 0.8387\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.1321 - val_accuracy: 0.8387\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.8387\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.1226 - val_accuracy: 0.8387\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.1603 - val_accuracy: 0.8323\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.1569 - val_accuracy: 0.8323\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.0887 - val_accuracy: 0.8323\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.0896 - val_accuracy: 0.8387\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.1218 - val_accuracy: 0.8323\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1572 - val_accuracy: 0.8323\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.0826 - val_accuracy: 0.8452\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.1684 - val_accuracy: 0.8323\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.0192 - val_accuracy: 0.8452\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0160 - accuracy: 0.9984 - val_loss: 2.1109 - val_accuracy: 0.6968\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9082 - accuracy: 0.6898 - val_loss: 0.6021 - val_accuracy: 0.6323\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6018 - accuracy: 0.5751 - val_loss: 0.5953 - val_accuracy: 0.6387\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5953 - accuracy: 0.6387\n",
            "Test Loss: 0.5952579379081726, Test Accuracy: 0.6387096643447876\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 50ms/step - loss: 48.9493 - accuracy: 0.6769 - val_loss: 46.6673 - val_accuracy: 0.7161\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.8532 - accuracy: 0.6769 - val_loss: 42.6145 - val_accuracy: 0.7161\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 40.8686 - accuracy: 0.6769 - val_loss: 38.7231 - val_accuracy: 0.7161\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 37.0920 - accuracy: 0.6769 - val_loss: 35.0878 - val_accuracy: 0.7161\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 33.6014 - accuracy: 0.6769 - val_loss: 31.7191 - val_accuracy: 0.7161\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 30.3536 - accuracy: 0.6769 - val_loss: 28.5778 - val_accuracy: 0.7806\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 27.4248 - accuracy: 0.7270 - val_loss: 25.8242 - val_accuracy: 0.7226\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 24.7898 - accuracy: 0.7431 - val_loss: 23.3028 - val_accuracy: 0.8000\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 22.3257 - accuracy: 0.7658 - val_loss: 20.9715 - val_accuracy: 0.8194\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 20.0917 - accuracy: 0.7997 - val_loss: 18.9156 - val_accuracy: 0.8645\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 18.0771 - accuracy: 0.8223 - val_loss: 16.9950 - val_accuracy: 0.8774\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 16.2631 - accuracy: 0.8320 - val_loss: 15.2622 - val_accuracy: 0.8452\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 14.5934 - accuracy: 0.8481 - val_loss: 13.6772 - val_accuracy: 0.8774\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.1033 - accuracy: 0.8578 - val_loss: 12.4792 - val_accuracy: 0.7290\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 11.7859 - accuracy: 0.8255 - val_loss: 11.0879 - val_accuracy: 0.8581\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.5466 - accuracy: 0.8788 - val_loss: 9.9158 - val_accuracy: 0.8710\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.3960 - accuracy: 0.9031 - val_loss: 8.8497 - val_accuracy: 0.8903\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.3904 - accuracy: 0.9144 - val_loss: 7.9138 - val_accuracy: 0.8968\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.4479 - accuracy: 0.9612 - val_loss: 7.2031 - val_accuracy: 0.8774\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.6435 - accuracy: 0.9661 - val_loss: 6.4865 - val_accuracy: 0.8387\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.0059 - accuracy: 0.9047 - val_loss: 5.6966 - val_accuracy: 0.9161\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.3392 - accuracy: 0.9257 - val_loss: 5.0588 - val_accuracy: 0.9097\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.6944 - accuracy: 0.9790 - val_loss: 4.5214 - val_accuracy: 0.9161\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.1581 - accuracy: 0.9838 - val_loss: 4.0735 - val_accuracy: 0.9032\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6906 - accuracy: 0.9887 - val_loss: 3.6439 - val_accuracy: 0.9161\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.2609 - accuracy: 0.9952 - val_loss: 3.2918 - val_accuracy: 0.9355\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.8880 - accuracy: 0.9935 - val_loss: 3.0314 - val_accuracy: 0.8903\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.5533 - accuracy: 0.9952 - val_loss: 2.6104 - val_accuracy: 0.9226\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.2535 - accuracy: 0.9968 - val_loss: 2.3227 - val_accuracy: 0.9097\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.9784 - accuracy: 0.9952 - val_loss: 2.2828 - val_accuracy: 0.9097\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7597 - accuracy: 0.9887 - val_loss: 2.1562 - val_accuracy: 0.8968\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.5751 - accuracy: 0.9855 - val_loss: 1.8576 - val_accuracy: 0.8387\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.7093 - accuracy: 0.8691 - val_loss: 1.6497 - val_accuracy: 0.9032\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.4344 - accuracy: 0.9241 - val_loss: 1.4694 - val_accuracy: 0.8710\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.2041 - accuracy: 0.9742 - val_loss: 1.2911 - val_accuracy: 0.8903\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0487 - accuracy: 0.9855 - val_loss: 1.3624 - val_accuracy: 0.9097\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.9106 - accuracy: 0.9952 - val_loss: 1.1898 - val_accuracy: 0.9290\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7935 - accuracy: 0.9968 - val_loss: 1.1387 - val_accuracy: 0.9097\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6958 - accuracy: 0.9984 - val_loss: 1.1645 - val_accuracy: 0.9097\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6125 - accuracy: 0.9984 - val_loss: 1.1233 - val_accuracy: 0.9097\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5407 - accuracy: 0.9984 - val_loss: 0.9983 - val_accuracy: 0.9226\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4791 - accuracy: 0.9984 - val_loss: 0.9909 - val_accuracy: 0.9097\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4202 - accuracy: 1.0000 - val_loss: 0.8779 - val_accuracy: 0.9032\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3729 - accuracy: 1.0000 - val_loss: 1.0123 - val_accuracy: 0.8774\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5003 - accuracy: 0.9742 - val_loss: 1.5170 - val_accuracy: 0.6323\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5759 - accuracy: 0.8982 - val_loss: 0.6008 - val_accuracy: 0.8645\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4877 - accuracy: 0.9208 - val_loss: 0.5207 - val_accuracy: 0.8710\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3780 - accuracy: 0.9515 - val_loss: 0.5881 - val_accuracy: 0.8645\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2845 - accuracy: 0.9758 - val_loss: 0.5932 - val_accuracy: 0.9032\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2244 - accuracy: 0.9935 - val_loss: 0.4908 - val_accuracy: 0.8903\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1948 - accuracy: 0.9952 - val_loss: 0.5390 - val_accuracy: 0.9097\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1645 - accuracy: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.8839\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1750 - accuracy: 0.9903 - val_loss: 0.6007 - val_accuracy: 0.8968\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3085 - accuracy: 0.9402 - val_loss: 0.4618 - val_accuracy: 0.8194\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2574 - accuracy: 0.9532 - val_loss: 0.3481 - val_accuracy: 0.8968\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1646 - accuracy: 0.9838 - val_loss: 0.4295 - val_accuracy: 0.8903\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1256 - accuracy: 0.9935 - val_loss: 0.4630 - val_accuracy: 0.8839\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1476 - accuracy: 0.9806 - val_loss: 0.4315 - val_accuracy: 0.8968\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1057 - accuracy: 0.9952 - val_loss: 0.4284 - val_accuracy: 0.8903\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.8839\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0780 - accuracy: 0.9952 - val_loss: 0.7520 - val_accuracy: 0.8710\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0733 - accuracy: 0.9968 - val_loss: 0.4672 - val_accuracy: 0.8710\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9161\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.9355\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9355\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9290\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9290\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9290\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9290\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9290\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9290\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.9226\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9226\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9226\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9226\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9161\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9161\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9161\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9226\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.9226\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9226\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.9161\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9161\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9097\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 0.9161\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9161\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9161\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9161\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9097\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9097\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9097\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9161\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9161\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9161\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9161\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9097\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.9097\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9097\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9161\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9097\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.9161\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.9161\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9226\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9161\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.8968\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9484\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9161\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9097\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9097\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9355\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9161\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9161\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9161\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9161\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9161\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.9161\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9161\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9161\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9419\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9226\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.9032\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1384 - accuracy: 0.9628 - val_loss: 0.6599 - val_accuracy: 0.8387\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1284 - accuracy: 0.9693 - val_loss: 0.4045 - val_accuracy: 0.8581\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1054 - accuracy: 0.9693 - val_loss: 0.4718 - val_accuracy: 0.8387\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0836 - accuracy: 0.9806 - val_loss: 0.5480 - val_accuracy: 0.8774\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0540 - accuracy: 0.9919 - val_loss: 0.6443 - val_accuracy: 0.9032\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0381 - accuracy: 0.9968 - val_loss: 0.8746 - val_accuracy: 0.9032\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0568 - accuracy: 0.9935 - val_loss: 0.3951 - val_accuracy: 0.9032\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0474 - accuracy: 0.9952 - val_loss: 0.3659 - val_accuracy: 0.9032\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9097\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.9161\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.6253 - val_accuracy: 0.9161\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 0.9226\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.9290\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.9290\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9226\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.9226\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9290\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9290\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9290\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9290\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.9290\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9226\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9226\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9226\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9226\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9226\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9226\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9226\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9161\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9226\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9161\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9226\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9226\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9161\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9161\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.9226\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9290\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.9290\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.9226\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.9226\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9226\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9290\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.9290\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.9226\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9226\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4794 - val_accuracy: 0.9226\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4757 - val_accuracy: 0.9226\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9290\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9290\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9290\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9290\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.9355\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9355\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9355\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9355\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.9355\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.9355\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.9355\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9355\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9097\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8903\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.5174 - val_accuracy: 0.8903\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0497 - accuracy: 0.9903 - val_loss: 0.7514 - val_accuracy: 0.8774\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0787 - accuracy: 0.9887 - val_loss: 1.3310 - val_accuracy: 0.7871\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3083 - accuracy: 0.8982 - val_loss: 0.3657 - val_accuracy: 0.8581\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1630 - accuracy: 0.9564 - val_loss: 0.3639 - val_accuracy: 0.8903\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0822 - accuracy: 0.9742 - val_loss: 0.7947 - val_accuracy: 0.8903\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0815 - accuracy: 0.9822 - val_loss: 0.3721 - val_accuracy: 0.9032\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0315 - accuracy: 0.9984 - val_loss: 0.4133 - val_accuracy: 0.8839\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0312 - accuracy: 0.9935 - val_loss: 0.5251 - val_accuracy: 0.8903\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0521 - accuracy: 0.9871 - val_loss: 0.4097 - val_accuracy: 0.9097\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0364 - accuracy: 0.9935 - val_loss: 0.4157 - val_accuracy: 0.9161\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0246 - accuracy: 0.9968 - val_loss: 0.4872 - val_accuracy: 0.9290\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0304 - accuracy: 0.9935 - val_loss: 0.4870 - val_accuracy: 0.8968\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0209 - accuracy: 0.9968 - val_loss: 0.3461 - val_accuracy: 0.8839\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0182 - accuracy: 0.9968 - val_loss: 0.6478 - val_accuracy: 0.9290\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 0.9984 - val_loss: 0.4133 - val_accuracy: 0.9161\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0118 - accuracy: 0.9984 - val_loss: 0.7715 - val_accuracy: 0.9161\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.5221 - val_accuracy: 0.9226\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.9226\n",
            "Test Loss: 0.5221103429794312, Test Accuracy: 0.9225806593894958\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 50ms/step - loss: 48.8549 - accuracy: 0.6850 - val_loss: 46.5104 - val_accuracy: 0.6516\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.6141 - accuracy: 0.6931 - val_loss: 42.3319 - val_accuracy: 0.6516\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 40.5324 - accuracy: 0.6931 - val_loss: 38.4081 - val_accuracy: 0.6516\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 36.7382 - accuracy: 0.6931 - val_loss: 34.7556 - val_accuracy: 0.6774\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 33.2703 - accuracy: 0.6979 - val_loss: 31.4316 - val_accuracy: 0.6645\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 30.0215 - accuracy: 0.7367 - val_loss: 28.4240 - val_accuracy: 0.8000\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 27.1253 - accuracy: 0.7754 - val_loss: 25.6582 - val_accuracy: 0.8129\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 24.4569 - accuracy: 0.7916 - val_loss: 23.0846 - val_accuracy: 0.8129\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 22.0550 - accuracy: 0.8191 - val_loss: 20.7947 - val_accuracy: 0.7484\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.8268 - accuracy: 0.7964 - val_loss: 18.7006 - val_accuracy: 0.7935\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 17.8249 - accuracy: 0.8271 - val_loss: 16.8180 - val_accuracy: 0.8323\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 16.0145 - accuracy: 0.8304 - val_loss: 15.1395 - val_accuracy: 0.8516\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.3658 - accuracy: 0.8611 - val_loss: 13.5516 - val_accuracy: 0.8452\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 12.8826 - accuracy: 0.8530 - val_loss: 12.1793 - val_accuracy: 0.8000\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 11.5530 - accuracy: 0.8433 - val_loss: 10.8871 - val_accuracy: 0.8581\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.3052 - accuracy: 0.8901 - val_loss: 9.7656 - val_accuracy: 0.8581\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.2029 - accuracy: 0.9095 - val_loss: 8.7424 - val_accuracy: 0.8774\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 8.1846 - accuracy: 0.9499 - val_loss: 7.8296 - val_accuracy: 0.8839\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.2946 - accuracy: 0.9580 - val_loss: 7.0254 - val_accuracy: 0.8452\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.5240 - accuracy: 0.9418 - val_loss: 6.2386 - val_accuracy: 0.8903\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.8137 - accuracy: 0.9580 - val_loss: 5.6612 - val_accuracy: 0.8581\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.1674 - accuracy: 0.9628 - val_loss: 4.9917 - val_accuracy: 0.8774\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.5765 - accuracy: 0.9774 - val_loss: 4.4512 - val_accuracy: 0.9161\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.0848 - accuracy: 0.9628 - val_loss: 4.5242 - val_accuracy: 0.7742\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.6815 - accuracy: 0.9483 - val_loss: 3.5777 - val_accuracy: 0.8774\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.2030 - accuracy: 0.9806 - val_loss: 3.2333 - val_accuracy: 0.8387\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.8385 - accuracy: 0.9838 - val_loss: 2.8628 - val_accuracy: 0.8645\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.5003 - accuracy: 0.9903 - val_loss: 2.5777 - val_accuracy: 0.8839\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.1964 - accuracy: 0.9984 - val_loss: 2.3816 - val_accuracy: 0.8968\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.9386 - accuracy: 0.9984 - val_loss: 2.1689 - val_accuracy: 0.8903\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.7090 - accuracy: 0.9984 - val_loss: 1.9206 - val_accuracy: 0.8968\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5005 - accuracy: 0.9984 - val_loss: 1.7112 - val_accuracy: 0.8839\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3113 - accuracy: 0.9984 - val_loss: 1.7208 - val_accuracy: 0.8903\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1524 - accuracy: 0.9984 - val_loss: 1.4968 - val_accuracy: 0.8774\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0309 - accuracy: 0.9903 - val_loss: 1.4167 - val_accuracy: 0.8581\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0156 - accuracy: 0.9596 - val_loss: 1.1493 - val_accuracy: 0.8839\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8436 - accuracy: 0.9855 - val_loss: 1.1201 - val_accuracy: 0.8710\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7242 - accuracy: 0.9952 - val_loss: 1.0317 - val_accuracy: 0.8710\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6348 - accuracy: 0.9984 - val_loss: 0.9219 - val_accuracy: 0.9032\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5503 - accuracy: 0.9984 - val_loss: 0.9392 - val_accuracy: 0.8774\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6466 - accuracy: 0.9435 - val_loss: 0.7653 - val_accuracy: 0.8710\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5321 - accuracy: 0.9790 - val_loss: 0.7746 - val_accuracy: 0.8968\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4122 - accuracy: 0.9952 - val_loss: 0.8188 - val_accuracy: 0.8774\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4051 - accuracy: 0.9838 - val_loss: 0.7789 - val_accuracy: 0.8387\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3542 - accuracy: 0.9806 - val_loss: 0.5220 - val_accuracy: 0.9032\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2832 - accuracy: 0.9984 - val_loss: 0.5926 - val_accuracy: 0.8903\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2627 - accuracy: 0.9968 - val_loss: 0.5769 - val_accuracy: 0.9097\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2359 - accuracy: 0.9887 - val_loss: 0.5637 - val_accuracy: 0.8710\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2201 - accuracy: 0.9903 - val_loss: 0.5954 - val_accuracy: 0.8645\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1773 - accuracy: 0.9968 - val_loss: 0.5366 - val_accuracy: 0.8710\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1595 - accuracy: 0.9952 - val_loss: 0.6256 - val_accuracy: 0.8516\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1360 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8710\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1190 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.8774\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.8839\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.8903\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9032\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.8968\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.8903\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8903\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.8903\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.8903\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.8903\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.8968\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.8968\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9032\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9032\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.8968\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9032\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.8968\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.9032\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.8968\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.8968\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9032\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.8968\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.8968\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.8968\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.9032\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.8968\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.8968\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.8968\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.8903\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.8903\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.8968\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.8968\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9032\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.8968\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.8903\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 0.9032\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.8968\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.8903\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.8968\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.8968\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.8968\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.9097\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.8968\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.8968\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.8968\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.8968\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9097\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9161\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9032\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9032\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.9032\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9032\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9032\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.8968\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9097\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.8968\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9032\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9097\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.8968\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.9097\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9097\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.8968\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5495 - val_accuracy: 0.8645\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6248 - accuracy: 0.8013 - val_loss: 0.5606 - val_accuracy: 0.6774\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5435 - accuracy: 0.7674 - val_loss: 0.5948 - val_accuracy: 0.8194\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4748 - accuracy: 0.8562 - val_loss: 0.5062 - val_accuracy: 0.8387\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4184 - accuracy: 0.8869 - val_loss: 0.4436 - val_accuracy: 0.8581\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3158 - accuracy: 0.9386 - val_loss: 0.4888 - val_accuracy: 0.8194\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2397 - accuracy: 0.9532 - val_loss: 0.4436 - val_accuracy: 0.8710\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1501 - accuracy: 0.9790 - val_loss: 0.3269 - val_accuracy: 0.9032\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0882 - accuracy: 0.9935 - val_loss: 0.5058 - val_accuracy: 0.9097\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0877 - accuracy: 0.9935 - val_loss: 0.4486 - val_accuracy: 0.8774\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1156 - accuracy: 0.9774 - val_loss: 0.5299 - val_accuracy: 0.8000\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1720 - accuracy: 0.9499 - val_loss: 0.4219 - val_accuracy: 0.8387\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0927 - accuracy: 0.9903 - val_loss: 0.3943 - val_accuracy: 0.8581\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0578 - accuracy: 0.9984 - val_loss: 0.5170 - val_accuracy: 0.8645\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0603 - accuracy: 0.9935 - val_loss: 0.6854 - val_accuracy: 0.8581\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0603 - accuracy: 0.9919 - val_loss: 0.4446 - val_accuracy: 0.8774\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0581 - accuracy: 0.9903 - val_loss: 0.3852 - val_accuracy: 0.8839\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0481 - accuracy: 0.9935 - val_loss: 0.5365 - val_accuracy: 0.8258\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0474 - accuracy: 0.9968 - val_loss: 0.5154 - val_accuracy: 0.8774\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.8581\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8710\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 0.8839\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.8774\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.8774\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.5938 - val_accuracy: 0.8710\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.8774\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.5946 - val_accuracy: 0.8774\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.8710\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 0.8774\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.8710\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.8710\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.8774\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.8774\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.8645\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8645\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8581\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8645\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.7689 - val_accuracy: 0.8645\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.8710\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.8710\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.8710\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.8710\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.8710\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8042 - val_accuracy: 0.8710\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.8710\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.8710\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.8368 - val_accuracy: 0.8710\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8221 - val_accuracy: 0.8645\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8282 - val_accuracy: 0.8710\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8543 - val_accuracy: 0.8710\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8424 - val_accuracy: 0.8774\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.8774\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.8710\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8678 - val_accuracy: 0.8774\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.8774\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8573 - val_accuracy: 0.8774\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.8201 - val_accuracy: 0.8710\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7874 - val_accuracy: 0.8710\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.8710\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.8710\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.8774\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.8774\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 0.8774\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.8774\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.8710\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.8710\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8388 - val_accuracy: 0.8774\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8679 - val_accuracy: 0.8839\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8633 - val_accuracy: 0.8774\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8385 - val_accuracy: 0.8774\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.8710\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7892 - val_accuracy: 0.8774\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.8710\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.8774\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.8710\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7727 - val_accuracy: 0.8710\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7826 - val_accuracy: 0.8710\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8802 - val_accuracy: 0.8903\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.9102 - val_accuracy: 0.8968\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2054 - accuracy: 0.9645 - val_loss: 0.3317 - val_accuracy: 0.8774\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1940 - accuracy: 0.9241 - val_loss: 0.4579 - val_accuracy: 0.7871\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1732 - accuracy: 0.9338 - val_loss: 0.3233 - val_accuracy: 0.8710\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1065 - accuracy: 0.9628 - val_loss: 0.2713 - val_accuracy: 0.9226\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1027 - accuracy: 0.9612 - val_loss: 0.3969 - val_accuracy: 0.8258\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0672 - accuracy: 0.9822 - val_loss: 0.3646 - val_accuracy: 0.8968\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0267 - accuracy: 0.9952 - val_loss: 0.4407 - val_accuracy: 0.8968\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8968\n",
            "Test Loss: 0.4406575858592987, Test Accuracy: 0.896774172782898\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 51ms/step - loss: 48.8129 - accuracy: 0.6672 - val_loss: 46.4127 - val_accuracy: 0.6968\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.5271 - accuracy: 0.6817 - val_loss: 42.2362 - val_accuracy: 0.6968\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 40.4598 - accuracy: 0.6817 - val_loss: 38.3059 - val_accuracy: 0.6968\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 36.6464 - accuracy: 0.6817 - val_loss: 34.6246 - val_accuracy: 0.6968\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 33.1510 - accuracy: 0.6850 - val_loss: 31.4215 - val_accuracy: 0.7161\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 29.9844 - accuracy: 0.6995 - val_loss: 28.3504 - val_accuracy: 0.7355\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 27.0448 - accuracy: 0.7124 - val_loss: 25.5761 - val_accuracy: 0.7806\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 24.3626 - accuracy: 0.7787 - val_loss: 22.9777 - val_accuracy: 0.8194\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.9612 - accuracy: 0.8142 - val_loss: 20.6574 - val_accuracy: 0.7742\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.7990 - accuracy: 0.8126 - val_loss: 18.6468 - val_accuracy: 0.7742\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 17.7601 - accuracy: 0.8142 - val_loss: 16.7247 - val_accuracy: 0.8323\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 15.9432 - accuracy: 0.8417 - val_loss: 15.0133 - val_accuracy: 0.8710\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 14.2835 - accuracy: 0.8885 - val_loss: 13.4921 - val_accuracy: 0.8581\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 12.7879 - accuracy: 0.9095 - val_loss: 12.0587 - val_accuracy: 0.8903\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 11.4701 - accuracy: 0.8982 - val_loss: 10.8022 - val_accuracy: 0.8774\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 10.2429 - accuracy: 0.9208 - val_loss: 9.6983 - val_accuracy: 0.8710\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.1577 - accuracy: 0.9160 - val_loss: 8.7734 - val_accuracy: 0.7548\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 8.1527 - accuracy: 0.9467 - val_loss: 7.7239 - val_accuracy: 0.8839\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.2506 - accuracy: 0.9515 - val_loss: 6.9553 - val_accuracy: 0.8258\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.4655 - accuracy: 0.9596 - val_loss: 6.1901 - val_accuracy: 0.8839\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.7364 - accuracy: 0.9709 - val_loss: 5.4995 - val_accuracy: 0.8774\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.0888 - accuracy: 0.9806 - val_loss: 5.0199 - val_accuracy: 0.7742\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.5385 - accuracy: 0.9725 - val_loss: 4.4545 - val_accuracy: 0.8323\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.9932 - accuracy: 0.9919 - val_loss: 3.9377 - val_accuracy: 0.8516\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.5368 - accuracy: 0.9935 - val_loss: 3.5153 - val_accuracy: 0.8581\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.1354 - accuracy: 0.9935 - val_loss: 3.1465 - val_accuracy: 0.8452\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.8037 - accuracy: 0.9742 - val_loss: 2.8582 - val_accuracy: 0.8258\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.4609 - accuracy: 0.9855 - val_loss: 2.5042 - val_accuracy: 0.8903\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.2032 - accuracy: 0.9709 - val_loss: 2.3126 - val_accuracy: 0.9032\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.9834 - accuracy: 0.9596 - val_loss: 2.1074 - val_accuracy: 0.8323\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7110 - accuracy: 0.9806 - val_loss: 1.7984 - val_accuracy: 0.9097\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5089 - accuracy: 0.9790 - val_loss: 1.7127 - val_accuracy: 0.8774\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.3116 - accuracy: 0.9919 - val_loss: 1.4439 - val_accuracy: 0.9097\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1523 - accuracy: 0.9952 - val_loss: 1.3393 - val_accuracy: 0.8903\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0111 - accuracy: 0.9968 - val_loss: 1.2670 - val_accuracy: 0.8774\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8857 - accuracy: 0.9984 - val_loss: 1.1508 - val_accuracy: 0.9032\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7758 - accuracy: 1.0000 - val_loss: 1.1702 - val_accuracy: 0.8581\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6823 - accuracy: 1.0000 - val_loss: 0.9236 - val_accuracy: 0.9161\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6011 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.8452\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5286 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.9226\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4654 - accuracy: 1.0000 - val_loss: 0.7346 - val_accuracy: 0.9161\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4092 - accuracy: 1.0000 - val_loss: 0.6592 - val_accuracy: 0.9161\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3600 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8903\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3169 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 0.8839\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2789 - accuracy: 1.0000 - val_loss: 0.5808 - val_accuracy: 0.8968\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2456 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.8968\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.9032\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1906 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9032\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1679 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.8968\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1479 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.8903\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1306 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9097\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9032\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.9097\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9032\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9032\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.8774\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.8839\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9032\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.9097\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9032\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.9097\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9032\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9290\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.8968\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.8839\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9032\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.8968\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.8903\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.8968\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9032\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.8581\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9355\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.9767 - val_accuracy: 0.8452\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.9032\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9032\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9032\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9097\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9097\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9226\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9097\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9097\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9226\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9161\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9226\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9161\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9097\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9226\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.8903\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9161\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.8968\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.8968\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9161\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8710\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9161\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.9226\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.8903\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.8774\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8774\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9226\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9226\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.8968\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.7747e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9226\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.0114e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9161\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.5801e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9097\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.2745e-04 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9226\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.9085e-04 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.8903\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.4287e-04 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9097\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.4577e-04 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9226\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.8385e-04 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9226\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9161\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.3224e-04 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9161\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.3707e-04 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.8710\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.4934e-04 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.8968\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.6389e-04 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.8968\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.6941e-04 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9097\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.3209e-04 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.8968\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.9045e-04 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9097\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.6297e-04 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9032\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.4811e-04 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.9032\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.3687e-04 - accuracy: 1.0000 - val_loss: 0.5400 - val_accuracy: 0.8710\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.2660e-04 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9161\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.8960e-04 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9097\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.7507e-04 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8774\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.5145e-04 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.9161\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.5126e-04 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.8839\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.3372e-04 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9226\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0379 - val_accuracy: 0.7677\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.1253 - accuracy: 0.3570 - val_loss: 0.8659 - val_accuracy: 0.3032\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.9288 - accuracy: 0.3183 - val_loss: 0.9835 - val_accuracy: 0.3032\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9935 - accuracy: 0.5024 - val_loss: 0.9936 - val_accuracy: 0.6903\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9801 - accuracy: 0.6171 - val_loss: 0.9495 - val_accuracy: 0.6968\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.9370 - accuracy: 0.6640 - val_loss: 0.9181 - val_accuracy: 0.6968\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8928 - accuracy: 0.6672 - val_loss: 0.8345 - val_accuracy: 0.6968\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8836 - accuracy: 0.6381 - val_loss: 0.8609 - val_accuracy: 0.6968\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8359 - accuracy: 0.6575 - val_loss: 0.8096 - val_accuracy: 0.6968\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8300 - accuracy: 0.6527 - val_loss: 0.7843 - val_accuracy: 0.6968\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7885 - accuracy: 0.6753 - val_loss: 0.7763 - val_accuracy: 0.6968\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7703 - accuracy: 0.6801 - val_loss: 0.7371 - val_accuracy: 0.6968\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7588 - accuracy: 0.6801 - val_loss: 0.7206 - val_accuracy: 0.6968\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7769 - accuracy: 0.6785 - val_loss: 0.7517 - val_accuracy: 0.6968\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7422 - accuracy: 0.6817 - val_loss: 0.7608 - val_accuracy: 0.6968\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7231 - accuracy: 0.6801 - val_loss: 0.6831 - val_accuracy: 0.6968\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6856 - accuracy: 0.6834 - val_loss: 0.6949 - val_accuracy: 0.6968\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6801 - accuracy: 0.6850 - val_loss: 0.6664 - val_accuracy: 0.6968\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6718 - accuracy: 0.6866 - val_loss: 0.6498 - val_accuracy: 0.7226\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6323 - accuracy: 0.7092 - val_loss: 0.6234 - val_accuracy: 0.7548\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6190 - accuracy: 0.7722 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6327 - accuracy: 0.7609 - val_loss: 0.5928 - val_accuracy: 0.7161\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6215 - accuracy: 0.7593 - val_loss: 0.5628 - val_accuracy: 0.7484\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5855 - accuracy: 0.7948 - val_loss: 0.5428 - val_accuracy: 0.7742\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5935 - accuracy: 0.8158 - val_loss: 0.5544 - val_accuracy: 0.8258\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5323 - accuracy: 0.7997 - val_loss: 0.5699 - val_accuracy: 0.8065\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5324 - accuracy: 0.8288 - val_loss: 0.5874 - val_accuracy: 0.8129\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5388 - accuracy: 0.8126 - val_loss: 0.5629 - val_accuracy: 0.8194\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5302 - accuracy: 0.8061 - val_loss: 0.6346 - val_accuracy: 0.8452\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5088 - accuracy: 0.8368 - val_loss: 0.5614 - val_accuracy: 0.8065\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5011 - accuracy: 0.8142 - val_loss: 0.5913 - val_accuracy: 0.8065\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5004 - accuracy: 0.8352 - val_loss: 0.5233 - val_accuracy: 0.8065\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4307 - accuracy: 0.8530 - val_loss: 0.6145 - val_accuracy: 0.7032\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6579 - accuracy: 0.7431 - val_loss: 0.6735 - val_accuracy: 0.7613\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5740 - accuracy: 0.7884 - val_loss: 0.5649 - val_accuracy: 0.7613\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5050 - accuracy: 0.8191 - val_loss: 0.5245 - val_accuracy: 0.8323\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4648 - accuracy: 0.8465 - val_loss: 0.6263 - val_accuracy: 0.7742\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4995 - accuracy: 0.8061 - val_loss: 0.7469 - val_accuracy: 0.7097\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5017 - accuracy: 0.8223 - val_loss: 0.4768 - val_accuracy: 0.8258\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4474 - accuracy: 0.8481 - val_loss: 0.4870 - val_accuracy: 0.8194\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4442 - accuracy: 0.8514 - val_loss: 0.4831 - val_accuracy: 0.8194\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4396 - accuracy: 0.8401 - val_loss: 0.4513 - val_accuracy: 0.8387\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3847 - accuracy: 0.8659 - val_loss: 0.4806 - val_accuracy: 0.8194\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4367 - accuracy: 0.8481 - val_loss: 0.5377 - val_accuracy: 0.8194\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4174 - accuracy: 0.8611 - val_loss: 0.5497 - val_accuracy: 0.8194\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4187 - accuracy: 0.8481 - val_loss: 0.6475 - val_accuracy: 0.7484\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3752 - accuracy: 0.8853 - val_loss: 0.4791 - val_accuracy: 0.8194\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3556 - accuracy: 0.8724 - val_loss: 0.5261 - val_accuracy: 0.8194\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3545 - accuracy: 0.8788 - val_loss: 0.4598 - val_accuracy: 0.8065\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3714 - accuracy: 0.8724 - val_loss: 0.4526 - val_accuracy: 0.8387\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3789 - accuracy: 0.8691 - val_loss: 0.5513 - val_accuracy: 0.7871\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3592 - accuracy: 0.8869 - val_loss: 0.4665 - val_accuracy: 0.8516\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3333 - accuracy: 0.8950 - val_loss: 0.5022 - val_accuracy: 0.7806\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3184 - accuracy: 0.8950 - val_loss: 0.5200 - val_accuracy: 0.8065\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2984 - accuracy: 0.9031 - val_loss: 0.5800 - val_accuracy: 0.8129\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2926 - accuracy: 0.9257 - val_loss: 0.4570 - val_accuracy: 0.8387\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3516 - accuracy: 0.9047 - val_loss: 0.4827 - val_accuracy: 0.8065\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3216 - accuracy: 0.8837 - val_loss: 0.5796 - val_accuracy: 0.7935\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2467 - accuracy: 0.9338 - val_loss: 0.6963 - val_accuracy: 0.8258\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2444 - accuracy: 0.9338 - val_loss: 0.5501 - val_accuracy: 0.8129\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2489 - accuracy: 0.9321 - val_loss: 0.4809 - val_accuracy: 0.8258\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2302 - accuracy: 0.9402 - val_loss: 0.4192 - val_accuracy: 0.8516\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2168 - accuracy: 0.9548 - val_loss: 0.5360 - val_accuracy: 0.8323\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1866 - accuracy: 0.9661 - val_loss: 0.4846 - val_accuracy: 0.8710\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2076 - accuracy: 0.9499 - val_loss: 0.5706 - val_accuracy: 0.8129\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2100 - accuracy: 0.9483 - val_loss: 0.7135 - val_accuracy: 0.8065\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1701 - accuracy: 0.9693 - val_loss: 0.5472 - val_accuracy: 0.8387\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1659 - accuracy: 0.9661 - val_loss: 0.6350 - val_accuracy: 0.8129\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1838 - accuracy: 0.9548 - val_loss: 0.6313 - val_accuracy: 0.8065\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1698 - accuracy: 0.9742 - val_loss: 0.4919 - val_accuracy: 0.8452\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1597 - accuracy: 0.9661 - val_loss: 0.6017 - val_accuracy: 0.8452\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1282 - accuracy: 0.9806 - val_loss: 0.7403 - val_accuracy: 0.8129\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1470 - accuracy: 0.9790 - val_loss: 0.5809 - val_accuracy: 0.8452\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1254 - accuracy: 0.9790 - val_loss: 0.6279 - val_accuracy: 0.8645\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6279 - accuracy: 0.8645\n",
            "Test Loss: 0.627925455570221, Test Accuracy: 0.8645161390304565\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 51ms/step - loss: 48.7870 - accuracy: 0.6565 - val_loss: 46.3022 - val_accuracy: 0.7273\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 44.3866 - accuracy: 0.6742 - val_loss: 42.0115 - val_accuracy: 0.7273\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 40.2242 - accuracy: 0.6742 - val_loss: 38.0130 - val_accuracy: 0.7273\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 36.3212 - accuracy: 0.6742 - val_loss: 34.2888 - val_accuracy: 0.7338\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 32.7879 - accuracy: 0.6839 - val_loss: 30.9134 - val_accuracy: 0.7403\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 29.5461 - accuracy: 0.7387 - val_loss: 27.8663 - val_accuracy: 0.7597\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 26.5812 - accuracy: 0.8210 - val_loss: 25.0701 - val_accuracy: 0.8052\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 23.8881 - accuracy: 0.8339 - val_loss: 22.5385 - val_accuracy: 0.7857\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.4744 - accuracy: 0.8387 - val_loss: 20.2251 - val_accuracy: 0.8571\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.2662 - accuracy: 0.8565 - val_loss: 18.1948 - val_accuracy: 0.8052\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 17.2570 - accuracy: 0.8597 - val_loss: 16.3340 - val_accuracy: 0.7597\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.4542 - accuracy: 0.8774 - val_loss: 14.6328 - val_accuracy: 0.7987\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.8288 - accuracy: 0.8742 - val_loss: 13.1141 - val_accuracy: 0.7922\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 12.3735 - accuracy: 0.8758 - val_loss: 11.7379 - val_accuracy: 0.8052\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 11.0261 - accuracy: 0.9048 - val_loss: 10.4908 - val_accuracy: 0.8247\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.8143 - accuracy: 0.9323 - val_loss: 9.3452 - val_accuracy: 0.8571\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 8.7162 - accuracy: 0.9581 - val_loss: 8.4353 - val_accuracy: 0.8442\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.7664 - accuracy: 0.9532 - val_loss: 7.4302 - val_accuracy: 0.8442\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.8941 - accuracy: 0.9645 - val_loss: 6.8834 - val_accuracy: 0.8506\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.1211 - accuracy: 0.9694 - val_loss: 5.9724 - val_accuracy: 0.8377\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.4533 - accuracy: 0.9516 - val_loss: 5.3791 - val_accuracy: 0.8247\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.8152 - accuracy: 0.9581 - val_loss: 4.8794 - val_accuracy: 0.8377\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.2437 - accuracy: 0.9823 - val_loss: 4.4535 - val_accuracy: 0.7662\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.7519 - accuracy: 0.9774 - val_loss: 3.9077 - val_accuracy: 0.8312\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.3058 - accuracy: 0.9839 - val_loss: 3.6155 - val_accuracy: 0.8831\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.9013 - accuracy: 0.9968 - val_loss: 3.3291 - val_accuracy: 0.8571\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.5461 - accuracy: 0.9968 - val_loss: 2.8318 - val_accuracy: 0.8961\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.2267 - accuracy: 0.9968 - val_loss: 2.7782 - val_accuracy: 0.8377\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.0168 - accuracy: 0.9694 - val_loss: 2.2444 - val_accuracy: 0.8961\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.8060 - accuracy: 0.9661 - val_loss: 2.3752 - val_accuracy: 0.8506\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5965 - accuracy: 0.9661 - val_loss: 1.9218 - val_accuracy: 0.8701\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3627 - accuracy: 0.9952 - val_loss: 1.7660 - val_accuracy: 0.8506\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1866 - accuracy: 0.9968 - val_loss: 1.6850 - val_accuracy: 0.9156\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0416 - accuracy: 0.9968 - val_loss: 1.5695 - val_accuracy: 0.8896\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9114 - accuracy: 0.9984 - val_loss: 1.3872 - val_accuracy: 0.8831\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7970 - accuracy: 0.9968 - val_loss: 1.4018 - val_accuracy: 0.8312\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7023 - accuracy: 0.9952 - val_loss: 1.2118 - val_accuracy: 0.8831\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6104 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.9026\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5338 - accuracy: 1.0000 - val_loss: 0.9852 - val_accuracy: 0.9156\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4689 - accuracy: 1.0000 - val_loss: 0.9220 - val_accuracy: 0.9156\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4142 - accuracy: 0.9968 - val_loss: 1.1010 - val_accuracy: 0.8766\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3659 - accuracy: 0.9984 - val_loss: 0.9231 - val_accuracy: 0.8896\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3624 - accuracy: 0.9871 - val_loss: 1.1137 - val_accuracy: 0.8571\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3628 - accuracy: 0.9742 - val_loss: 0.7675 - val_accuracy: 0.9156\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3045 - accuracy: 0.9839 - val_loss: 0.7796 - val_accuracy: 0.9091\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2482 - accuracy: 0.9919 - val_loss: 0.6970 - val_accuracy: 0.8571\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2521 - accuracy: 0.9855 - val_loss: 0.6187 - val_accuracy: 0.8766\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1990 - accuracy: 0.9952 - val_loss: 0.6289 - val_accuracy: 0.8961\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1580 - accuracy: 1.0000 - val_loss: 0.6309 - val_accuracy: 0.8831\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1396 - accuracy: 0.9984 - val_loss: 0.7090 - val_accuracy: 0.9221\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1242 - accuracy: 0.9984 - val_loss: 0.9016 - val_accuracy: 0.8442\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1163 - accuracy: 0.9968 - val_loss: 0.7062 - val_accuracy: 0.8831\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1311 - accuracy: 0.9839 - val_loss: 0.5729 - val_accuracy: 0.8571\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1072 - accuracy: 0.9935 - val_loss: 0.5894 - val_accuracy: 0.8636\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1103 - accuracy: 0.9919 - val_loss: 0.5559 - val_accuracy: 0.9286\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0998 - accuracy: 0.9903 - val_loss: 0.6355 - val_accuracy: 0.8312\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0817 - accuracy: 0.9919 - val_loss: 0.6644 - val_accuracy: 0.8312\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0617 - accuracy: 0.9984 - val_loss: 0.6474 - val_accuracy: 0.8831\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.6355 - val_accuracy: 0.8961\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 0.8766\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.8831\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.5881 - val_accuracy: 0.8896\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.8896\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.5723 - val_accuracy: 0.9026\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.5674 - val_accuracy: 0.9026\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.9026\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.5390 - val_accuracy: 0.9026\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.5290 - val_accuracy: 0.9026\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.8961\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.8961\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8961\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.8961\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.8961\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.8961\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.9026\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 0.9026\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.9091\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.9026\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.9026\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.9026\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.9026\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.8961\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.8961\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.8961\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.9091\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5536 - val_accuracy: 0.9026\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.9026\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.9026\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.9091\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.9091\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5521 - val_accuracy: 0.9091\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.9091\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5517 - val_accuracy: 0.9091\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9026\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5927 - val_accuracy: 0.9026\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8831\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.8901 - val_accuracy: 0.8766\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0313 - accuracy: 0.9919 - val_loss: 0.8383 - val_accuracy: 0.8571\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1539 - accuracy: 0.9629 - val_loss: 0.6657 - val_accuracy: 0.8247\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1191 - accuracy: 0.9758 - val_loss: 0.9579 - val_accuracy: 0.7208\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2149 - accuracy: 0.9258 - val_loss: 0.6109 - val_accuracy: 0.8182\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0733 - accuracy: 0.9871 - val_loss: 0.8815 - val_accuracy: 0.8636\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1379 - accuracy: 0.9694 - val_loss: 0.5424 - val_accuracy: 0.8312\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0937 - accuracy: 0.9774 - val_loss: 0.4507 - val_accuracy: 0.8571\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0531 - accuracy: 0.9903 - val_loss: 0.5138 - val_accuracy: 0.8896\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.7247 - val_accuracy: 0.8831\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.8495 - val_accuracy: 0.9091\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.8775 - val_accuracy: 0.9026\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.9026\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.9026\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.9026\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.9026\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.7916 - val_accuracy: 0.9026\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.9026\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8240 - val_accuracy: 0.9026\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8112 - val_accuracy: 0.9026\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.9026\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8187 - val_accuracy: 0.9026\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.8250 - val_accuracy: 0.9026\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8499 - val_accuracy: 0.9026\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8623 - val_accuracy: 0.8961\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 0.9026\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.9026\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8384 - val_accuracy: 0.9026\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7872 - val_accuracy: 0.9026\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8586 - val_accuracy: 0.8961\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8332 - val_accuracy: 0.9026\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.9026\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.9026\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.9026\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7881 - val_accuracy: 0.8961\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.8961\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.8961\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.9026\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0385 - accuracy: 0.9839 - val_loss: 0.4307 - val_accuracy: 0.8896\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0957 - accuracy: 0.9758 - val_loss: 0.5727 - val_accuracy: 0.8442\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0282 - accuracy: 0.9984 - val_loss: 0.7644 - val_accuracy: 0.8571\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0642 - accuracy: 0.9790 - val_loss: 0.8543 - val_accuracy: 0.8052\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0448 - accuracy: 0.9919 - val_loss: 0.5931 - val_accuracy: 0.8961\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0290 - accuracy: 0.9935 - val_loss: 0.8857 - val_accuracy: 0.8312\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0289 - accuracy: 0.9968 - val_loss: 0.8862 - val_accuracy: 0.8636\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0510 - accuracy: 0.9903 - val_loss: 0.4681 - val_accuracy: 0.8831\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0182 - accuracy: 0.9984 - val_loss: 0.4200 - val_accuracy: 0.8896\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.5553 - val_accuracy: 0.8701\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.9026\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0151 - accuracy: 0.9984 - val_loss: 0.7583 - val_accuracy: 0.8701\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0135 - accuracy: 0.9984 - val_loss: 0.6274 - val_accuracy: 0.8831\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.6814 - val_accuracy: 0.8571\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0430 - accuracy: 0.9903 - val_loss: 0.9673 - val_accuracy: 0.7662\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0538 - accuracy: 0.9806 - val_loss: 0.4761 - val_accuracy: 0.8961\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0307 - accuracy: 0.9952 - val_loss: 0.5730 - val_accuracy: 0.8766\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.7094 - val_accuracy: 0.8896\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.9026\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.7793 - val_accuracy: 0.8896\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.8961\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.8961\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.9026\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.7428 - val_accuracy: 0.9026\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.9026\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.9026\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.9026\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.9091\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.9091\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 0.9026\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.9091\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.9156\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6577 - val_accuracy: 0.9156\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.9156\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6517 - val_accuracy: 0.9156\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.9156\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.9221\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6415 - val_accuracy: 0.9221\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.9221\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 0.9221\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.9221\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6273 - val_accuracy: 0.9156\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.9156\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6262 - val_accuracy: 0.9156\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 0.9156\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.9156\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.9156\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6135 - val_accuracy: 0.9156\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.9156\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.9156\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.9156\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.9156\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.9156\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5971 - val_accuracy: 0.9156\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.9156\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.9156\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9156\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6121 - val_accuracy: 0.9221\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6130 - val_accuracy: 0.9221\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6095 - val_accuracy: 0.9221\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.9221\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5941 - val_accuracy: 0.9221\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.9221\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.9221\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6090 - val_accuracy: 0.9221\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9221\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6133 - accuracy: 0.9221\n",
            "Test Loss: 0.6133467555046082, Test Accuracy: 0.9220778942108154\n",
            "\n",
            "Average Accuracy Across All Folds: 0.8489317059516907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdamW + Random 증강 + L2규제 + dropout 3개 + Early stopping : 0.8811646461486816\n"
      ],
      "metadata": {
        "id": "J6WjR8npK4sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import AdamW\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model_with_early_stopping():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model_with_early_stopping()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB1TmlvvImwB",
        "outputId": "552d6a9e-58ef-4c5d-c10e-d08fefe8c06c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 62ms/step - loss: 48.6130 - accuracy: 0.6785 - val_loss: 46.0315 - val_accuracy: 0.6323\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 44.0917 - accuracy: 0.6979 - val_loss: 41.7011 - val_accuracy: 0.6323\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 39.9037 - accuracy: 0.6979 - val_loss: 37.7825 - val_accuracy: 0.6323\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 36.0235 - accuracy: 0.6979 - val_loss: 33.9805 - val_accuracy: 0.6323\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 32.4411 - accuracy: 0.7060 - val_loss: 30.7263 - val_accuracy: 0.7161\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 29.1959 - accuracy: 0.8142 - val_loss: 27.5896 - val_accuracy: 0.7613\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 26.2492 - accuracy: 0.8546 - val_loss: 24.8526 - val_accuracy: 0.7806\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 23.5906 - accuracy: 0.8643 - val_loss: 22.2676 - val_accuracy: 0.8194\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.2249 - accuracy: 0.8352 - val_loss: 19.9966 - val_accuracy: 0.7613\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 18.9869 - accuracy: 0.8691 - val_loss: 17.9541 - val_accuracy: 0.7935\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 17.0010 - accuracy: 0.8805 - val_loss: 16.0599 - val_accuracy: 0.8258\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.1875 - accuracy: 0.9208 - val_loss: 14.3744 - val_accuracy: 0.8323\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 13.5820 - accuracy: 0.9305 - val_loss: 12.8970 - val_accuracy: 0.7871\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 12.1330 - accuracy: 0.9273 - val_loss: 11.5500 - val_accuracy: 0.8129\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.8468 - accuracy: 0.9273 - val_loss: 10.3752 - val_accuracy: 0.8258\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.6155 - accuracy: 0.9596 - val_loss: 9.2583 - val_accuracy: 0.8323\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 8.5389 - accuracy: 0.9515 - val_loss: 8.8985 - val_accuracy: 0.7355\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 7.8131 - accuracy: 0.8239 - val_loss: 7.3759 - val_accuracy: 0.7613\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 6.8442 - accuracy: 0.9063 - val_loss: 6.7214 - val_accuracy: 0.8000\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 6.0005 - accuracy: 0.9580 - val_loss: 5.8754 - val_accuracy: 0.8516\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.4177 - accuracy: 0.9289 - val_loss: 5.2206 - val_accuracy: 0.8387\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.8733 - accuracy: 0.9176 - val_loss: 4.6506 - val_accuracy: 0.8258\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.2647 - accuracy: 0.9499 - val_loss: 4.2373 - val_accuracy: 0.8581\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6939 - accuracy: 0.9822 - val_loss: 4.0478 - val_accuracy: 0.8581\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.2487 - accuracy: 0.9935 - val_loss: 3.8025 - val_accuracy: 0.8129\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.8996 - accuracy: 0.9887 - val_loss: 3.5218 - val_accuracy: 0.8387\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.5940 - accuracy: 0.9774 - val_loss: 2.8263 - val_accuracy: 0.8194\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.2647 - accuracy: 0.9887 - val_loss: 2.7333 - val_accuracy: 0.8452\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.9843 - accuracy: 0.9968 - val_loss: 2.4861 - val_accuracy: 0.8581\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7479 - accuracy: 0.9984 - val_loss: 2.4904 - val_accuracy: 0.8387\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.5420 - accuracy: 0.9984 - val_loss: 2.4716 - val_accuracy: 0.8323\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.3601 - accuracy: 0.9984 - val_loss: 2.1510 - val_accuracy: 0.8258\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.2040 - accuracy: 0.9968 - val_loss: 1.8433 - val_accuracy: 0.8645\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0617 - accuracy: 0.9984 - val_loss: 1.8319 - val_accuracy: 0.8452\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.9323 - accuracy: 1.0000 - val_loss: 1.7615 - val_accuracy: 0.8323\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.8207 - accuracy: 1.0000 - val_loss: 1.6823 - val_accuracy: 0.8194\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7230 - accuracy: 1.0000 - val_loss: 1.5438 - val_accuracy: 0.8194\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6371 - accuracy: 1.0000 - val_loss: 1.4201 - val_accuracy: 0.8387\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5613 - accuracy: 1.0000 - val_loss: 1.3489 - val_accuracy: 0.8387\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4947 - accuracy: 1.0000 - val_loss: 1.2693 - val_accuracy: 0.8452\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4362 - accuracy: 1.0000 - val_loss: 1.2027 - val_accuracy: 0.8452\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3846 - accuracy: 1.0000 - val_loss: 1.1636 - val_accuracy: 0.8516\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3392 - accuracy: 1.0000 - val_loss: 1.1363 - val_accuracy: 0.8452\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2993 - accuracy: 1.0000 - val_loss: 1.1218 - val_accuracy: 0.8452\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2641 - accuracy: 1.0000 - val_loss: 1.1068 - val_accuracy: 0.8452\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2333 - accuracy: 1.0000 - val_loss: 1.0795 - val_accuracy: 0.8452\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.0663 - val_accuracy: 0.8516\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1820 - accuracy: 1.0000 - val_loss: 1.0408 - val_accuracy: 0.8516\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1610 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.8516\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1424 - accuracy: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.8516\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1261 - accuracy: 1.0000 - val_loss: 1.0031 - val_accuracy: 0.8516\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1116 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.8516\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0989 - accuracy: 1.0000 - val_loss: 0.9829 - val_accuracy: 0.8581\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.9290 - val_accuracy: 0.8516\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.8516\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.8516\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.9348 - val_accuracy: 0.8516\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.8581\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.9234 - val_accuracy: 0.8516\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.9018 - val_accuracy: 0.8516\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.8516\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.8452\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.8581\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.9441 - val_accuracy: 0.8516\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.9237 - val_accuracy: 0.8452\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.9350 - val_accuracy: 0.8516\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.8676 - val_accuracy: 0.8452\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2173 - val_accuracy: 0.8323\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.1131 - val_accuracy: 0.8452\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.8387\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.9204 - val_accuracy: 0.8387\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.8387\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.8452\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.9074 - val_accuracy: 0.8452\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8922 - val_accuracy: 0.8452\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.8452\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.8452\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8675 - accuracy: 0.8452\n",
            "Test Loss: 0.8675389289855957, Test Accuracy: 0.8451613187789917\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7fc5a0612440>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 101, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 5s 60ms/step - loss: 48.6603 - accuracy: 0.6543 - val_loss: 46.0083 - val_accuracy: 0.7161\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 44.2107 - accuracy: 0.6769 - val_loss: 41.8169 - val_accuracy: 0.7161\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 40.0291 - accuracy: 0.6769 - val_loss: 37.7434 - val_accuracy: 0.7161\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 36.1550 - accuracy: 0.6769 - val_loss: 34.0387 - val_accuracy: 0.7161\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 32.5919 - accuracy: 0.6769 - val_loss: 30.7339 - val_accuracy: 0.7161\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 29.3697 - accuracy: 0.6769 - val_loss: 27.6597 - val_accuracy: 0.7161\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 26.4342 - accuracy: 0.6769 - val_loss: 24.8700 - val_accuracy: 0.7161\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 23.7587 - accuracy: 0.6834 - val_loss: 22.2866 - val_accuracy: 0.8065\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 21.3104 - accuracy: 0.7738 - val_loss: 19.9808 - val_accuracy: 0.8194\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 19.1019 - accuracy: 0.8223 - val_loss: 17.8947 - val_accuracy: 0.8710\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 17.1021 - accuracy: 0.8675 - val_loss: 16.0470 - val_accuracy: 0.8516\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 15.3246 - accuracy: 0.8724 - val_loss: 14.3659 - val_accuracy: 0.8323\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 13.6927 - accuracy: 0.8756 - val_loss: 12.8232 - val_accuracy: 0.8774\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 12.2236 - accuracy: 0.9208 - val_loss: 11.5559 - val_accuracy: 0.8516\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 10.9815 - accuracy: 0.8562 - val_loss: 10.3046 - val_accuracy: 0.8710\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.7344 - accuracy: 0.9289 - val_loss: 9.2815 - val_accuracy: 0.8258\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 8.6476 - accuracy: 0.9418 - val_loss: 8.2304 - val_accuracy: 0.8065\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.6643 - accuracy: 0.9435 - val_loss: 7.8679 - val_accuracy: 0.8839\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.0049 - accuracy: 0.8562 - val_loss: 6.5768 - val_accuracy: 0.8581\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.1821 - accuracy: 0.8643 - val_loss: 5.8154 - val_accuracy: 0.8839\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 5.3673 - accuracy: 0.9499 - val_loss: 5.3022 - val_accuracy: 0.8710\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.7949 - accuracy: 0.9435 - val_loss: 4.6613 - val_accuracy: 0.8581\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.2918 - accuracy: 0.9273 - val_loss: 4.1927 - val_accuracy: 0.8516\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6979 - accuracy: 0.9806 - val_loss: 3.9296 - val_accuracy: 0.8581\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.2684 - accuracy: 0.9871 - val_loss: 3.7021 - val_accuracy: 0.8516\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.9530 - accuracy: 0.9548 - val_loss: 2.9772 - val_accuracy: 0.8581\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.6251 - accuracy: 0.9596 - val_loss: 2.6402 - val_accuracy: 0.8710\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.2640 - accuracy: 0.9871 - val_loss: 2.5645 - val_accuracy: 0.8839\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.9934 - accuracy: 0.9919 - val_loss: 2.6042 - val_accuracy: 0.8968\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.7543 - accuracy: 0.9935 - val_loss: 2.3517 - val_accuracy: 0.8516\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5565 - accuracy: 0.9887 - val_loss: 1.9529 - val_accuracy: 0.8645\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.3577 - accuracy: 0.9968 - val_loss: 1.6782 - val_accuracy: 0.8774\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.1941 - accuracy: 1.0000 - val_loss: 1.6442 - val_accuracy: 0.8710\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0485 - accuracy: 1.0000 - val_loss: 1.7122 - val_accuracy: 0.9032\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9248 - accuracy: 0.9984 - val_loss: 1.6841 - val_accuracy: 0.8774\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9439 - accuracy: 0.9677 - val_loss: 1.8127 - val_accuracy: 0.8000\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9733 - accuracy: 0.9208 - val_loss: 1.0338 - val_accuracy: 0.8387\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7344 - accuracy: 0.9677 - val_loss: 1.1459 - val_accuracy: 0.8710\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5946 - accuracy: 0.9935 - val_loss: 1.0408 - val_accuracy: 0.8774\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5150 - accuracy: 0.9968 - val_loss: 1.1333 - val_accuracy: 0.8710\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4521 - accuracy: 0.9984 - val_loss: 1.1743 - val_accuracy: 0.8839\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3973 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.8903\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3492 - accuracy: 1.0000 - val_loss: 0.9290 - val_accuracy: 0.8903\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3081 - accuracy: 1.0000 - val_loss: 0.8821 - val_accuracy: 0.8903\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2720 - accuracy: 1.0000 - val_loss: 0.8541 - val_accuracy: 0.8903\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2405 - accuracy: 1.0000 - val_loss: 0.8372 - val_accuracy: 0.8903\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.8903\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1883 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.8903\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1667 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.8903\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.8839\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.8103 - val_accuracy: 0.8839\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1165 - accuracy: 1.0000 - val_loss: 0.8214 - val_accuracy: 0.8839\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1035 - accuracy: 1.0000 - val_loss: 0.8293 - val_accuracy: 0.8839\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.8309 - val_accuracy: 0.8839\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.8338 - val_accuracy: 0.8839\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.8369 - val_accuracy: 0.8839\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.8362 - val_accuracy: 0.8839\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.8175 - val_accuracy: 0.8839\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.8839\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.7922 - val_accuracy: 0.8839\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.8839\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8839\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.8839\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.7757 - val_accuracy: 0.8839\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.7836 - val_accuracy: 0.8903\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.7704 - val_accuracy: 0.8839\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.7626 - val_accuracy: 0.8903\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.8839\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.7766 - val_accuracy: 0.8774\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.8968\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0510 - accuracy: 0.9887 - val_loss: 0.7373 - val_accuracy: 0.8258\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0627 - accuracy: 0.9871 - val_loss: 0.7185 - val_accuracy: 0.8774\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0640 - accuracy: 0.9952 - val_loss: 0.5418 - val_accuracy: 0.8839\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0505 - accuracy: 0.9919 - val_loss: 0.4759 - val_accuracy: 0.8581\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0815 - accuracy: 0.9822 - val_loss: 0.6011 - val_accuracy: 0.8452\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1103 - accuracy: 0.9725 - val_loss: 0.4674 - val_accuracy: 0.8710\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0642 - accuracy: 0.9903 - val_loss: 0.4519 - val_accuracy: 0.8710\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9984 - val_loss: 0.6668 - val_accuracy: 0.9032\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.8949 - val_accuracy: 0.8968\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.8903\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.8903\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.8903\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.8430 - val_accuracy: 0.8839\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.8903\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.7723 - val_accuracy: 0.8968\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.7602 - val_accuracy: 0.8968\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7715 - val_accuracy: 0.8968\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.8710\n",
            "Test Loss: 0.451890766620636, Test Accuracy: 0.8709677457809448\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 61ms/step - loss: 48.6905 - accuracy: 0.6672 - val_loss: 46.1340 - val_accuracy: 0.6516\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 44.1958 - accuracy: 0.6931 - val_loss: 41.8263 - val_accuracy: 0.6516\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 39.9961 - accuracy: 0.6931 - val_loss: 37.7954 - val_accuracy: 0.6516\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 36.1469 - accuracy: 0.6931 - val_loss: 34.1644 - val_accuracy: 0.6516\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 32.6190 - accuracy: 0.6931 - val_loss: 30.8031 - val_accuracy: 0.6516\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 29.4064 - accuracy: 0.7060 - val_loss: 27.7952 - val_accuracy: 0.6516\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 26.4660 - accuracy: 0.7221 - val_loss: 24.9503 - val_accuracy: 0.7161\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 23.7903 - accuracy: 0.7916 - val_loss: 22.4340 - val_accuracy: 0.8516\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 21.3837 - accuracy: 0.7997 - val_loss: 20.2007 - val_accuracy: 0.8000\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.2153 - accuracy: 0.7803 - val_loss: 18.0820 - val_accuracy: 0.8387\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 17.2033 - accuracy: 0.8336 - val_loss: 16.1806 - val_accuracy: 0.8516\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 15.4053 - accuracy: 0.8433 - val_loss: 14.5215 - val_accuracy: 0.8194\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 13.7859 - accuracy: 0.8756 - val_loss: 13.0550 - val_accuracy: 0.8258\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 12.3862 - accuracy: 0.8368 - val_loss: 11.6894 - val_accuracy: 0.8065\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 11.0458 - accuracy: 0.8675 - val_loss: 10.4176 - val_accuracy: 0.8258\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.8256 - accuracy: 0.8869 - val_loss: 9.2979 - val_accuracy: 0.9032\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 8.7188 - accuracy: 0.9305 - val_loss: 8.3995 - val_accuracy: 0.8774\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.8192 - accuracy: 0.9128 - val_loss: 7.4715 - val_accuracy: 0.8710\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 6.9215 - accuracy: 0.9321 - val_loss: 6.6228 - val_accuracy: 0.8903\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 6.1263 - accuracy: 0.9289 - val_loss: 5.9544 - val_accuracy: 0.8774\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 5.3869 - accuracy: 0.9709 - val_loss: 5.8987 - val_accuracy: 0.7871\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 4.9966 - accuracy: 0.8788 - val_loss: 4.9198 - val_accuracy: 0.7613\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 4.3686 - accuracy: 0.9063 - val_loss: 4.1644 - val_accuracy: 0.9097\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.7383 - accuracy: 0.9758 - val_loss: 4.0169 - val_accuracy: 0.8903\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.3674 - accuracy: 0.9725 - val_loss: 4.0688 - val_accuracy: 0.7548\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.2892 - accuracy: 0.7916 - val_loss: 3.1140 - val_accuracy: 0.8452\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.8997 - accuracy: 0.8772 - val_loss: 2.7767 - val_accuracy: 0.8581\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.5449 - accuracy: 0.9144 - val_loss: 2.4663 - val_accuracy: 0.9161\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.2185 - accuracy: 0.9612 - val_loss: 2.2332 - val_accuracy: 0.9161\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1.9237 - accuracy: 0.9919 - val_loss: 2.1395 - val_accuracy: 0.9097\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.6808 - accuracy: 0.9968 - val_loss: 1.9825 - val_accuracy: 0.9226\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.4486 - accuracy: 0.9887 - val_loss: 2.0285 - val_accuracy: 0.8581\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.5838 - accuracy: 0.8740 - val_loss: 1.5415 - val_accuracy: 0.8387\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.2637 - accuracy: 0.9386 - val_loss: 1.4262 - val_accuracy: 0.8645\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.0570 - accuracy: 0.9822 - val_loss: 1.3976 - val_accuracy: 0.8839\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8836 - accuracy: 0.9952 - val_loss: 1.5538 - val_accuracy: 0.9032\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7694 - accuracy: 0.9984 - val_loss: 1.5938 - val_accuracy: 0.8968\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.9935 - val_loss: 1.5031 - val_accuracy: 0.8903\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6302 - accuracy: 0.9838 - val_loss: 1.1036 - val_accuracy: 0.9290\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5793 - accuracy: 0.9838 - val_loss: 1.0017 - val_accuracy: 0.8968\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4886 - accuracy: 0.9968 - val_loss: 1.0134 - val_accuracy: 0.8968\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4201 - accuracy: 0.9984 - val_loss: 1.1459 - val_accuracy: 0.8968\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3715 - accuracy: 1.0000 - val_loss: 1.0664 - val_accuracy: 0.9290\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3389 - accuracy: 0.9952 - val_loss: 0.9206 - val_accuracy: 0.9161\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3104 - accuracy: 0.9935 - val_loss: 1.0539 - val_accuracy: 0.8839\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2703 - accuracy: 0.9935 - val_loss: 0.8898 - val_accuracy: 0.9032\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2414 - accuracy: 0.9968 - val_loss: 0.8374 - val_accuracy: 0.9097\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2137 - accuracy: 0.9984 - val_loss: 0.8987 - val_accuracy: 0.9097\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1872 - accuracy: 0.9984 - val_loss: 0.9383 - val_accuracy: 0.8839\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1646 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.8903\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1462 - accuracy: 1.0000 - val_loss: 0.8686 - val_accuracy: 0.9032\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.8373 - val_accuracy: 0.9097\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1166 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.9032\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.7651 - val_accuracy: 0.9097\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.7385 - val_accuracy: 0.9097\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.9097\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.9161\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.9161\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.9226\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.6758 - val_accuracy: 0.9161\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 0.9161\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.9161\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.9355\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.9355\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.9355\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.9290\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.9290\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.9290\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.9290\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.9226\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.9290\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.9226\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.9161\n",
            "Test Loss: 0.6672523617744446, Test Accuracy: 0.9161290526390076\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 61ms/step - loss: 48.6763 - accuracy: 0.6753 - val_loss: 46.0812 - val_accuracy: 0.6968\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 44.2258 - accuracy: 0.6817 - val_loss: 41.8117 - val_accuracy: 0.6968\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 40.0859 - accuracy: 0.6817 - val_loss: 37.8892 - val_accuracy: 0.6968\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 36.2308 - accuracy: 0.6817 - val_loss: 34.2025 - val_accuracy: 0.6968\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 32.7027 - accuracy: 0.6817 - val_loss: 30.8205 - val_accuracy: 0.6968\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 29.4584 - accuracy: 0.6817 - val_loss: 27.7348 - val_accuracy: 0.7290\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 26.5014 - accuracy: 0.7399 - val_loss: 24.8973 - val_accuracy: 0.7871\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 23.7944 - accuracy: 0.8174 - val_loss: 22.3580 - val_accuracy: 0.8194\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 21.3807 - accuracy: 0.8174 - val_loss: 20.1144 - val_accuracy: 0.8194\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 19.1608 - accuracy: 0.8433 - val_loss: 18.0053 - val_accuracy: 0.8645\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 17.1722 - accuracy: 0.8756 - val_loss: 16.1376 - val_accuracy: 0.8710\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 15.3640 - accuracy: 0.8756 - val_loss: 14.4590 - val_accuracy: 0.8323\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 13.7436 - accuracy: 0.8966 - val_loss: 12.9705 - val_accuracy: 0.8194\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 12.3343 - accuracy: 0.8465 - val_loss: 11.6330 - val_accuracy: 0.8323\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 11.0107 - accuracy: 0.8869 - val_loss: 10.3546 - val_accuracy: 0.8710\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.7931 - accuracy: 0.8982 - val_loss: 9.2391 - val_accuracy: 0.8839\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 8.6740 - accuracy: 0.9338 - val_loss: 8.3471 - val_accuracy: 0.8258\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.6588 - accuracy: 0.9402 - val_loss: 7.3849 - val_accuracy: 0.8710\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 6.7355 - accuracy: 0.9774 - val_loss: 6.5981 - val_accuracy: 0.9032\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.9862 - accuracy: 0.9693 - val_loss: 6.0289 - val_accuracy: 0.8387\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 5.3254 - accuracy: 0.9612 - val_loss: 5.2496 - val_accuracy: 0.8968\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 4.7059 - accuracy: 0.9822 - val_loss: 4.8379 - val_accuracy: 0.8710\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 4.2252 - accuracy: 0.9580 - val_loss: 4.4124 - val_accuracy: 0.7871\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 3.7311 - accuracy: 0.9532 - val_loss: 3.7724 - val_accuracy: 0.8581\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 3.2610 - accuracy: 0.9838 - val_loss: 3.5858 - val_accuracy: 0.8581\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.8729 - accuracy: 0.9919 - val_loss: 3.3311 - val_accuracy: 0.8387\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 2.5289 - accuracy: 0.9903 - val_loss: 3.2969 - val_accuracy: 0.7935\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.2556 - accuracy: 0.9838 - val_loss: 2.5644 - val_accuracy: 0.8452\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.9711 - accuracy: 0.9952 - val_loss: 2.3778 - val_accuracy: 0.8645\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.7400 - accuracy: 0.9919 - val_loss: 2.2933 - val_accuracy: 0.8903\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.5381 - accuracy: 0.9952 - val_loss: 1.8722 - val_accuracy: 0.8774\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.3454 - accuracy: 0.9968 - val_loss: 1.6691 - val_accuracy: 0.8710\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.1810 - accuracy: 1.0000 - val_loss: 1.6614 - val_accuracy: 0.8839\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0354 - accuracy: 1.0000 - val_loss: 1.6410 - val_accuracy: 0.8839\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9104 - accuracy: 1.0000 - val_loss: 1.5135 - val_accuracy: 0.8903\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8000 - accuracy: 1.0000 - val_loss: 1.3711 - val_accuracy: 0.8968\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.7029 - accuracy: 1.0000 - val_loss: 1.2491 - val_accuracy: 0.8968\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6175 - accuracy: 1.0000 - val_loss: 1.1509 - val_accuracy: 0.8968\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5426 - accuracy: 1.0000 - val_loss: 1.0725 - val_accuracy: 0.8968\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4768 - accuracy: 1.0000 - val_loss: 1.0172 - val_accuracy: 0.8968\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4190 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.9032\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3683 - accuracy: 1.0000 - val_loss: 0.9366 - val_accuracy: 0.8968\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3237 - accuracy: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.9032\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2845 - accuracy: 1.0000 - val_loss: 0.8663 - val_accuracy: 0.9032\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2501 - accuracy: 1.0000 - val_loss: 0.8334 - val_accuracy: 0.9097\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.9097\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1935 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.9097\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1702 - accuracy: 1.0000 - val_loss: 0.7718 - val_accuracy: 0.9097\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.1499 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.9097\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1318 - accuracy: 1.0000 - val_loss: 0.7367 - val_accuracy: 0.9097\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.9097\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.9097\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.9097\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 0.9032\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.9097\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.9097\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.9097\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.9097\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.9097\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.6485 - val_accuracy: 0.9097\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.9032\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.9097\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.6514 - val_accuracy: 0.9097\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.9097\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.9097\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.9097\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.9097\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.9097\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.9097\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.9097\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.6359 - val_accuracy: 0.9097\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 0.9097\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.9097\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.9097\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.9097\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 0.9097\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.9161\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6282 - val_accuracy: 0.9097\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6459 - val_accuracy: 0.9161\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6376 - val_accuracy: 0.9097\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.9161\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.9161\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7909 - val_accuracy: 0.8774\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.9097\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.9097\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.9097\n",
            "Test Loss: 0.619178295135498, Test Accuracy: 0.9096774458885193\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 62ms/step - loss: 48.6227 - accuracy: 0.6677 - val_loss: 45.9947 - val_accuracy: 0.7273\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 44.1212 - accuracy: 0.6742 - val_loss: 41.6540 - val_accuracy: 0.7273\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 39.9223 - accuracy: 0.6742 - val_loss: 37.6624 - val_accuracy: 0.7273\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 36.0443 - accuracy: 0.6742 - val_loss: 33.9666 - val_accuracy: 0.7273\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 32.4951 - accuracy: 0.6855 - val_loss: 30.5884 - val_accuracy: 0.7532\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 29.2214 - accuracy: 0.7629 - val_loss: 27.5206 - val_accuracy: 0.7662\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 26.2977 - accuracy: 0.7629 - val_loss: 24.7735 - val_accuracy: 0.7532\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 23.5893 - accuracy: 0.8242 - val_loss: 22.2064 - val_accuracy: 0.8377\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 21.1404 - accuracy: 0.8484 - val_loss: 19.9613 - val_accuracy: 0.7662\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 18.9614 - accuracy: 0.8629 - val_loss: 17.8885 - val_accuracy: 0.8442\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 16.9592 - accuracy: 0.8677 - val_loss: 16.0439 - val_accuracy: 0.8182\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 15.1763 - accuracy: 0.8694 - val_loss: 14.4592 - val_accuracy: 0.8442\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 13.5080 - accuracy: 0.9161 - val_loss: 12.9168 - val_accuracy: 0.8636\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 12.2833 - accuracy: 0.7113 - val_loss: 11.7523 - val_accuracy: 0.6299\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 10.9054 - accuracy: 0.8161 - val_loss: 10.2415 - val_accuracy: 0.8312\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.6737 - accuracy: 0.8548 - val_loss: 9.2086 - val_accuracy: 0.8182\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 8.5799 - accuracy: 0.9161 - val_loss: 8.2018 - val_accuracy: 0.8701\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 7.6145 - accuracy: 0.9274 - val_loss: 7.4105 - val_accuracy: 0.8377\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.7251 - accuracy: 0.9242 - val_loss: 6.6927 - val_accuracy: 0.8571\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.0557 - accuracy: 0.8855 - val_loss: 5.8597 - val_accuracy: 0.8377\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.2978 - accuracy: 0.9371 - val_loss: 5.2110 - val_accuracy: 0.8766\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.6556 - accuracy: 0.9484 - val_loss: 4.9356 - val_accuracy: 0.8571\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.1295 - accuracy: 0.9484 - val_loss: 4.2615 - val_accuracy: 0.8896\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.6279 - accuracy: 0.9677 - val_loss: 4.0477 - val_accuracy: 0.8506\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.1860 - accuracy: 0.9790 - val_loss: 3.5605 - val_accuracy: 0.8961\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.7984 - accuracy: 0.9887 - val_loss: 3.4720 - val_accuracy: 0.8247\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.4891 - accuracy: 0.9839 - val_loss: 3.0771 - val_accuracy: 0.8052\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.1871 - accuracy: 0.9823 - val_loss: 2.9080 - val_accuracy: 0.8896\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.9147 - accuracy: 0.9952 - val_loss: 2.5492 - val_accuracy: 0.8831\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.6710 - accuracy: 0.9984 - val_loss: 2.5702 - val_accuracy: 0.8571\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.5041 - accuracy: 0.9855 - val_loss: 2.1427 - val_accuracy: 0.8961\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.3557 - accuracy: 0.9758 - val_loss: 1.7246 - val_accuracy: 0.8442\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1781 - accuracy: 0.9823 - val_loss: 1.8614 - val_accuracy: 0.8571\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0058 - accuracy: 0.9984 - val_loss: 2.0834 - val_accuracy: 0.8831\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8878 - accuracy: 0.9952 - val_loss: 2.0879 - val_accuracy: 0.8571\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7911 - accuracy: 0.9952 - val_loss: 1.4893 - val_accuracy: 0.8377\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6962 - accuracy: 0.9952 - val_loss: 1.4839 - val_accuracy: 0.8636\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.6026 - accuracy: 0.9968 - val_loss: 1.9117 - val_accuracy: 0.8117\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5304 - accuracy: 0.9968 - val_loss: 1.4833 - val_accuracy: 0.8442\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4621 - accuracy: 0.9968 - val_loss: 1.5580 - val_accuracy: 0.8506\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.4232 - accuracy: 0.9952 - val_loss: 1.5579 - val_accuracy: 0.7922\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3894 - accuracy: 0.9919 - val_loss: 0.9781 - val_accuracy: 0.8701\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3254 - accuracy: 0.9968 - val_loss: 1.1953 - val_accuracy: 0.8701\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2816 - accuracy: 0.9984 - val_loss: 1.3749 - val_accuracy: 0.8636\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3751 - accuracy: 0.9645 - val_loss: 0.6762 - val_accuracy: 0.8312\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3062 - accuracy: 0.9677 - val_loss: 0.7889 - val_accuracy: 0.8442\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2179 - accuracy: 0.9903 - val_loss: 1.1517 - val_accuracy: 0.8766\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1772 - accuracy: 1.0000 - val_loss: 1.5416 - val_accuracy: 0.8701\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 1.5776 - val_accuracy: 0.8701\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 1.4610 - val_accuracy: 0.8701\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1199 - accuracy: 1.0000 - val_loss: 1.3112 - val_accuracy: 0.8766\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1051 - accuracy: 1.0000 - val_loss: 1.1761 - val_accuracy: 0.8766\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0925 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.8701\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 1.0342 - val_accuracy: 0.8766\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 1.0130 - val_accuracy: 0.8701\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.8312\n",
            "Test Loss: 0.6761738061904907, Test Accuracy: 0.8311688303947449\n",
            "\n",
            "Average Accuracy Across All Folds: 0.8746208786964417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdamW + Random 증강 + L2규제 + dropout 3개 + Early stopping + epoch 150 + batch_noramalization : 0.9147465348243713\n"
      ],
      "metadata": {
        "id": "ylx07pRXfLTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import AdamW\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model_with_early_stopping():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model_with_early_stopping()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=150, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0tlj1JwfLjg",
        "outputId": "bf3befd1-115c-4248-b766-9ff904896f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "10/10 [==============================] - 9s 91ms/step - loss: 50.4873 - accuracy: 0.5380 - val_loss: 49.4637 - val_accuracy: 0.6323\n",
            "Epoch 2/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 49.0633 - accuracy: 0.6834 - val_loss: 48.2314 - val_accuracy: 0.6323\n",
            "Epoch 3/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 47.6388 - accuracy: 0.7835 - val_loss: 47.0216 - val_accuracy: 0.6323\n",
            "Epoch 4/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 46.2798 - accuracy: 0.8465 - val_loss: 45.8221 - val_accuracy: 0.6323\n",
            "Epoch 5/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 44.8349 - accuracy: 0.9047 - val_loss: 44.6742 - val_accuracy: 0.6323\n",
            "Epoch 6/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 43.4430 - accuracy: 0.9467 - val_loss: 43.5412 - val_accuracy: 0.6323\n",
            "Epoch 7/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 42.0354 - accuracy: 0.9855 - val_loss: 42.4371 - val_accuracy: 0.6323\n",
            "Epoch 8/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 40.7204 - accuracy: 0.9806 - val_loss: 41.3003 - val_accuracy: 0.6323\n",
            "Epoch 9/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 39.3406 - accuracy: 0.9903 - val_loss: 40.1420 - val_accuracy: 0.6323\n",
            "Epoch 10/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 38.0127 - accuracy: 0.9919 - val_loss: 38.8753 - val_accuracy: 0.6323\n",
            "Epoch 11/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 36.6796 - accuracy: 0.9952 - val_loss: 37.6950 - val_accuracy: 0.6323\n",
            "Epoch 12/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 35.3633 - accuracy: 0.9919 - val_loss: 36.4391 - val_accuracy: 0.6323\n",
            "Epoch 13/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 34.0702 - accuracy: 0.9968 - val_loss: 35.2571 - val_accuracy: 0.6323\n",
            "Epoch 14/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 32.8307 - accuracy: 0.9903 - val_loss: 33.8296 - val_accuracy: 0.6323\n",
            "Epoch 15/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 31.5558 - accuracy: 0.9984 - val_loss: 32.6040 - val_accuracy: 0.6323\n",
            "Epoch 16/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 30.3427 - accuracy: 0.9984 - val_loss: 31.4556 - val_accuracy: 0.6323\n",
            "Epoch 17/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 29.1598 - accuracy: 0.9968 - val_loss: 30.1942 - val_accuracy: 0.6323\n",
            "Epoch 18/150\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 28.0106 - accuracy: 0.9968 - val_loss: 28.9484 - val_accuracy: 0.6323\n",
            "Epoch 19/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 26.8807 - accuracy: 0.9984 - val_loss: 27.9485 - val_accuracy: 0.6323\n",
            "Epoch 20/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 25.7913 - accuracy: 0.9984 - val_loss: 26.9885 - val_accuracy: 0.6323\n",
            "Epoch 21/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 24.7347 - accuracy: 1.0000 - val_loss: 25.8360 - val_accuracy: 0.6323\n",
            "Epoch 22/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 23.7221 - accuracy: 0.9968 - val_loss: 24.6051 - val_accuracy: 0.6387\n",
            "Epoch 23/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 22.7219 - accuracy: 1.0000 - val_loss: 23.2485 - val_accuracy: 0.6839\n",
            "Epoch 24/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 21.7731 - accuracy: 0.9984 - val_loss: 22.3877 - val_accuracy: 0.6710\n",
            "Epoch 25/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 20.8564 - accuracy: 0.9968 - val_loss: 21.4557 - val_accuracy: 0.6774\n",
            "Epoch 26/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 19.9921 - accuracy: 0.9935 - val_loss: 20.3353 - val_accuracy: 0.7226\n",
            "Epoch 27/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 19.1787 - accuracy: 0.9887 - val_loss: 20.0131 - val_accuracy: 0.6774\n",
            "Epoch 28/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 18.3821 - accuracy: 0.9871 - val_loss: 18.5932 - val_accuracy: 0.7548\n",
            "Epoch 29/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 17.6103 - accuracy: 0.9855 - val_loss: 18.0972 - val_accuracy: 0.7161\n",
            "Epoch 30/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 16.8834 - accuracy: 0.9838 - val_loss: 17.3071 - val_accuracy: 0.7548\n",
            "Epoch 31/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 16.1763 - accuracy: 0.9887 - val_loss: 16.6850 - val_accuracy: 0.7355\n",
            "Epoch 32/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 15.5445 - accuracy: 0.9774 - val_loss: 15.6294 - val_accuracy: 0.8323\n",
            "Epoch 33/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 14.8675 - accuracy: 0.9935 - val_loss: 15.1235 - val_accuracy: 0.8452\n",
            "Epoch 34/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 14.3140 - accuracy: 0.9903 - val_loss: 14.8146 - val_accuracy: 0.8000\n",
            "Epoch 35/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 13.7374 - accuracy: 0.9822 - val_loss: 14.1717 - val_accuracy: 0.8129\n",
            "Epoch 36/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 13.1784 - accuracy: 0.9887 - val_loss: 13.5886 - val_accuracy: 0.8194\n",
            "Epoch 37/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 12.6613 - accuracy: 0.9855 - val_loss: 13.0499 - val_accuracy: 0.8129\n",
            "Epoch 38/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 12.2629 - accuracy: 0.9677 - val_loss: 12.5230 - val_accuracy: 0.8129\n",
            "Epoch 39/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 11.6863 - accuracy: 0.9935 - val_loss: 12.0482 - val_accuracy: 0.8065\n",
            "Epoch 40/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 11.2414 - accuracy: 0.9968 - val_loss: 11.6054 - val_accuracy: 0.8258\n",
            "Epoch 41/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 10.8055 - accuracy: 0.9968 - val_loss: 11.1842 - val_accuracy: 0.8452\n",
            "Epoch 42/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 10.3862 - accuracy: 0.9968 - val_loss: 11.0628 - val_accuracy: 0.8194\n",
            "Epoch 43/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 9.9917 - accuracy: 0.9968 - val_loss: 10.7787 - val_accuracy: 0.8323\n",
            "Epoch 44/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.6116 - accuracy: 0.9968 - val_loss: 10.3322 - val_accuracy: 0.8323\n",
            "Epoch 45/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 9.2239 - accuracy: 0.9984 - val_loss: 10.0384 - val_accuracy: 0.8258\n",
            "Epoch 46/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 8.8703 - accuracy: 0.9984 - val_loss: 9.9360 - val_accuracy: 0.8323\n",
            "Epoch 47/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.5315 - accuracy: 0.9984 - val_loss: 9.3541 - val_accuracy: 0.8194\n",
            "Epoch 48/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 8.2214 - accuracy: 0.9935 - val_loss: 8.8285 - val_accuracy: 0.8387\n",
            "Epoch 49/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.9130 - accuracy: 0.9903 - val_loss: 8.8531 - val_accuracy: 0.8258\n",
            "Epoch 50/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.6401 - accuracy: 0.9871 - val_loss: 8.7455 - val_accuracy: 0.8065\n",
            "Epoch 51/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.3780 - accuracy: 0.9871 - val_loss: 8.1951 - val_accuracy: 0.8129\n",
            "Epoch 52/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.1894 - accuracy: 0.9758 - val_loss: 7.9885 - val_accuracy: 0.8258\n",
            "Epoch 53/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 7.0584 - accuracy: 0.9548 - val_loss: 8.1478 - val_accuracy: 0.7935\n",
            "Epoch 54/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.6361 - accuracy: 0.9887 - val_loss: 7.1803 - val_accuracy: 0.8387\n",
            "Epoch 55/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.4907 - accuracy: 0.9661 - val_loss: 7.0583 - val_accuracy: 0.8516\n",
            "Epoch 56/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 6.2167 - accuracy: 0.9838 - val_loss: 7.0494 - val_accuracy: 0.8387\n",
            "Epoch 57/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 6.0237 - accuracy: 0.9871 - val_loss: 6.7288 - val_accuracy: 0.8000\n",
            "Epoch 58/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.7689 - accuracy: 0.9935 - val_loss: 6.4626 - val_accuracy: 0.8387\n",
            "Epoch 59/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 5.5703 - accuracy: 0.9855 - val_loss: 6.2811 - val_accuracy: 0.8258\n",
            "Epoch 60/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.3762 - accuracy: 0.9887 - val_loss: 5.9291 - val_accuracy: 0.8258\n",
            "Epoch 61/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.1656 - accuracy: 0.9952 - val_loss: 5.7416 - val_accuracy: 0.8323\n",
            "Epoch 62/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.0119 - accuracy: 0.9935 - val_loss: 5.5799 - val_accuracy: 0.8387\n",
            "Epoch 63/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.8090 - accuracy: 0.9952 - val_loss: 5.3416 - val_accuracy: 0.8000\n",
            "Epoch 64/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.6413 - accuracy: 0.9984 - val_loss: 5.1382 - val_accuracy: 0.8516\n",
            "Epoch 65/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.4795 - accuracy: 0.9984 - val_loss: 4.9340 - val_accuracy: 0.8903\n",
            "Epoch 66/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.3169 - accuracy: 0.9984 - val_loss: 4.8196 - val_accuracy: 0.8903\n",
            "Epoch 67/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.1601 - accuracy: 0.9984 - val_loss: 4.7702 - val_accuracy: 0.8516\n",
            "Epoch 68/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 4.0105 - accuracy: 0.9984 - val_loss: 4.6663 - val_accuracy: 0.8452\n",
            "Epoch 69/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.8633 - accuracy: 1.0000 - val_loss: 4.5829 - val_accuracy: 0.8258\n",
            "Epoch 70/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 3.7335 - accuracy: 0.9935 - val_loss: 4.6164 - val_accuracy: 0.8387\n",
            "Epoch 71/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.6071 - accuracy: 0.9968 - val_loss: 4.3947 - val_accuracy: 0.8323\n",
            "Epoch 72/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.4652 - accuracy: 1.0000 - val_loss: 4.2977 - val_accuracy: 0.8581\n",
            "Epoch 73/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.3566 - accuracy: 0.9968 - val_loss: 3.9480 - val_accuracy: 0.8710\n",
            "Epoch 74/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.2240 - accuracy: 1.0000 - val_loss: 3.8083 - val_accuracy: 0.8774\n",
            "Epoch 75/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.1091 - accuracy: 1.0000 - val_loss: 3.7073 - val_accuracy: 0.8645\n",
            "Epoch 76/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.9975 - accuracy: 1.0000 - val_loss: 3.5903 - val_accuracy: 0.8645\n",
            "Epoch 77/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.8907 - accuracy: 1.0000 - val_loss: 3.4588 - val_accuracy: 0.8581\n",
            "Epoch 78/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.7864 - accuracy: 1.0000 - val_loss: 3.2997 - val_accuracy: 0.8774\n",
            "Epoch 79/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.6862 - accuracy: 1.0000 - val_loss: 3.1892 - val_accuracy: 0.8774\n",
            "Epoch 80/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.5902 - accuracy: 1.0000 - val_loss: 3.1174 - val_accuracy: 0.8645\n",
            "Epoch 81/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.4965 - accuracy: 1.0000 - val_loss: 3.0330 - val_accuracy: 0.8645\n",
            "Epoch 82/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.4067 - accuracy: 1.0000 - val_loss: 2.9349 - val_accuracy: 0.8645\n",
            "Epoch 83/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.3196 - accuracy: 1.0000 - val_loss: 2.8410 - val_accuracy: 0.8710\n",
            "Epoch 84/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.2424 - accuracy: 0.9984 - val_loss: 2.8066 - val_accuracy: 0.8452\n",
            "Epoch 85/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.1566 - accuracy: 1.0000 - val_loss: 2.9129 - val_accuracy: 0.8323\n",
            "Epoch 86/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.0837 - accuracy: 0.9984 - val_loss: 2.9009 - val_accuracy: 0.8323\n",
            "Epoch 87/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.0170 - accuracy: 0.9984 - val_loss: 2.6981 - val_accuracy: 0.8774\n",
            "Epoch 88/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.9634 - accuracy: 0.9968 - val_loss: 2.6144 - val_accuracy: 0.8645\n",
            "Epoch 89/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.8786 - accuracy: 1.0000 - val_loss: 2.5982 - val_accuracy: 0.8645\n",
            "Epoch 90/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.8182 - accuracy: 1.0000 - val_loss: 2.5473 - val_accuracy: 0.8645\n",
            "Epoch 91/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.7561 - accuracy: 1.0000 - val_loss: 2.4238 - val_accuracy: 0.8839\n",
            "Epoch 92/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.6961 - accuracy: 1.0000 - val_loss: 2.4965 - val_accuracy: 0.8710\n",
            "Epoch 93/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.6591 - accuracy: 0.9968 - val_loss: 2.5186 - val_accuracy: 0.8645\n",
            "Epoch 94/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.5981 - accuracy: 0.9968 - val_loss: 2.4952 - val_accuracy: 0.8645\n",
            "Epoch 95/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.5461 - accuracy: 0.9968 - val_loss: 2.5766 - val_accuracy: 0.8387\n",
            "Epoch 96/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.4895 - accuracy: 0.9984 - val_loss: 2.4934 - val_accuracy: 0.8323\n",
            "Epoch 97/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.4372 - accuracy: 1.0000 - val_loss: 2.5389 - val_accuracy: 0.8452\n",
            "Epoch 98/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.4040 - accuracy: 0.9968 - val_loss: 2.8577 - val_accuracy: 0.8258\n",
            "Epoch 99/150\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.3754 - accuracy: 0.9968 - val_loss: 3.3388 - val_accuracy: 0.8258\n",
            "Epoch 100/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.3430 - accuracy: 0.9968 - val_loss: 3.1954 - val_accuracy: 0.8516\n",
            "Epoch 101/150\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 1.3467 - accuracy: 0.9838 - val_loss: 2.9767 - val_accuracy: 0.8516\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.4237 - accuracy: 0.8839\n",
            "Test Loss: 2.423677682876587, Test Accuracy: 0.8838709592819214\n",
            "Epoch 1/150\n",
            "10/10 [==============================] - 9s 89ms/step - loss: 50.5421 - accuracy: 0.5202 - val_loss: 49.5146 - val_accuracy: 0.7161\n",
            "Epoch 2/150\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 49.1695 - accuracy: 0.6414 - val_loss: 48.2858 - val_accuracy: 0.7161\n",
            "Epoch 3/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 47.8300 - accuracy: 0.7399 - val_loss: 47.0904 - val_accuracy: 0.7161\n",
            "Epoch 4/150\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 46.4573 - accuracy: 0.8514 - val_loss: 45.8771 - val_accuracy: 0.7161\n",
            "Epoch 5/150\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 45.0595 - accuracy: 0.8966 - val_loss: 44.6593 - val_accuracy: 0.7161\n",
            "Epoch 6/150\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 43.6480 - accuracy: 0.9612 - val_loss: 43.4799 - val_accuracy: 0.7161\n",
            "Epoch 7/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 42.3329 - accuracy: 0.9774 - val_loss: 42.2756 - val_accuracy: 0.7161\n",
            "Epoch 8/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 41.0196 - accuracy: 0.9855 - val_loss: 41.1041 - val_accuracy: 0.7161\n",
            "Epoch 9/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 39.7075 - accuracy: 0.9855 - val_loss: 39.8549 - val_accuracy: 0.7161\n",
            "Epoch 10/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 38.3913 - accuracy: 0.9919 - val_loss: 38.6473 - val_accuracy: 0.7161\n",
            "Epoch 11/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 37.0959 - accuracy: 0.9935 - val_loss: 37.4318 - val_accuracy: 0.7161\n",
            "Epoch 12/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 35.8115 - accuracy: 0.9984 - val_loss: 36.1426 - val_accuracy: 0.7161\n",
            "Epoch 13/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 34.5512 - accuracy: 0.9871 - val_loss: 35.0273 - val_accuracy: 0.7161\n",
            "Epoch 14/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 33.2782 - accuracy: 0.9968 - val_loss: 33.9075 - val_accuracy: 0.7161\n",
            "Epoch 15/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 32.0520 - accuracy: 0.9984 - val_loss: 32.6546 - val_accuracy: 0.7161\n",
            "Epoch 16/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 30.8479 - accuracy: 0.9984 - val_loss: 31.5795 - val_accuracy: 0.7161\n",
            "Epoch 17/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 29.6804 - accuracy: 0.9984 - val_loss: 30.3023 - val_accuracy: 0.7161\n",
            "Epoch 18/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 28.5205 - accuracy: 0.9984 - val_loss: 28.9533 - val_accuracy: 0.7161\n",
            "Epoch 19/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 27.4095 - accuracy: 0.9968 - val_loss: 28.0206 - val_accuracy: 0.7161\n",
            "Epoch 20/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 26.3149 - accuracy: 0.9984 - val_loss: 26.8902 - val_accuracy: 0.7161\n",
            "Epoch 21/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 25.2602 - accuracy: 1.0000 - val_loss: 25.8720 - val_accuracy: 0.7161\n",
            "Epoch 22/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 24.2374 - accuracy: 1.0000 - val_loss: 24.7839 - val_accuracy: 0.7161\n",
            "Epoch 23/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 23.2502 - accuracy: 0.9968 - val_loss: 23.7202 - val_accuracy: 0.7226\n",
            "Epoch 24/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 22.2886 - accuracy: 1.0000 - val_loss: 22.9162 - val_accuracy: 0.7161\n",
            "Epoch 25/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 21.3641 - accuracy: 1.0000 - val_loss: 21.9299 - val_accuracy: 0.7161\n",
            "Epoch 26/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 20.4671 - accuracy: 1.0000 - val_loss: 20.9204 - val_accuracy: 0.7226\n",
            "Epoch 27/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 19.6071 - accuracy: 0.9984 - val_loss: 19.9430 - val_accuracy: 0.7613\n",
            "Epoch 28/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 18.7741 - accuracy: 1.0000 - val_loss: 19.0541 - val_accuracy: 0.7742\n",
            "Epoch 29/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 17.9760 - accuracy: 0.9984 - val_loss: 18.3376 - val_accuracy: 0.7871\n",
            "Epoch 30/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 17.2097 - accuracy: 1.0000 - val_loss: 17.4667 - val_accuracy: 0.7871\n",
            "Epoch 31/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 16.4791 - accuracy: 0.9968 - val_loss: 16.7468 - val_accuracy: 0.8000\n",
            "Epoch 32/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 15.8340 - accuracy: 0.9887 - val_loss: 16.1785 - val_accuracy: 0.7548\n",
            "Epoch 33/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 15.2059 - accuracy: 0.9806 - val_loss: 15.4670 - val_accuracy: 0.7871\n",
            "Epoch 34/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 14.6284 - accuracy: 0.9580 - val_loss: 14.6696 - val_accuracy: 0.8258\n",
            "Epoch 35/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 14.0314 - accuracy: 0.9645 - val_loss: 13.9970 - val_accuracy: 0.8452\n",
            "Epoch 36/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.4786 - accuracy: 0.9855 - val_loss: 13.6638 - val_accuracy: 0.8452\n",
            "Epoch 37/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 12.9739 - accuracy: 0.9822 - val_loss: 13.1772 - val_accuracy: 0.8387\n",
            "Epoch 38/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 12.4724 - accuracy: 0.9871 - val_loss: 12.6638 - val_accuracy: 0.8774\n",
            "Epoch 39/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 12.0287 - accuracy: 0.9871 - val_loss: 12.2464 - val_accuracy: 0.8645\n",
            "Epoch 40/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 11.5666 - accuracy: 0.9838 - val_loss: 11.7860 - val_accuracy: 0.8581\n",
            "Epoch 41/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 11.1499 - accuracy: 0.9871 - val_loss: 11.4260 - val_accuracy: 0.8774\n",
            "Epoch 42/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.7494 - accuracy: 0.9855 - val_loss: 11.0503 - val_accuracy: 0.8387\n",
            "Epoch 43/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.3744 - accuracy: 0.9806 - val_loss: 10.8161 - val_accuracy: 0.8194\n",
            "Epoch 44/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.9712 - accuracy: 0.9838 - val_loss: 10.2420 - val_accuracy: 0.8839\n",
            "Epoch 45/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 9.6433 - accuracy: 0.9855 - val_loss: 9.8121 - val_accuracy: 0.8839\n",
            "Epoch 46/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 9.3125 - accuracy: 0.9790 - val_loss: 9.5161 - val_accuracy: 0.8645\n",
            "Epoch 47/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 9.0809 - accuracy: 0.9677 - val_loss: 9.2565 - val_accuracy: 0.8774\n",
            "Epoch 48/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 8.6592 - accuracy: 0.9903 - val_loss: 9.4037 - val_accuracy: 0.8581\n",
            "Epoch 49/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.4340 - accuracy: 0.9742 - val_loss: 8.6320 - val_accuracy: 0.8968\n",
            "Epoch 50/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.0752 - accuracy: 0.9935 - val_loss: 8.6647 - val_accuracy: 0.8710\n",
            "Epoch 51/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.8157 - accuracy: 0.9919 - val_loss: 8.0658 - val_accuracy: 0.9161\n",
            "Epoch 52/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.6222 - accuracy: 0.9903 - val_loss: 7.7303 - val_accuracy: 0.9161\n",
            "Epoch 53/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.2931 - accuracy: 0.9935 - val_loss: 7.9069 - val_accuracy: 0.8452\n",
            "Epoch 54/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 7.0515 - accuracy: 0.9887 - val_loss: 7.5751 - val_accuracy: 0.8903\n",
            "Epoch 55/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.8127 - accuracy: 0.9919 - val_loss: 7.2634 - val_accuracy: 0.8968\n",
            "Epoch 56/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.5821 - accuracy: 0.9952 - val_loss: 6.8426 - val_accuracy: 0.9097\n",
            "Epoch 57/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.3532 - accuracy: 0.9952 - val_loss: 6.5498 - val_accuracy: 0.9032\n",
            "Epoch 58/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 6.1295 - accuracy: 0.9984 - val_loss: 6.5949 - val_accuracy: 0.8903\n",
            "Epoch 59/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.9374 - accuracy: 0.9935 - val_loss: 6.1639 - val_accuracy: 0.9161\n",
            "Epoch 60/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.7674 - accuracy: 0.9855 - val_loss: 6.0659 - val_accuracy: 0.9032\n",
            "Epoch 61/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.5398 - accuracy: 0.9919 - val_loss: 5.9727 - val_accuracy: 0.8774\n",
            "Epoch 62/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.3578 - accuracy: 0.9919 - val_loss: 5.5938 - val_accuracy: 0.8968\n",
            "Epoch 63/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 5.1510 - accuracy: 1.0000 - val_loss: 5.5897 - val_accuracy: 0.8774\n",
            "Epoch 64/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.9873 - accuracy: 0.9984 - val_loss: 5.4490 - val_accuracy: 0.8774\n",
            "Epoch 65/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 4.8074 - accuracy: 1.0000 - val_loss: 5.2477 - val_accuracy: 0.8839\n",
            "Epoch 66/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 4.6440 - accuracy: 0.9984 - val_loss: 4.9789 - val_accuracy: 0.9032\n",
            "Epoch 67/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 4.4907 - accuracy: 0.9984 - val_loss: 4.6611 - val_accuracy: 0.9226\n",
            "Epoch 68/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 4.3510 - accuracy: 0.9968 - val_loss: 4.6365 - val_accuracy: 0.9097\n",
            "Epoch 69/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.2033 - accuracy: 0.9935 - val_loss: 4.6711 - val_accuracy: 0.9032\n",
            "Epoch 70/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.0676 - accuracy: 0.9935 - val_loss: 4.5314 - val_accuracy: 0.8968\n",
            "Epoch 71/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.9314 - accuracy: 0.9952 - val_loss: 4.4647 - val_accuracy: 0.9032\n",
            "Epoch 72/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.7851 - accuracy: 1.0000 - val_loss: 4.2927 - val_accuracy: 0.8968\n",
            "Epoch 73/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.6737 - accuracy: 0.9952 - val_loss: 4.2318 - val_accuracy: 0.9032\n",
            "Epoch 74/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.5641 - accuracy: 0.9903 - val_loss: 3.9865 - val_accuracy: 0.9097\n",
            "Epoch 75/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.4574 - accuracy: 0.9935 - val_loss: 3.8962 - val_accuracy: 0.8968\n",
            "Epoch 76/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.3492 - accuracy: 0.9919 - val_loss: 3.9373 - val_accuracy: 0.8903\n",
            "Epoch 77/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.2197 - accuracy: 0.9968 - val_loss: 3.6839 - val_accuracy: 0.8774\n",
            "Epoch 78/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.1061 - accuracy: 0.9952 - val_loss: 3.5478 - val_accuracy: 0.8774\n",
            "Epoch 79/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.9975 - accuracy: 0.9984 - val_loss: 3.4428 - val_accuracy: 0.9032\n",
            "Epoch 80/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.8973 - accuracy: 1.0000 - val_loss: 3.3542 - val_accuracy: 0.9097\n",
            "Epoch 81/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.8019 - accuracy: 1.0000 - val_loss: 3.2618 - val_accuracy: 0.9032\n",
            "Epoch 82/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 2.7553 - accuracy: 0.9871 - val_loss: 3.1545 - val_accuracy: 0.8968\n",
            "Epoch 83/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.6452 - accuracy: 0.9887 - val_loss: 3.4071 - val_accuracy: 0.8516\n",
            "Epoch 84/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.5506 - accuracy: 0.9952 - val_loss: 3.1749 - val_accuracy: 0.8903\n",
            "Epoch 85/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.5405 - accuracy: 0.9855 - val_loss: 3.2140 - val_accuracy: 0.8516\n",
            "Epoch 86/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 2.4335 - accuracy: 0.9855 - val_loss: 3.0007 - val_accuracy: 0.8839\n",
            "Epoch 87/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.3173 - accuracy: 0.9952 - val_loss: 2.8226 - val_accuracy: 0.8968\n",
            "Epoch 88/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.2852 - accuracy: 0.9887 - val_loss: 3.0200 - val_accuracy: 0.8839\n",
            "Epoch 89/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.1957 - accuracy: 0.9903 - val_loss: 2.9068 - val_accuracy: 0.8839\n",
            "Epoch 90/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.1101 - accuracy: 0.9968 - val_loss: 2.6948 - val_accuracy: 0.8903\n",
            "Epoch 91/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.0409 - accuracy: 0.9984 - val_loss: 2.5425 - val_accuracy: 0.8968\n",
            "Epoch 92/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.9758 - accuracy: 0.9984 - val_loss: 2.4505 - val_accuracy: 0.8968\n",
            "Epoch 93/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.9051 - accuracy: 1.0000 - val_loss: 2.3611 - val_accuracy: 0.8903\n",
            "Epoch 94/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.8414 - accuracy: 1.0000 - val_loss: 2.2760 - val_accuracy: 0.8968\n",
            "Epoch 95/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.7784 - accuracy: 1.0000 - val_loss: 2.2456 - val_accuracy: 0.8968\n",
            "Epoch 96/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.7162 - accuracy: 1.0000 - val_loss: 2.1559 - val_accuracy: 0.8968\n",
            "Epoch 97/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.6618 - accuracy: 0.9984 - val_loss: 2.1469 - val_accuracy: 0.9032\n",
            "Epoch 98/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.6017 - accuracy: 1.0000 - val_loss: 2.1621 - val_accuracy: 0.8903\n",
            "Epoch 99/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.5541 - accuracy: 0.9984 - val_loss: 2.0804 - val_accuracy: 0.9032\n",
            "Epoch 100/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.5096 - accuracy: 0.9968 - val_loss: 1.8740 - val_accuracy: 0.9032\n",
            "Epoch 101/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.4458 - accuracy: 1.0000 - val_loss: 1.8514 - val_accuracy: 0.9032\n",
            "Epoch 102/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.3989 - accuracy: 1.0000 - val_loss: 1.8363 - val_accuracy: 0.8839\n",
            "Epoch 103/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.3522 - accuracy: 1.0000 - val_loss: 1.7944 - val_accuracy: 0.8839\n",
            "Epoch 104/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.3057 - accuracy: 1.0000 - val_loss: 1.7532 - val_accuracy: 0.8839\n",
            "Epoch 105/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.2609 - accuracy: 1.0000 - val_loss: 1.7036 - val_accuracy: 0.8774\n",
            "Epoch 106/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 1.2174 - accuracy: 1.0000 - val_loss: 1.6852 - val_accuracy: 0.8774\n",
            "Epoch 107/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.1750 - accuracy: 1.0000 - val_loss: 1.6521 - val_accuracy: 0.8839\n",
            "Epoch 108/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.1344 - accuracy: 1.0000 - val_loss: 1.6141 - val_accuracy: 0.8839\n",
            "Epoch 109/150\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.0997 - accuracy: 0.9984 - val_loss: 1.5577 - val_accuracy: 0.8968\n",
            "Epoch 110/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0677 - accuracy: 0.9984 - val_loss: 1.5629 - val_accuracy: 0.9032\n",
            "Epoch 111/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0264 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.8968\n",
            "Epoch 112/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0085 - accuracy: 0.9984 - val_loss: 1.6407 - val_accuracy: 0.8774\n",
            "Epoch 113/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.9637 - accuracy: 1.0000 - val_loss: 1.5079 - val_accuracy: 0.8839\n",
            "Epoch 114/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.9312 - accuracy: 1.0000 - val_loss: 1.4658 - val_accuracy: 0.8968\n",
            "Epoch 115/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.8989 - accuracy: 1.0000 - val_loss: 1.4444 - val_accuracy: 0.9032\n",
            "Epoch 116/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.8678 - accuracy: 1.0000 - val_loss: 1.4124 - val_accuracy: 0.9032\n",
            "Epoch 117/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.8467 - accuracy: 0.9984 - val_loss: 1.4381 - val_accuracy: 0.8968\n",
            "Epoch 118/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8375 - accuracy: 0.9952 - val_loss: 1.5164 - val_accuracy: 0.8839\n",
            "Epoch 119/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.8057 - accuracy: 1.0000 - val_loss: 1.5809 - val_accuracy: 0.8903\n",
            "Epoch 120/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.8533 - accuracy: 0.9919 - val_loss: 1.7867 - val_accuracy: 0.8516\n",
            "Epoch 121/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.7751 - accuracy: 1.0000 - val_loss: 2.0746 - val_accuracy: 0.8516\n",
            "Epoch 122/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7778 - accuracy: 0.9952 - val_loss: 1.9136 - val_accuracy: 0.8516\n",
            "Epoch 123/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.8118 - accuracy: 0.9790 - val_loss: 1.5761 - val_accuracy: 0.8903\n",
            "Epoch 124/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.9304 - accuracy: 0.9693 - val_loss: 2.3277 - val_accuracy: 0.8710\n",
            "Epoch 125/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.8736 - accuracy: 0.9758 - val_loss: 1.7964 - val_accuracy: 0.8968\n",
            "Epoch 126/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.8398 - accuracy: 0.9774 - val_loss: 2.2806 - val_accuracy: 0.8387\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4125 - accuracy: 0.9032\n",
            "Test Loss: 1.4124844074249268, Test Accuracy: 0.9032257795333862\n",
            "Epoch 1/150\n",
            "10/10 [==============================] - 11s 92ms/step - loss: 50.5518 - accuracy: 0.5363 - val_loss: 49.5182 - val_accuracy: 0.6516\n",
            "Epoch 2/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 49.1352 - accuracy: 0.6397 - val_loss: 48.3034 - val_accuracy: 0.6516\n",
            "Epoch 3/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 47.8445 - accuracy: 0.7092 - val_loss: 47.0956 - val_accuracy: 0.6516\n",
            "Epoch 4/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 46.4815 - accuracy: 0.8013 - val_loss: 45.8904 - val_accuracy: 0.6516\n",
            "Epoch 5/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 45.1248 - accuracy: 0.8595 - val_loss: 44.7135 - val_accuracy: 0.6516\n",
            "Epoch 6/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 43.7448 - accuracy: 0.9338 - val_loss: 43.5908 - val_accuracy: 0.6516\n",
            "Epoch 7/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 42.3918 - accuracy: 0.9725 - val_loss: 42.4748 - val_accuracy: 0.6516\n",
            "Epoch 8/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 41.1614 - accuracy: 0.9628 - val_loss: 41.2838 - val_accuracy: 0.6516\n",
            "Epoch 9/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 39.8471 - accuracy: 0.9806 - val_loss: 40.1767 - val_accuracy: 0.6516\n",
            "Epoch 10/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 38.5550 - accuracy: 0.9919 - val_loss: 39.0601 - val_accuracy: 0.6516\n",
            "Epoch 11/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 37.3048 - accuracy: 0.9952 - val_loss: 37.8581 - val_accuracy: 0.6516\n",
            "Epoch 12/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 36.0459 - accuracy: 0.9952 - val_loss: 36.6793 - val_accuracy: 0.6516\n",
            "Epoch 13/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 34.7941 - accuracy: 0.9984 - val_loss: 35.4934 - val_accuracy: 0.6516\n",
            "Epoch 14/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 33.6098 - accuracy: 0.9919 - val_loss: 34.1720 - val_accuracy: 0.6516\n",
            "Epoch 15/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 32.3881 - accuracy: 0.9952 - val_loss: 33.1380 - val_accuracy: 0.6516\n",
            "Epoch 16/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 31.2242 - accuracy: 0.9871 - val_loss: 32.0068 - val_accuracy: 0.6516\n",
            "Epoch 17/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 30.0696 - accuracy: 0.9919 - val_loss: 30.8678 - val_accuracy: 0.6516\n",
            "Epoch 18/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 28.9469 - accuracy: 0.9984 - val_loss: 29.7757 - val_accuracy: 0.6516\n",
            "Epoch 19/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 27.8490 - accuracy: 0.9984 - val_loss: 28.6265 - val_accuracy: 0.6516\n",
            "Epoch 20/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 26.7877 - accuracy: 0.9984 - val_loss: 27.4725 - val_accuracy: 0.6516\n",
            "Epoch 21/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 25.7467 - accuracy: 1.0000 - val_loss: 26.2823 - val_accuracy: 0.6516\n",
            "Epoch 22/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 24.7483 - accuracy: 0.9935 - val_loss: 25.2998 - val_accuracy: 0.6516\n",
            "Epoch 23/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 23.7698 - accuracy: 0.9968 - val_loss: 24.2379 - val_accuracy: 0.6516\n",
            "Epoch 24/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 22.8337 - accuracy: 0.9952 - val_loss: 23.0833 - val_accuracy: 0.6710\n",
            "Epoch 25/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 21.9279 - accuracy: 0.9952 - val_loss: 22.3153 - val_accuracy: 0.6968\n",
            "Epoch 26/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 21.0446 - accuracy: 0.9968 - val_loss: 21.9008 - val_accuracy: 0.6774\n",
            "Epoch 27/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 20.2146 - accuracy: 0.9919 - val_loss: 20.6628 - val_accuracy: 0.7097\n",
            "Epoch 28/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 19.3963 - accuracy: 0.9968 - val_loss: 19.8311 - val_accuracy: 0.7097\n",
            "Epoch 29/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 18.6063 - accuracy: 0.9952 - val_loss: 18.9466 - val_accuracy: 0.7419\n",
            "Epoch 30/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 17.8488 - accuracy: 0.9968 - val_loss: 17.9792 - val_accuracy: 0.7935\n",
            "Epoch 31/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 17.1245 - accuracy: 0.9984 - val_loss: 17.3733 - val_accuracy: 0.7806\n",
            "Epoch 32/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 16.4344 - accuracy: 0.9935 - val_loss: 16.8475 - val_accuracy: 0.7290\n",
            "Epoch 33/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 15.7747 - accuracy: 0.9903 - val_loss: 15.9671 - val_accuracy: 0.8129\n",
            "Epoch 34/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 15.1631 - accuracy: 0.9903 - val_loss: 15.3381 - val_accuracy: 0.8194\n",
            "Epoch 35/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 14.5357 - accuracy: 0.9887 - val_loss: 14.6767 - val_accuracy: 0.8258\n",
            "Epoch 36/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 13.9488 - accuracy: 0.9903 - val_loss: 14.0408 - val_accuracy: 0.8452\n",
            "Epoch 37/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 13.4074 - accuracy: 0.9887 - val_loss: 13.5746 - val_accuracy: 0.8774\n",
            "Epoch 38/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 12.8623 - accuracy: 0.9855 - val_loss: 12.9976 - val_accuracy: 0.8258\n",
            "Epoch 39/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 12.3682 - accuracy: 0.9887 - val_loss: 12.4703 - val_accuracy: 0.8774\n",
            "Epoch 40/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 11.8878 - accuracy: 0.9919 - val_loss: 12.1300 - val_accuracy: 0.8581\n",
            "Epoch 41/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 11.4179 - accuracy: 0.9919 - val_loss: 11.5869 - val_accuracy: 0.9097\n",
            "Epoch 42/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10.9842 - accuracy: 0.9806 - val_loss: 11.8396 - val_accuracy: 0.7355\n",
            "Epoch 43/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.7150 - accuracy: 0.9758 - val_loss: 10.7513 - val_accuracy: 0.8452\n",
            "Epoch 44/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 10.2461 - accuracy: 0.9774 - val_loss: 10.5540 - val_accuracy: 0.8839\n",
            "Epoch 45/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 9.8614 - accuracy: 0.9838 - val_loss: 10.0413 - val_accuracy: 0.8903\n",
            "Epoch 46/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.4900 - accuracy: 0.9968 - val_loss: 10.2322 - val_accuracy: 0.8581\n",
            "Epoch 47/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.1597 - accuracy: 0.9919 - val_loss: 9.5367 - val_accuracy: 0.8839\n",
            "Epoch 48/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 8.8292 - accuracy: 0.9903 - val_loss: 9.0976 - val_accuracy: 0.8968\n",
            "Epoch 49/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.5142 - accuracy: 0.9919 - val_loss: 8.8182 - val_accuracy: 0.8581\n",
            "Epoch 50/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 8.2650 - accuracy: 0.9838 - val_loss: 9.0654 - val_accuracy: 0.8387\n",
            "Epoch 51/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.0302 - accuracy: 0.9742 - val_loss: 8.7358 - val_accuracy: 0.8387\n",
            "Epoch 52/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.7180 - accuracy: 0.9838 - val_loss: 7.7221 - val_accuracy: 0.8903\n",
            "Epoch 53/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 7.4897 - accuracy: 0.9790 - val_loss: 7.7876 - val_accuracy: 0.8387\n",
            "Epoch 54/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 7.1631 - accuracy: 0.9887 - val_loss: 7.3865 - val_accuracy: 0.8968\n",
            "Epoch 55/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.8982 - accuracy: 0.9952 - val_loss: 7.0924 - val_accuracy: 0.9032\n",
            "Epoch 56/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 6.6550 - accuracy: 0.9935 - val_loss: 7.1902 - val_accuracy: 0.8452\n",
            "Epoch 57/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.4401 - accuracy: 0.9919 - val_loss: 6.8219 - val_accuracy: 0.8839\n",
            "Epoch 58/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.2119 - accuracy: 0.9952 - val_loss: 6.6040 - val_accuracy: 0.8710\n",
            "Epoch 59/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.9895 - accuracy: 0.9919 - val_loss: 6.4087 - val_accuracy: 0.8645\n",
            "Epoch 60/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.7694 - accuracy: 0.9984 - val_loss: 6.0466 - val_accuracy: 0.9032\n",
            "Epoch 61/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 5.5740 - accuracy: 0.9952 - val_loss: 5.8578 - val_accuracy: 0.8968\n",
            "Epoch 62/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.3683 - accuracy: 1.0000 - val_loss: 5.7364 - val_accuracy: 0.8710\n",
            "Epoch 63/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.1768 - accuracy: 0.9984 - val_loss: 5.4650 - val_accuracy: 0.9032\n",
            "Epoch 64/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 4.9919 - accuracy: 1.0000 - val_loss: 5.3012 - val_accuracy: 0.9032\n",
            "Epoch 65/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 4.8116 - accuracy: 1.0000 - val_loss: 5.1289 - val_accuracy: 0.9161\n",
            "Epoch 66/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.6504 - accuracy: 0.9968 - val_loss: 4.8433 - val_accuracy: 0.9097\n",
            "Epoch 67/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 4.4736 - accuracy: 1.0000 - val_loss: 4.7692 - val_accuracy: 0.9161\n",
            "Epoch 68/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.3254 - accuracy: 0.9968 - val_loss: 4.4990 - val_accuracy: 0.9097\n",
            "Epoch 69/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 4.1610 - accuracy: 1.0000 - val_loss: 4.7494 - val_accuracy: 0.8452\n",
            "Epoch 70/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.0309 - accuracy: 0.9968 - val_loss: 4.2489 - val_accuracy: 0.9226\n",
            "Epoch 71/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.8721 - accuracy: 1.0000 - val_loss: 4.0823 - val_accuracy: 0.9161\n",
            "Epoch 72/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.7359 - accuracy: 0.9984 - val_loss: 3.9306 - val_accuracy: 0.9097\n",
            "Epoch 73/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.6017 - accuracy: 1.0000 - val_loss: 3.8089 - val_accuracy: 0.9419\n",
            "Epoch 74/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.4765 - accuracy: 0.9984 - val_loss: 3.8692 - val_accuracy: 0.8774\n",
            "Epoch 75/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.3588 - accuracy: 0.9984 - val_loss: 3.7698 - val_accuracy: 0.8903\n",
            "Epoch 76/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.2383 - accuracy: 1.0000 - val_loss: 3.5933 - val_accuracy: 0.9161\n",
            "Epoch 77/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.1274 - accuracy: 1.0000 - val_loss: 3.4936 - val_accuracy: 0.9097\n",
            "Epoch 78/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.0231 - accuracy: 0.9984 - val_loss: 3.3006 - val_accuracy: 0.9032\n",
            "Epoch 79/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.9142 - accuracy: 0.9984 - val_loss: 3.2334 - val_accuracy: 0.9161\n",
            "Epoch 80/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.8212 - accuracy: 0.9968 - val_loss: 3.1353 - val_accuracy: 0.8903\n",
            "Epoch 81/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.7395 - accuracy: 1.0000 - val_loss: 2.9692 - val_accuracy: 0.9161\n",
            "Epoch 82/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.6660 - accuracy: 0.9935 - val_loss: 3.1633 - val_accuracy: 0.8839\n",
            "Epoch 83/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.5949 - accuracy: 0.9919 - val_loss: 2.9590 - val_accuracy: 0.9032\n",
            "Epoch 84/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.5124 - accuracy: 0.9952 - val_loss: 3.7336 - val_accuracy: 0.9032\n",
            "Epoch 85/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.4205 - accuracy: 0.9968 - val_loss: 3.0068 - val_accuracy: 0.8968\n",
            "Epoch 86/150\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 2.4008 - accuracy: 0.9855 - val_loss: 2.9312 - val_accuracy: 0.8839\n",
            "Epoch 87/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.2893 - accuracy: 0.9919 - val_loss: 2.9089 - val_accuracy: 0.8516\n",
            "Epoch 88/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.2144 - accuracy: 0.9952 - val_loss: 2.6031 - val_accuracy: 0.8968\n",
            "Epoch 89/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.1441 - accuracy: 0.9887 - val_loss: 2.6341 - val_accuracy: 0.8903\n",
            "Epoch 90/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.1060 - accuracy: 0.9822 - val_loss: 3.4636 - val_accuracy: 0.8129\n",
            "Epoch 91/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.0536 - accuracy: 0.9855 - val_loss: 2.4170 - val_accuracy: 0.9355\n",
            "Epoch 92/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.9383 - accuracy: 0.9968 - val_loss: 2.4776 - val_accuracy: 0.9290\n",
            "Epoch 93/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.8679 - accuracy: 0.9984 - val_loss: 2.4141 - val_accuracy: 0.8968\n",
            "Epoch 94/150\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.8213 - accuracy: 0.9952 - val_loss: 2.3230 - val_accuracy: 0.9032\n",
            "Epoch 95/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 1.7685 - accuracy: 0.9935 - val_loss: 2.2963 - val_accuracy: 0.9161\n",
            "Epoch 96/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 1.6856 - accuracy: 0.9984 - val_loss: 1.9640 - val_accuracy: 0.9484\n",
            "Epoch 97/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 1.6253 - accuracy: 1.0000 - val_loss: 1.9167 - val_accuracy: 0.9419\n",
            "Epoch 98/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.5713 - accuracy: 0.9984 - val_loss: 1.9157 - val_accuracy: 0.9226\n",
            "Epoch 99/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.5373 - accuracy: 0.9968 - val_loss: 1.8617 - val_accuracy: 0.9226\n",
            "Epoch 100/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.4679 - accuracy: 0.9984 - val_loss: 1.9455 - val_accuracy: 0.9032\n",
            "Epoch 101/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 1.4307 - accuracy: 0.9984 - val_loss: 1.8250 - val_accuracy: 0.9097\n",
            "Epoch 102/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.3822 - accuracy: 1.0000 - val_loss: 1.8303 - val_accuracy: 0.9032\n",
            "Epoch 103/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.3412 - accuracy: 0.9968 - val_loss: 1.7540 - val_accuracy: 0.9290\n",
            "Epoch 104/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.3038 - accuracy: 0.9968 - val_loss: 1.8305 - val_accuracy: 0.9097\n",
            "Epoch 105/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.2534 - accuracy: 0.9952 - val_loss: 1.7428 - val_accuracy: 0.9226\n",
            "Epoch 106/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.2157 - accuracy: 0.9968 - val_loss: 1.7991 - val_accuracy: 0.9161\n",
            "Epoch 107/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.1913 - accuracy: 0.9984 - val_loss: 1.8725 - val_accuracy: 0.8968\n",
            "Epoch 108/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.2014 - accuracy: 0.9871 - val_loss: 2.0095 - val_accuracy: 0.8903\n",
            "Epoch 109/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.1550 - accuracy: 0.9903 - val_loss: 2.0099 - val_accuracy: 0.8839\n",
            "Epoch 110/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.0968 - accuracy: 0.9919 - val_loss: 1.7399 - val_accuracy: 0.9226\n",
            "Epoch 111/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0566 - accuracy: 0.9935 - val_loss: 1.7602 - val_accuracy: 0.9097\n",
            "Epoch 112/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0034 - accuracy: 1.0000 - val_loss: 1.7426 - val_accuracy: 0.8903\n",
            "Epoch 113/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.9828 - accuracy: 0.9968 - val_loss: 1.6299 - val_accuracy: 0.9097\n",
            "Epoch 114/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.9412 - accuracy: 0.9984 - val_loss: 1.4628 - val_accuracy: 0.9032\n",
            "Epoch 115/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.9441 - accuracy: 0.9903 - val_loss: 1.4529 - val_accuracy: 0.8968\n",
            "Epoch 116/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.9052 - accuracy: 0.9952 - val_loss: 1.4823 - val_accuracy: 0.8774\n",
            "Epoch 117/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.8847 - accuracy: 0.9968 - val_loss: 1.4179 - val_accuracy: 0.8903\n",
            "Epoch 118/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.8307 - accuracy: 1.0000 - val_loss: 1.4211 - val_accuracy: 0.8839\n",
            "Epoch 119/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.8239 - accuracy: 0.9952 - val_loss: 1.3077 - val_accuracy: 0.8968\n",
            "Epoch 120/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.8061 - accuracy: 0.9968 - val_loss: 1.3062 - val_accuracy: 0.9032\n",
            "Epoch 121/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.8439 - accuracy: 0.9790 - val_loss: 1.2884 - val_accuracy: 0.8968\n",
            "Epoch 122/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.8018 - accuracy: 0.9855 - val_loss: 1.1290 - val_accuracy: 0.9097\n",
            "Epoch 123/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.7343 - accuracy: 0.9968 - val_loss: 1.2441 - val_accuracy: 0.9032\n",
            "Epoch 124/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.7179 - accuracy: 0.9984 - val_loss: 1.0783 - val_accuracy: 0.9290\n",
            "Epoch 125/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6804 - accuracy: 1.0000 - val_loss: 1.0419 - val_accuracy: 0.9355\n",
            "Epoch 126/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6558 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.9419\n",
            "Epoch 127/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6329 - accuracy: 0.9984 - val_loss: 0.9678 - val_accuracy: 0.9419\n",
            "Epoch 128/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6060 - accuracy: 1.0000 - val_loss: 1.0075 - val_accuracy: 0.9290\n",
            "Epoch 129/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5838 - accuracy: 1.0000 - val_loss: 0.9941 - val_accuracy: 0.9355\n",
            "Epoch 130/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5608 - accuracy: 1.0000 - val_loss: 1.1202 - val_accuracy: 0.8968\n",
            "Epoch 131/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5421 - accuracy: 0.9984 - val_loss: 0.8983 - val_accuracy: 0.9290\n",
            "Epoch 132/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5201 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.9419\n",
            "Epoch 133/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5137 - accuracy: 0.9952 - val_loss: 0.8201 - val_accuracy: 0.9355\n",
            "Epoch 134/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4831 - accuracy: 1.0000 - val_loss: 0.7579 - val_accuracy: 0.9290\n",
            "Epoch 135/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4659 - accuracy: 1.0000 - val_loss: 0.7293 - val_accuracy: 0.9290\n",
            "Epoch 136/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4489 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.9355\n",
            "Epoch 137/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4349 - accuracy: 0.9984 - val_loss: 0.6773 - val_accuracy: 0.9290\n",
            "Epoch 138/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4305 - accuracy: 0.9984 - val_loss: 0.7040 - val_accuracy: 0.9290\n",
            "Epoch 139/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4152 - accuracy: 0.9935 - val_loss: 0.6814 - val_accuracy: 0.9226\n",
            "Epoch 140/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3908 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.9097\n",
            "Epoch 141/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4110 - accuracy: 0.9903 - val_loss: 0.8168 - val_accuracy: 0.9097\n",
            "Epoch 142/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3764 - accuracy: 0.9968 - val_loss: 0.8630 - val_accuracy: 0.9097\n",
            "Epoch 143/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3722 - accuracy: 0.9952 - val_loss: 1.1050 - val_accuracy: 0.8774\n",
            "Epoch 144/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3598 - accuracy: 0.9984 - val_loss: 0.9196 - val_accuracy: 0.8968\n",
            "Epoch 145/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3497 - accuracy: 1.0000 - val_loss: 0.9130 - val_accuracy: 0.8968\n",
            "Epoch 146/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3376 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.9097\n",
            "Epoch 147/150\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.3241 - accuracy: 1.0000 - val_loss: 0.8947 - val_accuracy: 0.9097\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6774 - accuracy: 0.9290\n",
            "Test Loss: 0.6773502230644226, Test Accuracy: 0.9290322661399841\n",
            "Epoch 1/150\n",
            "10/10 [==============================] - 9s 86ms/step - loss: 50.5311 - accuracy: 0.5428 - val_loss: 49.4807 - val_accuracy: 0.6968\n",
            "Epoch 2/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 49.1181 - accuracy: 0.6737 - val_loss: 48.2423 - val_accuracy: 0.6968\n",
            "Epoch 3/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 47.6967 - accuracy: 0.7884 - val_loss: 47.0080 - val_accuracy: 0.6968\n",
            "Epoch 4/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 46.3123 - accuracy: 0.8546 - val_loss: 45.7809 - val_accuracy: 0.6968\n",
            "Epoch 5/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 44.8980 - accuracy: 0.8934 - val_loss: 44.5823 - val_accuracy: 0.6968\n",
            "Epoch 6/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 43.5249 - accuracy: 0.9499 - val_loss: 43.3910 - val_accuracy: 0.6968\n",
            "Epoch 7/150\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 42.1622 - accuracy: 0.9774 - val_loss: 42.2509 - val_accuracy: 0.6968\n",
            "Epoch 8/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 40.8461 - accuracy: 0.9758 - val_loss: 41.1105 - val_accuracy: 0.6968\n",
            "Epoch 9/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 39.5149 - accuracy: 0.9871 - val_loss: 39.8449 - val_accuracy: 0.6968\n",
            "Epoch 10/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 38.2152 - accuracy: 0.9838 - val_loss: 38.6988 - val_accuracy: 0.6968\n",
            "Epoch 11/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 36.8892 - accuracy: 0.9968 - val_loss: 37.4928 - val_accuracy: 0.6968\n",
            "Epoch 12/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 35.6141 - accuracy: 0.9887 - val_loss: 36.2524 - val_accuracy: 0.6968\n",
            "Epoch 13/150\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 34.3282 - accuracy: 0.9984 - val_loss: 35.1806 - val_accuracy: 0.6968\n",
            "Epoch 14/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 33.1053 - accuracy: 0.9903 - val_loss: 33.8139 - val_accuracy: 0.6968\n",
            "Epoch 15/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 31.8633 - accuracy: 0.9935 - val_loss: 32.6022 - val_accuracy: 0.6968\n",
            "Epoch 16/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 30.6571 - accuracy: 0.9968 - val_loss: 31.3874 - val_accuracy: 0.6968\n",
            "Epoch 17/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 29.5237 - accuracy: 0.9903 - val_loss: 30.3792 - val_accuracy: 0.6968\n",
            "Epoch 18/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 28.3710 - accuracy: 0.9919 - val_loss: 29.1672 - val_accuracy: 0.6968\n",
            "Epoch 19/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 27.2611 - accuracy: 0.9952 - val_loss: 28.0686 - val_accuracy: 0.6968\n",
            "Epoch 20/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 26.1901 - accuracy: 0.9984 - val_loss: 26.8926 - val_accuracy: 0.6968\n",
            "Epoch 21/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 25.1513 - accuracy: 0.9984 - val_loss: 25.6668 - val_accuracy: 0.6968\n",
            "Epoch 22/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 24.1426 - accuracy: 0.9984 - val_loss: 24.5505 - val_accuracy: 0.7032\n",
            "Epoch 23/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 23.1615 - accuracy: 0.9984 - val_loss: 23.4775 - val_accuracy: 0.7226\n",
            "Epoch 24/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 22.2137 - accuracy: 1.0000 - val_loss: 22.5738 - val_accuracy: 0.7226\n",
            "Epoch 25/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 21.3008 - accuracy: 0.9984 - val_loss: 21.6409 - val_accuracy: 0.7419\n",
            "Epoch 26/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 20.4148 - accuracy: 1.0000 - val_loss: 20.6785 - val_accuracy: 0.7806\n",
            "Epoch 27/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 19.5602 - accuracy: 1.0000 - val_loss: 19.7246 - val_accuracy: 0.8194\n",
            "Epoch 28/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 18.7831 - accuracy: 0.9952 - val_loss: 18.8000 - val_accuracy: 0.8258\n",
            "Epoch 29/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 17.9822 - accuracy: 0.9952 - val_loss: 18.0289 - val_accuracy: 0.8452\n",
            "Epoch 30/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 17.2311 - accuracy: 0.9935 - val_loss: 17.2284 - val_accuracy: 0.8516\n",
            "Epoch 31/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 16.5246 - accuracy: 0.9919 - val_loss: 16.5554 - val_accuracy: 0.8452\n",
            "Epoch 32/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 15.8609 - accuracy: 0.9871 - val_loss: 15.8637 - val_accuracy: 0.8710\n",
            "Epoch 33/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 15.2214 - accuracy: 0.9903 - val_loss: 15.2386 - val_accuracy: 0.8839\n",
            "Epoch 34/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 14.5751 - accuracy: 0.9935 - val_loss: 14.6367 - val_accuracy: 0.8903\n",
            "Epoch 35/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.9948 - accuracy: 0.9935 - val_loss: 14.2719 - val_accuracy: 0.8258\n",
            "Epoch 36/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.4594 - accuracy: 0.9871 - val_loss: 13.6837 - val_accuracy: 0.8774\n",
            "Epoch 37/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 12.9079 - accuracy: 0.9871 - val_loss: 13.0470 - val_accuracy: 0.8581\n",
            "Epoch 38/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 12.4190 - accuracy: 0.9790 - val_loss: 12.4507 - val_accuracy: 0.9097\n",
            "Epoch 39/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 11.9029 - accuracy: 0.9903 - val_loss: 12.0913 - val_accuracy: 0.8839\n",
            "Epoch 40/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 11.4237 - accuracy: 0.9952 - val_loss: 11.6059 - val_accuracy: 0.8839\n",
            "Epoch 41/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.9744 - accuracy: 0.9935 - val_loss: 11.3249 - val_accuracy: 0.8774\n",
            "Epoch 42/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 10.5529 - accuracy: 0.9919 - val_loss: 10.7517 - val_accuracy: 0.8774\n",
            "Epoch 43/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 10.1821 - accuracy: 0.9887 - val_loss: 10.3723 - val_accuracy: 0.8968\n",
            "Epoch 44/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.7912 - accuracy: 0.9790 - val_loss: 9.9491 - val_accuracy: 0.9161\n",
            "Epoch 45/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.3946 - accuracy: 0.9887 - val_loss: 9.8393 - val_accuracy: 0.8968\n",
            "Epoch 46/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.0677 - accuracy: 0.9855 - val_loss: 9.5809 - val_accuracy: 0.8903\n",
            "Epoch 47/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 8.7263 - accuracy: 0.9871 - val_loss: 9.0788 - val_accuracy: 0.8839\n",
            "Epoch 48/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.3951 - accuracy: 0.9887 - val_loss: 8.6790 - val_accuracy: 0.8903\n",
            "Epoch 49/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.0923 - accuracy: 0.9806 - val_loss: 8.3038 - val_accuracy: 0.9032\n",
            "Epoch 50/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.7508 - accuracy: 0.9935 - val_loss: 8.6102 - val_accuracy: 0.8516\n",
            "Epoch 51/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.5107 - accuracy: 0.9855 - val_loss: 8.4312 - val_accuracy: 0.8323\n",
            "Epoch 52/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.2664 - accuracy: 0.9790 - val_loss: 8.1831 - val_accuracy: 0.8194\n",
            "Epoch 53/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.9367 - accuracy: 0.9952 - val_loss: 7.3676 - val_accuracy: 0.9032\n",
            "Epoch 54/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 6.6902 - accuracy: 0.9903 - val_loss: 7.0648 - val_accuracy: 0.9161\n",
            "Epoch 55/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.4520 - accuracy: 0.9919 - val_loss: 6.7117 - val_accuracy: 0.8968\n",
            "Epoch 56/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.2000 - accuracy: 0.9968 - val_loss: 6.6005 - val_accuracy: 0.8903\n",
            "Epoch 57/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 5.9703 - accuracy: 0.9952 - val_loss: 6.3850 - val_accuracy: 0.9032\n",
            "Epoch 58/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.7783 - accuracy: 0.9903 - val_loss: 6.2343 - val_accuracy: 0.8903\n",
            "Epoch 59/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.5612 - accuracy: 0.9952 - val_loss: 5.8428 - val_accuracy: 0.9032\n",
            "Epoch 60/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 5.3793 - accuracy: 0.9855 - val_loss: 5.6085 - val_accuracy: 0.8774\n",
            "Epoch 61/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.1561 - accuracy: 0.9952 - val_loss: 5.5299 - val_accuracy: 0.8903\n",
            "Epoch 62/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 4.9687 - accuracy: 0.9968 - val_loss: 5.2988 - val_accuracy: 0.8839\n",
            "Epoch 63/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.8337 - accuracy: 0.9871 - val_loss: 5.0375 - val_accuracy: 0.9032\n",
            "Epoch 64/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.6132 - accuracy: 1.0000 - val_loss: 4.8933 - val_accuracy: 0.8903\n",
            "Epoch 65/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 4.4787 - accuracy: 0.9887 - val_loss: 4.8358 - val_accuracy: 0.9161\n",
            "Epoch 66/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 4.3855 - accuracy: 0.9887 - val_loss: 5.0325 - val_accuracy: 0.8710\n",
            "Epoch 67/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 4.2251 - accuracy: 0.9838 - val_loss: 4.9333 - val_accuracy: 0.8452\n",
            "Epoch 68/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.1111 - accuracy: 0.9822 - val_loss: 4.3877 - val_accuracy: 0.8645\n",
            "Epoch 69/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.8972 - accuracy: 0.9935 - val_loss: 4.5101 - val_accuracy: 0.8774\n",
            "Epoch 70/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.7603 - accuracy: 0.9984 - val_loss: 4.1249 - val_accuracy: 0.9097\n",
            "Epoch 71/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.6267 - accuracy: 0.9984 - val_loss: 3.9459 - val_accuracy: 0.9290\n",
            "Epoch 72/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.5141 - accuracy: 0.9968 - val_loss: 3.8140 - val_accuracy: 0.9032\n",
            "Epoch 73/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.3724 - accuracy: 0.9968 - val_loss: 3.7058 - val_accuracy: 0.8968\n",
            "Epoch 74/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.2533 - accuracy: 0.9968 - val_loss: 3.5955 - val_accuracy: 0.8645\n",
            "Epoch 75/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.1421 - accuracy: 0.9984 - val_loss: 3.4796 - val_accuracy: 0.8774\n",
            "Epoch 76/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.0369 - accuracy: 0.9968 - val_loss: 3.3099 - val_accuracy: 0.8968\n",
            "Epoch 77/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.9179 - accuracy: 1.0000 - val_loss: 3.4589 - val_accuracy: 0.8645\n",
            "Epoch 78/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.8241 - accuracy: 0.9984 - val_loss: 3.2708 - val_accuracy: 0.8839\n",
            "Epoch 79/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.7244 - accuracy: 1.0000 - val_loss: 3.1609 - val_accuracy: 0.9226\n",
            "Epoch 80/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.6369 - accuracy: 0.9968 - val_loss: 3.0658 - val_accuracy: 0.9419\n",
            "Epoch 81/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.5574 - accuracy: 0.9935 - val_loss: 3.2593 - val_accuracy: 0.8710\n",
            "Epoch 82/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.4759 - accuracy: 0.9903 - val_loss: 2.7647 - val_accuracy: 0.8968\n",
            "Epoch 83/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 2.3788 - accuracy: 0.9968 - val_loss: 2.6948 - val_accuracy: 0.8968\n",
            "Epoch 84/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.2841 - accuracy: 1.0000 - val_loss: 2.6052 - val_accuracy: 0.8903\n",
            "Epoch 85/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.2046 - accuracy: 0.9984 - val_loss: 2.5972 - val_accuracy: 0.8903\n",
            "Epoch 86/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.1344 - accuracy: 0.9968 - val_loss: 2.5406 - val_accuracy: 0.8968\n",
            "Epoch 87/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.0638 - accuracy: 0.9968 - val_loss: 2.5479 - val_accuracy: 0.9032\n",
            "Epoch 88/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.9854 - accuracy: 0.9952 - val_loss: 2.7485 - val_accuracy: 0.8774\n",
            "Epoch 89/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.9238 - accuracy: 0.9952 - val_loss: 2.5933 - val_accuracy: 0.9032\n",
            "Epoch 90/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.8607 - accuracy: 0.9952 - val_loss: 2.3947 - val_accuracy: 0.9161\n",
            "Epoch 91/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.7846 - accuracy: 0.9984 - val_loss: 2.3053 - val_accuracy: 0.9032\n",
            "Epoch 92/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.7260 - accuracy: 0.9984 - val_loss: 2.2704 - val_accuracy: 0.8903\n",
            "Epoch 93/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.6635 - accuracy: 0.9984 - val_loss: 2.2198 - val_accuracy: 0.9097\n",
            "Epoch 94/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.6057 - accuracy: 0.9984 - val_loss: 2.2269 - val_accuracy: 0.8968\n",
            "Epoch 95/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.5945 - accuracy: 0.9903 - val_loss: 2.5273 - val_accuracy: 0.8581\n",
            "Epoch 96/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.5718 - accuracy: 0.9822 - val_loss: 1.8960 - val_accuracy: 0.9032\n",
            "Epoch 97/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.4926 - accuracy: 0.9903 - val_loss: 1.9330 - val_accuracy: 0.9032\n",
            "Epoch 98/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.4385 - accuracy: 0.9919 - val_loss: 2.0413 - val_accuracy: 0.8903\n",
            "Epoch 99/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.3731 - accuracy: 0.9984 - val_loss: 1.9831 - val_accuracy: 0.9161\n",
            "Epoch 100/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.3331 - accuracy: 0.9968 - val_loss: 1.8765 - val_accuracy: 0.9161\n",
            "Epoch 101/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.2807 - accuracy: 1.0000 - val_loss: 1.7702 - val_accuracy: 0.9226\n",
            "Epoch 102/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.2362 - accuracy: 1.0000 - val_loss: 1.7278 - val_accuracy: 0.9226\n",
            "Epoch 103/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 1.2057 - accuracy: 0.9935 - val_loss: 1.7223 - val_accuracy: 0.9097\n",
            "Epoch 104/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 1.1767 - accuracy: 0.9935 - val_loss: 1.6520 - val_accuracy: 0.8903\n",
            "Epoch 105/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.1144 - accuracy: 0.9984 - val_loss: 1.5829 - val_accuracy: 0.9097\n",
            "Epoch 106/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.1124 - accuracy: 0.9903 - val_loss: 1.7317 - val_accuracy: 0.8581\n",
            "Epoch 107/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0387 - accuracy: 1.0000 - val_loss: 1.8594 - val_accuracy: 0.8452\n",
            "Epoch 108/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0102 - accuracy: 0.9984 - val_loss: 1.7095 - val_accuracy: 0.8839\n",
            "Epoch 109/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0368 - accuracy: 0.9838 - val_loss: 1.7483 - val_accuracy: 0.8774\n",
            "Epoch 110/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.9703 - accuracy: 0.9919 - val_loss: 1.7875 - val_accuracy: 0.8903\n",
            "Epoch 111/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.9398 - accuracy: 0.9968 - val_loss: 1.9868 - val_accuracy: 0.8774\n",
            "Epoch 112/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.9505 - accuracy: 0.9935 - val_loss: 1.8860 - val_accuracy: 0.8903\n",
            "Epoch 113/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.8976 - accuracy: 0.9935 - val_loss: 1.6019 - val_accuracy: 0.8968\n",
            "Epoch 114/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.8724 - accuracy: 0.9935 - val_loss: 1.5382 - val_accuracy: 0.8839\n",
            "Epoch 115/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.8607 - accuracy: 0.9919 - val_loss: 1.5826 - val_accuracy: 0.8903\n",
            "Epoch 116/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.8187 - accuracy: 0.9984 - val_loss: 1.4883 - val_accuracy: 0.8839\n",
            "Epoch 117/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.7881 - accuracy: 1.0000 - val_loss: 1.2641 - val_accuracy: 0.9161\n",
            "Epoch 118/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.7606 - accuracy: 0.9984 - val_loss: 1.2198 - val_accuracy: 0.9226\n",
            "Epoch 119/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.7475 - accuracy: 0.9952 - val_loss: 1.1781 - val_accuracy: 0.9290\n",
            "Epoch 120/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7045 - accuracy: 1.0000 - val_loss: 1.1867 - val_accuracy: 0.9097\n",
            "Epoch 121/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6903 - accuracy: 0.9984 - val_loss: 1.0736 - val_accuracy: 0.9290\n",
            "Epoch 122/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6661 - accuracy: 0.9968 - val_loss: 1.0910 - val_accuracy: 0.9290\n",
            "Epoch 123/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6420 - accuracy: 0.9968 - val_loss: 1.2479 - val_accuracy: 0.9097\n",
            "Epoch 124/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6323 - accuracy: 0.9952 - val_loss: 1.4448 - val_accuracy: 0.8774\n",
            "Epoch 125/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6052 - accuracy: 0.9984 - val_loss: 1.2341 - val_accuracy: 0.9097\n",
            "Epoch 126/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5803 - accuracy: 0.9984 - val_loss: 1.1679 - val_accuracy: 0.9161\n",
            "Epoch 127/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5650 - accuracy: 0.9919 - val_loss: 1.4873 - val_accuracy: 0.8968\n",
            "Epoch 128/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5512 - accuracy: 0.9968 - val_loss: 1.3602 - val_accuracy: 0.8774\n",
            "Epoch 129/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.5189 - accuracy: 0.9984 - val_loss: 1.4075 - val_accuracy: 0.8774\n",
            "Epoch 130/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5080 - accuracy: 0.9952 - val_loss: 1.4214 - val_accuracy: 0.8516\n",
            "Epoch 131/150\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.4786 - accuracy: 1.0000 - val_loss: 1.6249 - val_accuracy: 0.8516\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0735 - accuracy: 0.9290\n",
            "Test Loss: 1.0735466480255127, Test Accuracy: 0.9290322661399841\n",
            "Epoch 1/150\n",
            "10/10 [==============================] - 9s 86ms/step - loss: 50.5697 - accuracy: 0.5145 - val_loss: 49.4814 - val_accuracy: 0.7273\n",
            "Epoch 2/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 49.1082 - accuracy: 0.6855 - val_loss: 48.2358 - val_accuracy: 0.7273\n",
            "Epoch 3/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 47.7066 - accuracy: 0.7645 - val_loss: 47.0059 - val_accuracy: 0.7273\n",
            "Epoch 4/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 46.2898 - accuracy: 0.8484 - val_loss: 45.7770 - val_accuracy: 0.7273\n",
            "Epoch 5/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 44.9802 - accuracy: 0.9032 - val_loss: 44.5956 - val_accuracy: 0.7273\n",
            "Epoch 6/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 43.5961 - accuracy: 0.9419 - val_loss: 43.4243 - val_accuracy: 0.7273\n",
            "Epoch 7/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 42.2283 - accuracy: 0.9774 - val_loss: 42.3019 - val_accuracy: 0.7273\n",
            "Epoch 8/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 40.9134 - accuracy: 0.9903 - val_loss: 41.0952 - val_accuracy: 0.7273\n",
            "Epoch 9/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 39.6174 - accuracy: 0.9871 - val_loss: 39.9577 - val_accuracy: 0.7273\n",
            "Epoch 10/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 38.3140 - accuracy: 0.9919 - val_loss: 38.7883 - val_accuracy: 0.7273\n",
            "Epoch 11/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 37.0068 - accuracy: 0.9952 - val_loss: 37.5849 - val_accuracy: 0.7273\n",
            "Epoch 12/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 35.7192 - accuracy: 0.9984 - val_loss: 36.2781 - val_accuracy: 0.7273\n",
            "Epoch 13/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 34.4914 - accuracy: 0.9855 - val_loss: 35.2045 - val_accuracy: 0.7273\n",
            "Epoch 14/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 33.2305 - accuracy: 0.9919 - val_loss: 33.9864 - val_accuracy: 0.7273\n",
            "Epoch 15/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 31.9967 - accuracy: 0.9952 - val_loss: 32.8338 - val_accuracy: 0.7273\n",
            "Epoch 16/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 30.8037 - accuracy: 0.9935 - val_loss: 31.6859 - val_accuracy: 0.7273\n",
            "Epoch 17/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 29.6322 - accuracy: 0.9984 - val_loss: 30.4485 - val_accuracy: 0.7273\n",
            "Epoch 18/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 28.4890 - accuracy: 1.0000 - val_loss: 29.2757 - val_accuracy: 0.7273\n",
            "Epoch 19/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 27.3797 - accuracy: 0.9984 - val_loss: 28.1697 - val_accuracy: 0.7273\n",
            "Epoch 20/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 26.3020 - accuracy: 0.9968 - val_loss: 27.0841 - val_accuracy: 0.7273\n",
            "Epoch 21/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 25.2466 - accuracy: 1.0000 - val_loss: 26.1306 - val_accuracy: 0.7273\n",
            "Epoch 22/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 24.2394 - accuracy: 0.9968 - val_loss: 24.9226 - val_accuracy: 0.7273\n",
            "Epoch 23/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 23.2557 - accuracy: 0.9984 - val_loss: 23.8784 - val_accuracy: 0.7338\n",
            "Epoch 24/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 22.3107 - accuracy: 0.9984 - val_loss: 22.8998 - val_accuracy: 0.7403\n",
            "Epoch 25/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 21.4176 - accuracy: 0.9935 - val_loss: 21.7803 - val_accuracy: 0.7532\n",
            "Epoch 26/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 20.5311 - accuracy: 0.9952 - val_loss: 21.0754 - val_accuracy: 0.7532\n",
            "Epoch 27/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 19.6902 - accuracy: 0.9952 - val_loss: 20.0406 - val_accuracy: 0.7792\n",
            "Epoch 28/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 18.8956 - accuracy: 0.9952 - val_loss: 19.1561 - val_accuracy: 0.7987\n",
            "Epoch 29/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 18.1141 - accuracy: 0.9968 - val_loss: 18.4152 - val_accuracy: 0.8377\n",
            "Epoch 30/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 17.3793 - accuracy: 0.9935 - val_loss: 17.5739 - val_accuracy: 0.8247\n",
            "Epoch 31/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 16.6866 - accuracy: 0.9903 - val_loss: 17.0015 - val_accuracy: 0.8182\n",
            "Epoch 32/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 15.9889 - accuracy: 0.9919 - val_loss: 16.1821 - val_accuracy: 0.8571\n",
            "Epoch 33/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 15.3522 - accuracy: 0.9935 - val_loss: 15.4615 - val_accuracy: 0.8636\n",
            "Epoch 34/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 14.7205 - accuracy: 0.9903 - val_loss: 14.9039 - val_accuracy: 0.8377\n",
            "Epoch 35/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 14.1209 - accuracy: 0.9935 - val_loss: 14.4222 - val_accuracy: 0.8506\n",
            "Epoch 36/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.5672 - accuracy: 0.9919 - val_loss: 13.5717 - val_accuracy: 0.9091\n",
            "Epoch 37/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.0221 - accuracy: 0.9919 - val_loss: 12.9816 - val_accuracy: 0.9221\n",
            "Epoch 38/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 12.5071 - accuracy: 0.9935 - val_loss: 12.4783 - val_accuracy: 0.9091\n",
            "Epoch 39/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 12.0101 - accuracy: 0.9919 - val_loss: 12.1325 - val_accuracy: 0.8896\n",
            "Epoch 40/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 11.5420 - accuracy: 0.9903 - val_loss: 11.6722 - val_accuracy: 0.9221\n",
            "Epoch 41/150\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 11.0804 - accuracy: 0.9871 - val_loss: 11.1810 - val_accuracy: 0.9221\n",
            "Epoch 42/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 10.6650 - accuracy: 0.9839 - val_loss: 10.8272 - val_accuracy: 0.8961\n",
            "Epoch 43/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.2704 - accuracy: 0.9790 - val_loss: 10.4205 - val_accuracy: 0.8506\n",
            "Epoch 44/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.8446 - accuracy: 0.9871 - val_loss: 10.0133 - val_accuracy: 0.9026\n",
            "Epoch 45/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.5431 - accuracy: 0.9823 - val_loss: 10.0300 - val_accuracy: 0.8571\n",
            "Epoch 46/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 9.1782 - accuracy: 0.9742 - val_loss: 9.4649 - val_accuracy: 0.8961\n",
            "Epoch 47/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.0137 - accuracy: 0.9468 - val_loss: 9.2343 - val_accuracy: 0.8442\n",
            "Epoch 48/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.6709 - accuracy: 0.9597 - val_loss: 8.7921 - val_accuracy: 0.9091\n",
            "Epoch 49/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.3804 - accuracy: 0.9645 - val_loss: 8.4947 - val_accuracy: 0.9026\n",
            "Epoch 50/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.9815 - accuracy: 0.9823 - val_loss: 8.1746 - val_accuracy: 0.9156\n",
            "Epoch 51/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.7121 - accuracy: 0.9871 - val_loss: 7.8842 - val_accuracy: 0.9026\n",
            "Epoch 52/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.4376 - accuracy: 0.9871 - val_loss: 7.7163 - val_accuracy: 0.8961\n",
            "Epoch 53/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.1708 - accuracy: 0.9952 - val_loss: 7.3539 - val_accuracy: 0.9286\n",
            "Epoch 54/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.9165 - accuracy: 0.9952 - val_loss: 7.0871 - val_accuracy: 0.9221\n",
            "Epoch 55/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.6593 - accuracy: 1.0000 - val_loss: 6.9711 - val_accuracy: 0.9091\n",
            "Epoch 56/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.4211 - accuracy: 1.0000 - val_loss: 6.7901 - val_accuracy: 0.9156\n",
            "Epoch 57/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.2070 - accuracy: 0.9935 - val_loss: 6.4430 - val_accuracy: 0.9221\n",
            "Epoch 58/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.9707 - accuracy: 1.0000 - val_loss: 6.1960 - val_accuracy: 0.9221\n",
            "Epoch 59/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 5.7718 - accuracy: 0.9984 - val_loss: 6.0343 - val_accuracy: 0.9286\n",
            "Epoch 60/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.5520 - accuracy: 0.9984 - val_loss: 5.8420 - val_accuracy: 0.9286\n",
            "Epoch 61/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.3547 - accuracy: 0.9984 - val_loss: 5.6928 - val_accuracy: 0.9286\n",
            "Epoch 62/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.1824 - accuracy: 1.0000 - val_loss: 5.5671 - val_accuracy: 0.9221\n",
            "Epoch 63/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.9836 - accuracy: 1.0000 - val_loss: 5.4699 - val_accuracy: 0.9026\n",
            "Epoch 64/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.8328 - accuracy: 0.9968 - val_loss: 5.2479 - val_accuracy: 0.9091\n",
            "Epoch 65/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.6581 - accuracy: 0.9952 - val_loss: 5.0483 - val_accuracy: 0.9026\n",
            "Epoch 66/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.5021 - accuracy: 0.9968 - val_loss: 4.8804 - val_accuracy: 0.9091\n",
            "Epoch 67/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.3453 - accuracy: 0.9935 - val_loss: 4.6361 - val_accuracy: 0.8896\n",
            "Epoch 68/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.2048 - accuracy: 0.9903 - val_loss: 4.3518 - val_accuracy: 0.9286\n",
            "Epoch 69/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.0633 - accuracy: 0.9952 - val_loss: 4.2410 - val_accuracy: 0.9156\n",
            "Epoch 70/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.9032 - accuracy: 0.9968 - val_loss: 4.1566 - val_accuracy: 0.9091\n",
            "Epoch 71/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.7631 - accuracy: 1.0000 - val_loss: 4.0881 - val_accuracy: 0.8831\n",
            "Epoch 72/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.6387 - accuracy: 0.9968 - val_loss: 3.9480 - val_accuracy: 0.9026\n",
            "Epoch 73/150\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 3.5043 - accuracy: 1.0000 - val_loss: 3.8996 - val_accuracy: 0.8961\n",
            "Epoch 74/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.3815 - accuracy: 1.0000 - val_loss: 3.7772 - val_accuracy: 0.8896\n",
            "Epoch 75/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.2615 - accuracy: 1.0000 - val_loss: 3.6377 - val_accuracy: 0.9091\n",
            "Epoch 76/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.1458 - accuracy: 1.0000 - val_loss: 3.5039 - val_accuracy: 0.9091\n",
            "Epoch 77/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.0376 - accuracy: 0.9984 - val_loss: 3.3953 - val_accuracy: 0.9156\n",
            "Epoch 78/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.9265 - accuracy: 1.0000 - val_loss: 3.2572 - val_accuracy: 0.9156\n",
            "Epoch 79/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.8245 - accuracy: 1.0000 - val_loss: 3.1574 - val_accuracy: 0.9091\n",
            "Epoch 80/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.7248 - accuracy: 1.0000 - val_loss: 3.0682 - val_accuracy: 0.9156\n",
            "Epoch 81/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.6306 - accuracy: 1.0000 - val_loss: 3.0663 - val_accuracy: 0.9091\n",
            "Epoch 82/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.5464 - accuracy: 0.9968 - val_loss: 2.8890 - val_accuracy: 0.9091\n",
            "Epoch 83/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.4627 - accuracy: 0.9952 - val_loss: 3.0136 - val_accuracy: 0.8896\n",
            "Epoch 84/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.3793 - accuracy: 0.9968 - val_loss: 2.9062 - val_accuracy: 0.9026\n",
            "Epoch 85/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.2906 - accuracy: 1.0000 - val_loss: 2.7180 - val_accuracy: 0.9286\n",
            "Epoch 86/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.2226 - accuracy: 0.9968 - val_loss: 2.6359 - val_accuracy: 0.9221\n",
            "Epoch 87/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.1566 - accuracy: 0.9968 - val_loss: 2.5293 - val_accuracy: 0.9221\n",
            "Epoch 88/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.0657 - accuracy: 0.9984 - val_loss: 2.4286 - val_accuracy: 0.9351\n",
            "Epoch 89/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.9930 - accuracy: 1.0000 - val_loss: 2.4518 - val_accuracy: 0.9221\n",
            "Epoch 90/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.9255 - accuracy: 0.9984 - val_loss: 2.4342 - val_accuracy: 0.9156\n",
            "Epoch 91/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.8709 - accuracy: 0.9968 - val_loss: 2.3323 - val_accuracy: 0.9026\n",
            "Epoch 92/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.8170 - accuracy: 0.9952 - val_loss: 2.8998 - val_accuracy: 0.8961\n",
            "Epoch 93/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.8710 - accuracy: 0.9726 - val_loss: 3.4635 - val_accuracy: 0.8831\n",
            "Epoch 94/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.8418 - accuracy: 0.9774 - val_loss: 2.6700 - val_accuracy: 0.9026\n",
            "Epoch 95/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.7410 - accuracy: 0.9806 - val_loss: 2.5546 - val_accuracy: 0.8831\n",
            "Epoch 96/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.6988 - accuracy: 0.9823 - val_loss: 2.3505 - val_accuracy: 0.9156\n",
            "Epoch 97/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.6028 - accuracy: 0.9952 - val_loss: 2.1657 - val_accuracy: 0.9221\n",
            "Epoch 98/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.5480 - accuracy: 0.9984 - val_loss: 2.2833 - val_accuracy: 0.8896\n",
            "Epoch 99/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.4923 - accuracy: 0.9984 - val_loss: 2.4110 - val_accuracy: 0.8701\n",
            "Epoch 100/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.4529 - accuracy: 0.9952 - val_loss: 2.1282 - val_accuracy: 0.8961\n",
            "Epoch 101/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.3902 - accuracy: 1.0000 - val_loss: 2.0004 - val_accuracy: 0.9156\n",
            "Epoch 102/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.3447 - accuracy: 0.9968 - val_loss: 1.9539 - val_accuracy: 0.9156\n",
            "Epoch 103/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.2937 - accuracy: 1.0000 - val_loss: 1.9839 - val_accuracy: 0.8961\n",
            "Epoch 104/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.2591 - accuracy: 0.9984 - val_loss: 1.8170 - val_accuracy: 0.9156\n",
            "Epoch 105/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.2146 - accuracy: 0.9968 - val_loss: 1.8637 - val_accuracy: 0.9026\n",
            "Epoch 106/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.1750 - accuracy: 0.9968 - val_loss: 1.8172 - val_accuracy: 0.8961\n",
            "Epoch 107/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.1332 - accuracy: 0.9984 - val_loss: 1.6490 - val_accuracy: 0.9351\n",
            "Epoch 108/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.0889 - accuracy: 0.9984 - val_loss: 1.6191 - val_accuracy: 0.9286\n",
            "Epoch 109/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.0480 - accuracy: 1.0000 - val_loss: 1.6318 - val_accuracy: 0.9221\n",
            "Epoch 110/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.0139 - accuracy: 0.9968 - val_loss: 1.6475 - val_accuracy: 0.9156\n",
            "Epoch 111/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.9764 - accuracy: 1.0000 - val_loss: 1.5829 - val_accuracy: 0.9156\n",
            "Epoch 112/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.9475 - accuracy: 0.9984 - val_loss: 1.6668 - val_accuracy: 0.9091\n",
            "Epoch 113/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.9260 - accuracy: 0.9952 - val_loss: 1.5437 - val_accuracy: 0.9026\n",
            "Epoch 114/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.8892 - accuracy: 0.9984 - val_loss: 1.4443 - val_accuracy: 0.9221\n",
            "Epoch 115/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.8861 - accuracy: 0.9968 - val_loss: 1.6013 - val_accuracy: 0.9091\n",
            "Epoch 116/150\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8725 - accuracy: 0.9952 - val_loss: 1.5594 - val_accuracy: 0.9221\n",
            "Epoch 117/150\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8538 - accuracy: 0.9952 - val_loss: 1.6132 - val_accuracy: 0.9026\n",
            "Epoch 118/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.8374 - accuracy: 0.9952 - val_loss: 1.8680 - val_accuracy: 0.8571\n",
            "Epoch 119/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.8261 - accuracy: 0.9984 - val_loss: 1.6357 - val_accuracy: 0.9026\n",
            "Epoch 120/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7930 - accuracy: 0.9952 - val_loss: 1.7023 - val_accuracy: 0.9091\n",
            "Epoch 121/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.7668 - accuracy: 0.9952 - val_loss: 1.3711 - val_accuracy: 0.9156\n",
            "Epoch 122/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7344 - accuracy: 0.9968 - val_loss: 1.4376 - val_accuracy: 0.9026\n",
            "Epoch 123/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7048 - accuracy: 1.0000 - val_loss: 1.3742 - val_accuracy: 0.9156\n",
            "Epoch 124/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6816 - accuracy: 0.9984 - val_loss: 1.3516 - val_accuracy: 0.9026\n",
            "Epoch 125/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6575 - accuracy: 0.9984 - val_loss: 1.1844 - val_accuracy: 0.9221\n",
            "Epoch 126/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6368 - accuracy: 0.9968 - val_loss: 1.2276 - val_accuracy: 0.9091\n",
            "Epoch 127/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6761 - accuracy: 0.9903 - val_loss: 1.4599 - val_accuracy: 0.9026\n",
            "Epoch 128/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6076 - accuracy: 0.9952 - val_loss: 1.3163 - val_accuracy: 0.8896\n",
            "Epoch 129/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6012 - accuracy: 0.9919 - val_loss: 1.3263 - val_accuracy: 0.9026\n",
            "Epoch 130/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5995 - accuracy: 0.9935 - val_loss: 1.1887 - val_accuracy: 0.9221\n",
            "Epoch 131/150\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.5636 - accuracy: 0.9919 - val_loss: 1.0418 - val_accuracy: 0.9156\n",
            "Epoch 132/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.5931 - accuracy: 0.9887 - val_loss: 1.0678 - val_accuracy: 0.9091\n",
            "Epoch 133/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5285 - accuracy: 0.9952 - val_loss: 1.4045 - val_accuracy: 0.8571\n",
            "Epoch 134/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5028 - accuracy: 0.9984 - val_loss: 1.1874 - val_accuracy: 0.8831\n",
            "Epoch 135/150\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5031 - accuracy: 0.9935 - val_loss: 0.9580 - val_accuracy: 0.9351\n",
            "Epoch 136/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4671 - accuracy: 1.0000 - val_loss: 0.8666 - val_accuracy: 0.9221\n",
            "Epoch 137/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.4701 - accuracy: 0.9968 - val_loss: 0.8705 - val_accuracy: 0.9481\n",
            "Epoch 138/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4378 - accuracy: 1.0000 - val_loss: 0.9816 - val_accuracy: 0.9416\n",
            "Epoch 139/150\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4204 - accuracy: 1.0000 - val_loss: 0.9178 - val_accuracy: 0.9351\n",
            "Epoch 140/150\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4063 - accuracy: 0.9984 - val_loss: 0.7995 - val_accuracy: 0.9481\n",
            "Epoch 141/150\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3926 - accuracy: 0.9984 - val_loss: 0.7043 - val_accuracy: 0.9351\n",
            "Epoch 142/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3798 - accuracy: 0.9984 - val_loss: 0.8194 - val_accuracy: 0.9221\n",
            "Epoch 143/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3632 - accuracy: 1.0000 - val_loss: 0.8854 - val_accuracy: 0.9351\n",
            "Epoch 144/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3503 - accuracy: 1.0000 - val_loss: 0.8892 - val_accuracy: 0.9416\n",
            "Epoch 145/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3551 - accuracy: 0.9968 - val_loss: 0.8000 - val_accuracy: 0.9286\n",
            "Epoch 146/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3275 - accuracy: 1.0000 - val_loss: 0.7923 - val_accuracy: 0.9091\n",
            "Epoch 147/150\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3254 - accuracy: 0.9952 - val_loss: 0.7199 - val_accuracy: 0.9156\n",
            "Epoch 148/150\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3229 - accuracy: 0.9984 - val_loss: 0.7738 - val_accuracy: 0.9156\n",
            "Epoch 149/150\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3176 - accuracy: 1.0000 - val_loss: 1.0722 - val_accuracy: 0.9026\n",
            "Epoch 150/150\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3161 - accuracy: 0.9984 - val_loss: 0.8730 - val_accuracy: 0.9286\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8730 - accuracy: 0.9286\n",
            "Test Loss: 0.873046875, Test Accuracy: 0.9285714030265808\n",
            "\n",
            "Average Accuracy Across All Folds: 0.9147465348243713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdamW + Random 증강 + L2규제 + dropout 3개 + Early stopping + epoch 200 + batch_noramalization : 0.90056973695755"
      ],
      "metadata": {
        "id": "m8k9TO0Yn6Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import AdamW\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model_with_early_stopping():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model_with_early_stopping()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5zvvn0pjOtn",
        "outputId": "2df42000-8aae-441a-8a7e-8e68ee3b9cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 9s 86ms/step - loss: 50.5892 - accuracy: 0.5202 - val_loss: 49.5206 - val_accuracy: 0.6323\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 49.1571 - accuracy: 0.6607 - val_loss: 48.3311 - val_accuracy: 0.6323\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 47.7285 - accuracy: 0.7658 - val_loss: 47.1125 - val_accuracy: 0.6323\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 46.3083 - accuracy: 0.8740 - val_loss: 45.8874 - val_accuracy: 0.6323\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 44.9379 - accuracy: 0.9257 - val_loss: 44.6629 - val_accuracy: 0.6323\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 43.5638 - accuracy: 0.9564 - val_loss: 43.5058 - val_accuracy: 0.6323\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 42.2142 - accuracy: 0.9758 - val_loss: 42.3528 - val_accuracy: 0.6323\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 40.9057 - accuracy: 0.9709 - val_loss: 41.2641 - val_accuracy: 0.6323\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 39.5422 - accuracy: 0.9887 - val_loss: 40.1011 - val_accuracy: 0.6323\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 38.2275 - accuracy: 0.9887 - val_loss: 38.8858 - val_accuracy: 0.6323\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 36.9093 - accuracy: 0.9935 - val_loss: 37.5592 - val_accuracy: 0.6323\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 35.5946 - accuracy: 0.9984 - val_loss: 36.2973 - val_accuracy: 0.6323\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 34.3119 - accuracy: 0.9968 - val_loss: 35.0155 - val_accuracy: 0.6323\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 33.0645 - accuracy: 0.9919 - val_loss: 33.7985 - val_accuracy: 0.6323\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 31.8316 - accuracy: 0.9935 - val_loss: 32.8011 - val_accuracy: 0.6323\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 30.6259 - accuracy: 0.9919 - val_loss: 31.4204 - val_accuracy: 0.6323\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 29.4380 - accuracy: 0.9952 - val_loss: 30.0844 - val_accuracy: 0.6323\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 28.2882 - accuracy: 0.9984 - val_loss: 29.3044 - val_accuracy: 0.6323\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 27.1787 - accuracy: 0.9952 - val_loss: 28.2529 - val_accuracy: 0.6323\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 26.0852 - accuracy: 1.0000 - val_loss: 27.0224 - val_accuracy: 0.6323\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 25.0355 - accuracy: 1.0000 - val_loss: 25.9246 - val_accuracy: 0.6323\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 24.0185 - accuracy: 0.9984 - val_loss: 24.7525 - val_accuracy: 0.6452\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 23.0328 - accuracy: 0.9984 - val_loss: 23.5427 - val_accuracy: 0.6774\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 22.0873 - accuracy: 0.9984 - val_loss: 22.8757 - val_accuracy: 0.6387\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 21.1866 - accuracy: 0.9919 - val_loss: 21.9864 - val_accuracy: 0.6516\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 20.2916 - accuracy: 0.9968 - val_loss: 20.7781 - val_accuracy: 0.7290\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 19.4483 - accuracy: 0.9968 - val_loss: 19.7213 - val_accuracy: 0.7742\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 18.6543 - accuracy: 0.9903 - val_loss: 18.8191 - val_accuracy: 0.8065\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 17.9072 - accuracy: 0.9952 - val_loss: 18.3884 - val_accuracy: 0.7548\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 17.1606 - accuracy: 0.9887 - val_loss: 17.2911 - val_accuracy: 0.8452\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 16.4917 - accuracy: 0.9790 - val_loss: 16.5783 - val_accuracy: 0.8323\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 15.8376 - accuracy: 0.9871 - val_loss: 15.9331 - val_accuracy: 0.8452\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 15.1671 - accuracy: 0.9903 - val_loss: 15.3224 - val_accuracy: 0.8323\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 14.5806 - accuracy: 0.9871 - val_loss: 14.8685 - val_accuracy: 0.8065\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 14.0099 - accuracy: 0.9838 - val_loss: 14.4273 - val_accuracy: 0.7806\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.4542 - accuracy: 0.9919 - val_loss: 13.7358 - val_accuracy: 0.8129\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 12.9724 - accuracy: 0.9871 - val_loss: 13.3626 - val_accuracy: 0.8258\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 12.5952 - accuracy: 0.9725 - val_loss: 12.7895 - val_accuracy: 0.7935\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 12.0202 - accuracy: 0.9758 - val_loss: 12.5139 - val_accuracy: 0.8129\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 11.5796 - accuracy: 0.9790 - val_loss: 11.8325 - val_accuracy: 0.8452\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 11.1099 - accuracy: 0.9903 - val_loss: 11.4170 - val_accuracy: 0.8387\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 10.7065 - accuracy: 0.9903 - val_loss: 11.1375 - val_accuracy: 0.8065\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.3118 - accuracy: 0.9887 - val_loss: 10.7745 - val_accuracy: 0.8323\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 9.9058 - accuracy: 0.9919 - val_loss: 10.3574 - val_accuracy: 0.8452\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.5341 - accuracy: 0.9952 - val_loss: 9.9633 - val_accuracy: 0.8516\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.1715 - accuracy: 0.9952 - val_loss: 9.6499 - val_accuracy: 0.8516\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 8.8430 - accuracy: 0.9935 - val_loss: 9.5432 - val_accuracy: 0.8323\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.5441 - accuracy: 0.9887 - val_loss: 8.9843 - val_accuracy: 0.8387\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.3018 - accuracy: 0.9758 - val_loss: 8.7289 - val_accuracy: 0.8065\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.0081 - accuracy: 0.9758 - val_loss: 9.1581 - val_accuracy: 0.8129\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.6913 - accuracy: 0.9790 - val_loss: 8.1983 - val_accuracy: 0.8258\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.4331 - accuracy: 0.9758 - val_loss: 7.9739 - val_accuracy: 0.8452\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 7.1773 - accuracy: 0.9919 - val_loss: 8.0170 - val_accuracy: 0.8129\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.9247 - accuracy: 0.9903 - val_loss: 7.9528 - val_accuracy: 0.8323\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.6658 - accuracy: 0.9903 - val_loss: 7.5174 - val_accuracy: 0.8323\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.4336 - accuracy: 0.9903 - val_loss: 7.2544 - val_accuracy: 0.8194\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.1954 - accuracy: 0.9984 - val_loss: 7.2608 - val_accuracy: 0.8065\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 5.9860 - accuracy: 0.9935 - val_loss: 6.9992 - val_accuracy: 0.8258\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 5.7555 - accuracy: 1.0000 - val_loss: 6.5852 - val_accuracy: 0.8516\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.5573 - accuracy: 0.9968 - val_loss: 6.5224 - val_accuracy: 0.8387\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 5.3541 - accuracy: 1.0000 - val_loss: 6.3822 - val_accuracy: 0.8387\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.1631 - accuracy: 0.9984 - val_loss: 6.0751 - val_accuracy: 0.8516\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.9763 - accuracy: 0.9984 - val_loss: 5.8998 - val_accuracy: 0.8452\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 4.7976 - accuracy: 0.9984 - val_loss: 5.7155 - val_accuracy: 0.8452\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.6233 - accuracy: 1.0000 - val_loss: 5.5327 - val_accuracy: 0.8323\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 4.4566 - accuracy: 1.0000 - val_loss: 5.3507 - val_accuracy: 0.8323\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.2949 - accuracy: 1.0000 - val_loss: 5.1740 - val_accuracy: 0.8323\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.1396 - accuracy: 1.0000 - val_loss: 4.9914 - val_accuracy: 0.8258\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.9901 - accuracy: 1.0000 - val_loss: 4.8179 - val_accuracy: 0.8387\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.8449 - accuracy: 1.0000 - val_loss: 4.6879 - val_accuracy: 0.8452\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.7144 - accuracy: 0.9984 - val_loss: 4.5077 - val_accuracy: 0.8452\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.5797 - accuracy: 0.9984 - val_loss: 4.4291 - val_accuracy: 0.8452\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.4482 - accuracy: 0.9984 - val_loss: 4.1388 - val_accuracy: 0.8452\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.3232 - accuracy: 1.0000 - val_loss: 3.9949 - val_accuracy: 0.8387\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.2026 - accuracy: 1.0000 - val_loss: 3.9128 - val_accuracy: 0.8387\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 3.0922 - accuracy: 0.9984 - val_loss: 3.8196 - val_accuracy: 0.8387\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.9926 - accuracy: 0.9984 - val_loss: 3.7157 - val_accuracy: 0.8452\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.8989 - accuracy: 0.9952 - val_loss: 3.5278 - val_accuracy: 0.8387\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.8055 - accuracy: 0.9935 - val_loss: 3.6754 - val_accuracy: 0.8516\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.7137 - accuracy: 0.9984 - val_loss: 3.7289 - val_accuracy: 0.8452\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.6566 - accuracy: 0.9968 - val_loss: 3.7327 - val_accuracy: 0.8387\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.5923 - accuracy: 0.9887 - val_loss: 3.6379 - val_accuracy: 0.8516\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.4983 - accuracy: 0.9952 - val_loss: 4.0405 - val_accuracy: 0.8323\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.4334 - accuracy: 0.9887 - val_loss: 3.6138 - val_accuracy: 0.8710\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.3546 - accuracy: 0.9919 - val_loss: 4.3495 - val_accuracy: 0.7871\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.2930 - accuracy: 0.9935 - val_loss: 4.3098 - val_accuracy: 0.8000\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.1935 - accuracy: 1.0000 - val_loss: 4.0157 - val_accuracy: 0.8000\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 2.1332 - accuracy: 0.9968 - val_loss: 3.7293 - val_accuracy: 0.8387\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.5278 - accuracy: 0.8387\n",
            "Test Loss: 3.5278289318084717, Test Accuracy: 0.8387096524238586\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 9s 87ms/step - loss: 50.5050 - accuracy: 0.5218 - val_loss: 49.4960 - val_accuracy: 0.7161\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 49.1569 - accuracy: 0.6300 - val_loss: 48.3138 - val_accuracy: 0.7161\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 47.7415 - accuracy: 0.7544 - val_loss: 47.1133 - val_accuracy: 0.7161\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 46.3659 - accuracy: 0.8481 - val_loss: 45.8905 - val_accuracy: 0.7161\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 44.9606 - accuracy: 0.8966 - val_loss: 44.5996 - val_accuracy: 0.7161\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 43.5656 - accuracy: 0.9532 - val_loss: 43.2953 - val_accuracy: 0.7161\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 42.2255 - accuracy: 0.9677 - val_loss: 41.9934 - val_accuracy: 0.7161\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 40.8880 - accuracy: 0.9822 - val_loss: 40.6891 - val_accuracy: 0.7161\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 39.5546 - accuracy: 0.9952 - val_loss: 39.3781 - val_accuracy: 0.7161\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 38.2271 - accuracy: 0.9968 - val_loss: 38.0659 - val_accuracy: 0.7161\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 36.9317 - accuracy: 0.9887 - val_loss: 36.7764 - val_accuracy: 0.7161\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 35.6310 - accuracy: 0.9887 - val_loss: 35.4868 - val_accuracy: 0.7161\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 34.3415 - accuracy: 0.9919 - val_loss: 34.2153 - val_accuracy: 0.7161\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 33.0894 - accuracy: 0.9887 - val_loss: 32.9711 - val_accuracy: 0.7161\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 31.8476 - accuracy: 0.9935 - val_loss: 31.8192 - val_accuracy: 0.7161\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 30.6658 - accuracy: 0.9871 - val_loss: 30.6405 - val_accuracy: 0.7161\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 29.4818 - accuracy: 0.9871 - val_loss: 29.4076 - val_accuracy: 0.7161\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 28.3443 - accuracy: 0.9919 - val_loss: 28.3105 - val_accuracy: 0.7226\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 27.2564 - accuracy: 0.9871 - val_loss: 27.2036 - val_accuracy: 0.7226\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 26.1592 - accuracy: 0.9935 - val_loss: 26.1587 - val_accuracy: 0.7290\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 25.1227 - accuracy: 0.9903 - val_loss: 25.2025 - val_accuracy: 0.7290\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 24.1098 - accuracy: 0.9968 - val_loss: 24.1075 - val_accuracy: 0.7742\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 23.1627 - accuracy: 0.9919 - val_loss: 23.0579 - val_accuracy: 0.8000\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 22.2409 - accuracy: 0.9919 - val_loss: 22.2448 - val_accuracy: 0.7871\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 21.3409 - accuracy: 0.9871 - val_loss: 21.2328 - val_accuracy: 0.8065\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 20.4855 - accuracy: 0.9903 - val_loss: 20.6387 - val_accuracy: 0.7742\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 19.6395 - accuracy: 0.9952 - val_loss: 19.5750 - val_accuracy: 0.8452\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 18.8530 - accuracy: 0.9952 - val_loss: 18.8494 - val_accuracy: 0.8323\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 18.0901 - accuracy: 0.9887 - val_loss: 18.1289 - val_accuracy: 0.8258\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 17.4058 - accuracy: 0.9887 - val_loss: 17.5132 - val_accuracy: 0.8258\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 16.6731 - accuracy: 0.9952 - val_loss: 16.7435 - val_accuracy: 0.8258\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 15.9815 - accuracy: 0.9935 - val_loss: 16.0693 - val_accuracy: 0.8516\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 15.3246 - accuracy: 0.9952 - val_loss: 15.2844 - val_accuracy: 0.8903\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 14.7176 - accuracy: 0.9919 - val_loss: 14.8469 - val_accuracy: 0.8452\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 14.1030 - accuracy: 0.9968 - val_loss: 14.1186 - val_accuracy: 0.8839\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 13.5339 - accuracy: 0.9952 - val_loss: 13.5568 - val_accuracy: 0.8774\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 12.9747 - accuracy: 1.0000 - val_loss: 12.9958 - val_accuracy: 0.8968\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 12.4496 - accuracy: 1.0000 - val_loss: 12.4463 - val_accuracy: 0.9097\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 11.9344 - accuracy: 1.0000 - val_loss: 11.9214 - val_accuracy: 0.9226\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 11.4492 - accuracy: 1.0000 - val_loss: 11.5228 - val_accuracy: 0.8839\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 10.9846 - accuracy: 0.9952 - val_loss: 10.9694 - val_accuracy: 0.9097\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 10.5239 - accuracy: 1.0000 - val_loss: 10.5733 - val_accuracy: 0.8968\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 10.0914 - accuracy: 0.9984 - val_loss: 10.1899 - val_accuracy: 0.9032\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 9.6862 - accuracy: 0.9968 - val_loss: 9.8404 - val_accuracy: 0.8839\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 9.3125 - accuracy: 0.9935 - val_loss: 9.3442 - val_accuracy: 0.8968\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.9310 - accuracy: 0.9903 - val_loss: 8.9764 - val_accuracy: 0.9032\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.5512 - accuracy: 0.9984 - val_loss: 8.8206 - val_accuracy: 0.8323\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 8.2716 - accuracy: 0.9822 - val_loss: 8.6393 - val_accuracy: 0.8387\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.9248 - accuracy: 0.9919 - val_loss: 8.4818 - val_accuracy: 0.8323\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.6035 - accuracy: 0.9968 - val_loss: 7.9847 - val_accuracy: 0.8387\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 7.3250 - accuracy: 0.9919 - val_loss: 7.7220 - val_accuracy: 0.8452\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.0715 - accuracy: 0.9903 - val_loss: 7.5094 - val_accuracy: 0.8516\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.7966 - accuracy: 0.9887 - val_loss: 7.1461 - val_accuracy: 0.8903\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.5077 - accuracy: 0.9984 - val_loss: 6.8472 - val_accuracy: 0.8968\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.2917 - accuracy: 0.9952 - val_loss: 6.6005 - val_accuracy: 0.9097\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.0359 - accuracy: 0.9968 - val_loss: 6.5403 - val_accuracy: 0.9032\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.8170 - accuracy: 0.9952 - val_loss: 6.4892 - val_accuracy: 0.8452\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.5954 - accuracy: 0.9935 - val_loss: 6.1222 - val_accuracy: 0.8903\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 5.3992 - accuracy: 0.9952 - val_loss: 6.1872 - val_accuracy: 0.8581\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.2172 - accuracy: 0.9871 - val_loss: 6.0003 - val_accuracy: 0.8710\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 5.0665 - accuracy: 0.9774 - val_loss: 6.2329 - val_accuracy: 0.8452\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.8735 - accuracy: 0.9903 - val_loss: 5.8517 - val_accuracy: 0.8903\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 4.7455 - accuracy: 0.9838 - val_loss: 5.9019 - val_accuracy: 0.8581\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 4.5852 - accuracy: 0.9758 - val_loss: 6.0751 - val_accuracy: 0.8387\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.5193 - accuracy: 0.9677 - val_loss: 6.5440 - val_accuracy: 0.8387\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.3302 - accuracy: 0.9742 - val_loss: 5.7814 - val_accuracy: 0.8645\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.1403 - accuracy: 0.9838 - val_loss: 5.3737 - val_accuracy: 0.8968\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 3.9936 - accuracy: 0.9919 - val_loss: 6.3223 - val_accuracy: 0.8387\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 3.8432 - accuracy: 0.9919 - val_loss: 5.5978 - val_accuracy: 0.8581\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.7265 - accuracy: 0.9903 - val_loss: 5.0175 - val_accuracy: 0.9032\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.5790 - accuracy: 0.9952 - val_loss: 5.0194 - val_accuracy: 0.8839\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.4636 - accuracy: 0.9968 - val_loss: 4.6801 - val_accuracy: 0.8710\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.3403 - accuracy: 0.9968 - val_loss: 4.1354 - val_accuracy: 0.8774\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.2156 - accuracy: 1.0000 - val_loss: 3.9013 - val_accuracy: 0.8774\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.1045 - accuracy: 0.9968 - val_loss: 3.6674 - val_accuracy: 0.8903\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.9987 - accuracy: 0.9968 - val_loss: 3.4934 - val_accuracy: 0.9161\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.8900 - accuracy: 0.9968 - val_loss: 3.6291 - val_accuracy: 0.8968\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 2.7991 - accuracy: 0.9935 - val_loss: 3.2135 - val_accuracy: 0.9161\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.6849 - accuracy: 1.0000 - val_loss: 3.1240 - val_accuracy: 0.8968\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.5952 - accuracy: 0.9952 - val_loss: 3.1570 - val_accuracy: 0.9032\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.5063 - accuracy: 0.9984 - val_loss: 2.9779 - val_accuracy: 0.9290\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.4344 - accuracy: 0.9919 - val_loss: 2.9157 - val_accuracy: 0.8839\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.3497 - accuracy: 0.9935 - val_loss: 2.9494 - val_accuracy: 0.8839\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 2.2713 - accuracy: 0.9952 - val_loss: 2.9958 - val_accuracy: 0.8645\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.2003 - accuracy: 0.9919 - val_loss: 2.8500 - val_accuracy: 0.8710\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.1117 - accuracy: 0.9984 - val_loss: 2.8190 - val_accuracy: 0.9032\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.0422 - accuracy: 0.9984 - val_loss: 2.7271 - val_accuracy: 0.8968\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.9650 - accuracy: 1.0000 - val_loss: 2.6180 - val_accuracy: 0.9161\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.9044 - accuracy: 0.9984 - val_loss: 2.5548 - val_accuracy: 0.8839\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.8291 - accuracy: 1.0000 - val_loss: 2.5817 - val_accuracy: 0.8774\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.7734 - accuracy: 0.9968 - val_loss: 2.4202 - val_accuracy: 0.8903\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.7019 - accuracy: 1.0000 - val_loss: 2.2222 - val_accuracy: 0.8903\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.6675 - accuracy: 0.9952 - val_loss: 2.1578 - val_accuracy: 0.8903\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.6694 - accuracy: 0.9822 - val_loss: 2.3646 - val_accuracy: 0.8710\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.5917 - accuracy: 0.9935 - val_loss: 2.3354 - val_accuracy: 0.8774\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.5449 - accuracy: 0.9919 - val_loss: 2.1844 - val_accuracy: 0.8710\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.4818 - accuracy: 0.9903 - val_loss: 2.0321 - val_accuracy: 0.8903\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.4188 - accuracy: 0.9952 - val_loss: 1.8775 - val_accuracy: 0.8968\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.3667 - accuracy: 0.9968 - val_loss: 1.8906 - val_accuracy: 0.9032\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.3153 - accuracy: 1.0000 - val_loss: 1.9027 - val_accuracy: 0.9032\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.2808 - accuracy: 0.9968 - val_loss: 1.7788 - val_accuracy: 0.9097\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.2258 - accuracy: 1.0000 - val_loss: 1.7387 - val_accuracy: 0.9097\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.2066 - accuracy: 0.9952 - val_loss: 1.5962 - val_accuracy: 0.9161\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.1677 - accuracy: 0.9952 - val_loss: 1.7489 - val_accuracy: 0.8903\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.1140 - accuracy: 0.9968 - val_loss: 1.7871 - val_accuracy: 0.8903\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0682 - accuracy: 1.0000 - val_loss: 1.7456 - val_accuracy: 0.9032\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0338 - accuracy: 1.0000 - val_loss: 1.7867 - val_accuracy: 0.8903\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.0127 - accuracy: 0.9952 - val_loss: 1.5919 - val_accuracy: 0.9032\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.9815 - accuracy: 0.9968 - val_loss: 1.5664 - val_accuracy: 0.9161\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.9385 - accuracy: 0.9968 - val_loss: 1.4581 - val_accuracy: 0.9032\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.9019 - accuracy: 1.0000 - val_loss: 1.3692 - val_accuracy: 0.9097\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.8782 - accuracy: 0.9968 - val_loss: 1.2785 - val_accuracy: 0.9161\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.8455 - accuracy: 0.9952 - val_loss: 1.2596 - val_accuracy: 0.9032\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.8245 - accuracy: 0.9984 - val_loss: 1.3866 - val_accuracy: 0.8968\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.8017 - accuracy: 0.9952 - val_loss: 1.2284 - val_accuracy: 0.9032\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7716 - accuracy: 0.9968 - val_loss: 1.5316 - val_accuracy: 0.8774\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.7441 - accuracy: 1.0000 - val_loss: 1.4586 - val_accuracy: 0.8903\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.7275 - accuracy: 0.9984 - val_loss: 1.4701 - val_accuracy: 0.8968\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7207 - accuracy: 0.9968 - val_loss: 1.2545 - val_accuracy: 0.9097\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6978 - accuracy: 0.9968 - val_loss: 1.4200 - val_accuracy: 0.9032\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6975 - accuracy: 0.9952 - val_loss: 1.3969 - val_accuracy: 0.9097\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6509 - accuracy: 1.0000 - val_loss: 1.2657 - val_accuracy: 0.9161\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6387 - accuracy: 0.9968 - val_loss: 1.3264 - val_accuracy: 0.9161\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6323 - accuracy: 0.9968 - val_loss: 1.6694 - val_accuracy: 0.8839\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6069 - accuracy: 0.9984 - val_loss: 1.5789 - val_accuracy: 0.9032\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2284 - accuracy: 0.9032\n",
            "Test Loss: 1.2284492254257202, Test Accuracy: 0.9032257795333862\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 12s 87ms/step - loss: 50.5178 - accuracy: 0.5267 - val_loss: 49.4750 - val_accuracy: 0.6516\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 49.0874 - accuracy: 0.6801 - val_loss: 48.2356 - val_accuracy: 0.6516\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 47.6481 - accuracy: 0.7674 - val_loss: 46.9966 - val_accuracy: 0.6516\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 46.2389 - accuracy: 0.8546 - val_loss: 45.7783 - val_accuracy: 0.6516\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 44.8744 - accuracy: 0.9015 - val_loss: 44.6131 - val_accuracy: 0.6516\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 43.4978 - accuracy: 0.9370 - val_loss: 43.5084 - val_accuracy: 0.6516\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 42.0661 - accuracy: 0.9774 - val_loss: 42.3168 - val_accuracy: 0.6516\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 40.7487 - accuracy: 0.9774 - val_loss: 41.0864 - val_accuracy: 0.6516\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 39.3978 - accuracy: 0.9919 - val_loss: 39.9429 - val_accuracy: 0.6516\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 38.1026 - accuracy: 0.9855 - val_loss: 38.6181 - val_accuracy: 0.6516\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 36.7657 - accuracy: 0.9935 - val_loss: 37.5246 - val_accuracy: 0.6516\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 35.4719 - accuracy: 0.9935 - val_loss: 36.2673 - val_accuracy: 0.6516\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 34.1906 - accuracy: 0.9968 - val_loss: 34.9975 - val_accuracy: 0.6516\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 32.9568 - accuracy: 0.9871 - val_loss: 33.8368 - val_accuracy: 0.6516\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 31.7124 - accuracy: 0.9919 - val_loss: 32.5916 - val_accuracy: 0.6516\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 30.5201 - accuracy: 0.9935 - val_loss: 31.6882 - val_accuracy: 0.6516\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 29.3337 - accuracy: 0.9984 - val_loss: 30.4251 - val_accuracy: 0.6516\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 28.1967 - accuracy: 0.9919 - val_loss: 29.1670 - val_accuracy: 0.6516\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 27.0745 - accuracy: 1.0000 - val_loss: 27.8300 - val_accuracy: 0.6516\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 25.9951 - accuracy: 0.9984 - val_loss: 26.8416 - val_accuracy: 0.6516\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 24.9467 - accuracy: 0.9984 - val_loss: 25.8945 - val_accuracy: 0.6516\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 23.9242 - accuracy: 0.9968 - val_loss: 24.6000 - val_accuracy: 0.6903\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 22.9742 - accuracy: 0.9919 - val_loss: 23.7400 - val_accuracy: 0.6903\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 22.0127 - accuracy: 0.9919 - val_loss: 23.0436 - val_accuracy: 0.6645\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 21.1122 - accuracy: 0.9919 - val_loss: 21.6354 - val_accuracy: 0.7161\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 20.2646 - accuracy: 0.9838 - val_loss: 20.7890 - val_accuracy: 0.7355\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 19.3998 - accuracy: 0.9935 - val_loss: 20.0491 - val_accuracy: 0.7355\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 18.6137 - accuracy: 0.9935 - val_loss: 18.9590 - val_accuracy: 0.7742\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 17.8497 - accuracy: 0.9935 - val_loss: 18.0847 - val_accuracy: 0.7806\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 17.1055 - accuracy: 0.9935 - val_loss: 17.9739 - val_accuracy: 0.7032\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 16.4177 - accuracy: 0.9887 - val_loss: 17.0322 - val_accuracy: 0.7484\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 15.7435 - accuracy: 0.9935 - val_loss: 16.0570 - val_accuracy: 0.8000\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 15.0991 - accuracy: 0.9952 - val_loss: 15.3774 - val_accuracy: 0.8258\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 14.4829 - accuracy: 0.9903 - val_loss: 14.7734 - val_accuracy: 0.8387\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 13.8998 - accuracy: 0.9919 - val_loss: 14.2467 - val_accuracy: 0.8065\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.3423 - accuracy: 0.9887 - val_loss: 13.5292 - val_accuracy: 0.8581\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 12.7976 - accuracy: 0.9935 - val_loss: 13.2640 - val_accuracy: 0.8323\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 12.3567 - accuracy: 0.9838 - val_loss: 12.6909 - val_accuracy: 0.8516\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 11.8170 - accuracy: 0.9871 - val_loss: 12.0670 - val_accuracy: 0.8452\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 11.3748 - accuracy: 0.9855 - val_loss: 11.7425 - val_accuracy: 0.8258\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 10.9282 - accuracy: 0.9903 - val_loss: 11.3919 - val_accuracy: 0.8065\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.4928 - accuracy: 0.9952 - val_loss: 10.8864 - val_accuracy: 0.8581\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.0813 - accuracy: 0.9952 - val_loss: 10.4832 - val_accuracy: 0.8774\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.6895 - accuracy: 0.9935 - val_loss: 10.1684 - val_accuracy: 0.8839\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 9.3087 - accuracy: 0.9984 - val_loss: 9.7718 - val_accuracy: 0.8645\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.9369 - accuracy: 0.9968 - val_loss: 9.3889 - val_accuracy: 0.8516\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 8.5795 - accuracy: 1.0000 - val_loss: 9.0483 - val_accuracy: 0.8452\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.2475 - accuracy: 0.9968 - val_loss: 8.7237 - val_accuracy: 0.8710\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.9217 - accuracy: 0.9968 - val_loss: 8.5012 - val_accuracy: 0.8581\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.6210 - accuracy: 0.9935 - val_loss: 8.1792 - val_accuracy: 0.8323\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.3042 - accuracy: 1.0000 - val_loss: 7.9053 - val_accuracy: 0.8452\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.0549 - accuracy: 0.9887 - val_loss: 7.6469 - val_accuracy: 0.8581\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.7905 - accuracy: 0.9968 - val_loss: 7.5811 - val_accuracy: 0.8258\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.5180 - accuracy: 0.9984 - val_loss: 7.2815 - val_accuracy: 0.8452\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.2732 - accuracy: 0.9984 - val_loss: 7.0835 - val_accuracy: 0.8258\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 6.0439 - accuracy: 0.9935 - val_loss: 7.0030 - val_accuracy: 0.8323\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 5.8623 - accuracy: 0.9855 - val_loss: 6.7261 - val_accuracy: 0.8516\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.6512 - accuracy: 0.9919 - val_loss: 6.6766 - val_accuracy: 0.8194\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.4724 - accuracy: 0.9790 - val_loss: 6.1441 - val_accuracy: 0.8645\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.3136 - accuracy: 0.9855 - val_loss: 5.9809 - val_accuracy: 0.8903\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 5.1086 - accuracy: 0.9855 - val_loss: 5.9818 - val_accuracy: 0.8581\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 5.0248 - accuracy: 0.9709 - val_loss: 5.9710 - val_accuracy: 0.8645\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.8350 - accuracy: 0.9693 - val_loss: 5.6596 - val_accuracy: 0.8645\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.5990 - accuracy: 0.9919 - val_loss: 5.5741 - val_accuracy: 0.9032\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.5584 - accuracy: 0.9693 - val_loss: 5.2500 - val_accuracy: 0.8645\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 4.3339 - accuracy: 0.9855 - val_loss: 5.7054 - val_accuracy: 0.8516\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.1912 - accuracy: 0.9822 - val_loss: 5.5175 - val_accuracy: 0.8903\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.0078 - accuracy: 0.9968 - val_loss: 4.9112 - val_accuracy: 0.8968\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.8700 - accuracy: 0.9984 - val_loss: 4.6759 - val_accuracy: 0.8968\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.7352 - accuracy: 0.9984 - val_loss: 4.4700 - val_accuracy: 0.8968\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.5989 - accuracy: 1.0000 - val_loss: 4.2839 - val_accuracy: 0.9032\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.4691 - accuracy: 1.0000 - val_loss: 4.0959 - val_accuracy: 0.9097\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.3448 - accuracy: 1.0000 - val_loss: 3.9373 - val_accuracy: 0.9032\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.2247 - accuracy: 1.0000 - val_loss: 3.7910 - val_accuracy: 0.8903\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.1128 - accuracy: 0.9968 - val_loss: 3.6128 - val_accuracy: 0.9032\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.9996 - accuracy: 1.0000 - val_loss: 3.4897 - val_accuracy: 0.8774\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.8945 - accuracy: 0.9984 - val_loss: 3.3806 - val_accuracy: 0.8774\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.7889 - accuracy: 1.0000 - val_loss: 3.3644 - val_accuracy: 0.8839\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.6908 - accuracy: 0.9984 - val_loss: 3.2373 - val_accuracy: 0.8903\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.6024 - accuracy: 0.9984 - val_loss: 3.1799 - val_accuracy: 0.8645\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.5117 - accuracy: 1.0000 - val_loss: 3.0513 - val_accuracy: 0.8774\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.4335 - accuracy: 0.9984 - val_loss: 2.9912 - val_accuracy: 0.8903\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.3446 - accuracy: 1.0000 - val_loss: 2.9634 - val_accuracy: 0.8710\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.2632 - accuracy: 1.0000 - val_loss: 2.9085 - val_accuracy: 0.8710\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 2.1827 - accuracy: 1.0000 - val_loss: 2.7502 - val_accuracy: 0.8968\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.1050 - accuracy: 1.0000 - val_loss: 2.6617 - val_accuracy: 0.9032\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.0601 - accuracy: 0.9919 - val_loss: 2.6096 - val_accuracy: 0.8968\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.9704 - accuracy: 0.9984 - val_loss: 2.5909 - val_accuracy: 0.8774\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.9166 - accuracy: 0.9952 - val_loss: 2.7411 - val_accuracy: 0.8452\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.8644 - accuracy: 0.9968 - val_loss: 2.5856 - val_accuracy: 0.8903\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.8293 - accuracy: 0.9903 - val_loss: 2.2459 - val_accuracy: 0.9097\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.7455 - accuracy: 0.9968 - val_loss: 2.6680 - val_accuracy: 0.8710\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.6893 - accuracy: 0.9984 - val_loss: 2.6793 - val_accuracy: 0.8839\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.6328 - accuracy: 0.9984 - val_loss: 2.5673 - val_accuracy: 0.8968\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.5812 - accuracy: 0.9984 - val_loss: 2.5228 - val_accuracy: 0.8839\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.5577 - accuracy: 0.9952 - val_loss: 2.7645 - val_accuracy: 0.8581\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.5037 - accuracy: 0.9952 - val_loss: 2.5090 - val_accuracy: 0.8452\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.4304 - accuracy: 1.0000 - val_loss: 2.6885 - val_accuracy: 0.8452\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.3871 - accuracy: 1.0000 - val_loss: 2.5372 - val_accuracy: 0.8581\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.3431 - accuracy: 1.0000 - val_loss: 2.3072 - val_accuracy: 0.8452\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.2967 - accuracy: 1.0000 - val_loss: 2.2404 - val_accuracy: 0.8710\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.2501 - accuracy: 1.0000 - val_loss: 2.2164 - val_accuracy: 0.8645\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.2116 - accuracy: 0.9984 - val_loss: 2.0709 - val_accuracy: 0.8645\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.1979 - accuracy: 0.9919 - val_loss: 1.9400 - val_accuracy: 0.8903\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 1.1707 - accuracy: 0.9903 - val_loss: 1.8990 - val_accuracy: 0.8774\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.1183 - accuracy: 0.9952 - val_loss: 2.1790 - val_accuracy: 0.8323\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0705 - accuracy: 0.9968 - val_loss: 2.0552 - val_accuracy: 0.8839\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.1543 - accuracy: 0.9742 - val_loss: 2.3379 - val_accuracy: 0.8516\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0589 - accuracy: 0.9871 - val_loss: 2.0406 - val_accuracy: 0.8710\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0329 - accuracy: 0.9871 - val_loss: 2.2156 - val_accuracy: 0.8516\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.9965 - accuracy: 0.9935 - val_loss: 1.7679 - val_accuracy: 0.9161\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.9713 - accuracy: 0.9952 - val_loss: 1.8228 - val_accuracy: 0.9032\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.9338 - accuracy: 0.9984 - val_loss: 2.3397 - val_accuracy: 0.8774\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.9038 - accuracy: 0.9952 - val_loss: 2.1178 - val_accuracy: 0.8774\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.8953 - accuracy: 0.9935 - val_loss: 1.7587 - val_accuracy: 0.8774\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.8523 - accuracy: 0.9919 - val_loss: 1.7644 - val_accuracy: 0.8903\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.8024 - accuracy: 1.0000 - val_loss: 1.9075 - val_accuracy: 0.8839\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.7935 - accuracy: 0.9968 - val_loss: 1.6828 - val_accuracy: 0.8903\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.7502 - accuracy: 0.9984 - val_loss: 1.7399 - val_accuracy: 0.8581\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.7425 - accuracy: 0.9968 - val_loss: 1.6566 - val_accuracy: 0.8581\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6993 - accuracy: 0.9968 - val_loss: 1.7029 - val_accuracy: 0.8581\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6775 - accuracy: 0.9968 - val_loss: 1.7708 - val_accuracy: 0.8258\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6586 - accuracy: 0.9968 - val_loss: 1.6614 - val_accuracy: 0.8516\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6291 - accuracy: 0.9984 - val_loss: 1.5048 - val_accuracy: 0.8839\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6065 - accuracy: 1.0000 - val_loss: 1.4124 - val_accuracy: 0.9032\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6129 - accuracy: 0.9935 - val_loss: 1.4164 - val_accuracy: 0.8516\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5821 - accuracy: 0.9952 - val_loss: 1.2884 - val_accuracy: 0.8968\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5595 - accuracy: 0.9968 - val_loss: 1.2671 - val_accuracy: 0.9097\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5344 - accuracy: 0.9968 - val_loss: 1.2991 - val_accuracy: 0.8903\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5218 - accuracy: 0.9984 - val_loss: 1.2910 - val_accuracy: 0.8903\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5103 - accuracy: 0.9984 - val_loss: 1.2691 - val_accuracy: 0.8839\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4790 - accuracy: 1.0000 - val_loss: 1.1775 - val_accuracy: 0.8710\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4611 - accuracy: 1.0000 - val_loss: 1.1628 - val_accuracy: 0.8774\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4448 - accuracy: 1.0000 - val_loss: 1.0940 - val_accuracy: 0.8903\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4271 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 0.8968\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4132 - accuracy: 1.0000 - val_loss: 1.0601 - val_accuracy: 0.8968\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3963 - accuracy: 1.0000 - val_loss: 1.1535 - val_accuracy: 0.8839\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3965 - accuracy: 0.9968 - val_loss: 1.0818 - val_accuracy: 0.9097\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3801 - accuracy: 0.9968 - val_loss: 1.0999 - val_accuracy: 0.8903\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3788 - accuracy: 0.9984 - val_loss: 1.0995 - val_accuracy: 0.8839\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3674 - accuracy: 0.9984 - val_loss: 1.2162 - val_accuracy: 0.8774\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3797 - accuracy: 0.9968 - val_loss: 1.1288 - val_accuracy: 0.8968\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3500 - accuracy: 1.0000 - val_loss: 1.2006 - val_accuracy: 0.8903\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3476 - accuracy: 0.9984 - val_loss: 1.0737 - val_accuracy: 0.9097\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.3251 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.9032\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3143 - accuracy: 0.9984 - val_loss: 1.0897 - val_accuracy: 0.8903\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3399 - accuracy: 0.9935 - val_loss: 1.8842 - val_accuracy: 0.8000\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3448 - accuracy: 0.9855 - val_loss: 1.1641 - val_accuracy: 0.8645\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3559 - accuracy: 0.9822 - val_loss: 1.2457 - val_accuracy: 0.8516\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2956 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.8903\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3016 - accuracy: 0.9952 - val_loss: 1.2849 - val_accuracy: 0.8903\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3023 - accuracy: 0.9952 - val_loss: 1.3110 - val_accuracy: 0.9032\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2762 - accuracy: 0.9984 - val_loss: 1.3038 - val_accuracy: 0.8903\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2665 - accuracy: 0.9984 - val_loss: 1.4635 - val_accuracy: 0.8710\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.2678 - accuracy: 0.9968 - val_loss: 1.3862 - val_accuracy: 0.8839\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0324 - accuracy: 0.9032\n",
            "Test Loss: 1.0323978662490845, Test Accuracy: 0.9032257795333862\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 9s 85ms/step - loss: 50.4799 - accuracy: 0.5735 - val_loss: 49.4572 - val_accuracy: 0.6968\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 49.0937 - accuracy: 0.6656 - val_loss: 48.2117 - val_accuracy: 0.6968\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 47.7229 - accuracy: 0.7787 - val_loss: 46.9880 - val_accuracy: 0.6968\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 46.2623 - accuracy: 0.8546 - val_loss: 45.7425 - val_accuracy: 0.6968\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 44.8405 - accuracy: 0.9273 - val_loss: 44.5169 - val_accuracy: 0.6968\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 43.5275 - accuracy: 0.9435 - val_loss: 43.2878 - val_accuracy: 0.6968\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 42.1406 - accuracy: 0.9742 - val_loss: 42.1134 - val_accuracy: 0.6968\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 40.7948 - accuracy: 0.9887 - val_loss: 40.9404 - val_accuracy: 0.6968\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 39.4739 - accuracy: 0.9871 - val_loss: 39.7879 - val_accuracy: 0.6968\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 38.1714 - accuracy: 0.9919 - val_loss: 38.4614 - val_accuracy: 0.6968\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 36.8708 - accuracy: 0.9871 - val_loss: 37.3308 - val_accuracy: 0.6968\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 35.5705 - accuracy: 0.9984 - val_loss: 36.0748 - val_accuracy: 0.6968\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 34.3042 - accuracy: 0.9968 - val_loss: 34.7556 - val_accuracy: 0.6968\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 33.0560 - accuracy: 0.9968 - val_loss: 33.5924 - val_accuracy: 0.6968\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 31.8299 - accuracy: 0.9984 - val_loss: 32.4651 - val_accuracy: 0.6968\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 30.6271 - accuracy: 0.9968 - val_loss: 31.2117 - val_accuracy: 0.6968\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 29.4538 - accuracy: 0.9984 - val_loss: 29.9431 - val_accuracy: 0.6968\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 28.3164 - accuracy: 0.9968 - val_loss: 28.7696 - val_accuracy: 0.6968\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 27.2141 - accuracy: 0.9984 - val_loss: 27.5454 - val_accuracy: 0.6968\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 26.1561 - accuracy: 0.9919 - val_loss: 26.4321 - val_accuracy: 0.6968\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 25.0977 - accuracy: 0.9952 - val_loss: 25.2509 - val_accuracy: 0.7097\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 24.1175 - accuracy: 0.9871 - val_loss: 24.1664 - val_accuracy: 0.7613\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 23.1641 - accuracy: 0.9855 - val_loss: 23.0525 - val_accuracy: 0.8258\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 22.2076 - accuracy: 0.9935 - val_loss: 22.3250 - val_accuracy: 0.7806\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 21.3478 - accuracy: 0.9887 - val_loss: 21.3545 - val_accuracy: 0.8129\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 20.4553 - accuracy: 0.9935 - val_loss: 20.4671 - val_accuracy: 0.8000\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 19.6390 - accuracy: 0.9855 - val_loss: 19.6163 - val_accuracy: 0.8258\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 18.8291 - accuracy: 0.9919 - val_loss: 18.7868 - val_accuracy: 0.8516\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 18.0889 - accuracy: 0.9871 - val_loss: 17.9845 - val_accuracy: 0.8903\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 17.4177 - accuracy: 0.9758 - val_loss: 17.3443 - val_accuracy: 0.8839\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 16.6721 - accuracy: 0.9887 - val_loss: 16.5736 - val_accuracy: 0.9097\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 16.0238 - accuracy: 0.9871 - val_loss: 16.0292 - val_accuracy: 0.9032\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 15.3844 - accuracy: 0.9903 - val_loss: 15.3936 - val_accuracy: 0.9097\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 14.7881 - accuracy: 0.9935 - val_loss: 14.8220 - val_accuracy: 0.8968\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 14.2329 - accuracy: 0.9903 - val_loss: 14.4810 - val_accuracy: 0.8774\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.6966 - accuracy: 0.9887 - val_loss: 13.7902 - val_accuracy: 0.8968\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.1407 - accuracy: 0.9919 - val_loss: 13.5024 - val_accuracy: 0.8839\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 12.6989 - accuracy: 0.9790 - val_loss: 12.7991 - val_accuracy: 0.8968\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 12.1853 - accuracy: 0.9903 - val_loss: 12.3451 - val_accuracy: 0.8645\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 11.7344 - accuracy: 0.9822 - val_loss: 11.8111 - val_accuracy: 0.9032\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 11.2664 - accuracy: 0.9935 - val_loss: 11.4169 - val_accuracy: 0.8774\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 10.8445 - accuracy: 0.9935 - val_loss: 10.9972 - val_accuracy: 0.8710\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 10.4095 - accuracy: 1.0000 - val_loss: 10.7763 - val_accuracy: 0.8903\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 10.0139 - accuracy: 1.0000 - val_loss: 10.3768 - val_accuracy: 0.8903\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 9.6544 - accuracy: 0.9935 - val_loss: 9.8928 - val_accuracy: 0.9097\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 9.3344 - accuracy: 0.9871 - val_loss: 9.4022 - val_accuracy: 0.9097\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 9.0224 - accuracy: 0.9871 - val_loss: 9.1098 - val_accuracy: 0.9226\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 8.6960 - accuracy: 0.9790 - val_loss: 8.7151 - val_accuracy: 0.9161\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.3618 - accuracy: 0.9919 - val_loss: 8.9697 - val_accuracy: 0.8581\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.0804 - accuracy: 0.9887 - val_loss: 8.5593 - val_accuracy: 0.8710\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.7833 - accuracy: 0.9903 - val_loss: 8.0501 - val_accuracy: 0.8710\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.4980 - accuracy: 0.9935 - val_loss: 8.8413 - val_accuracy: 0.8452\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.2669 - accuracy: 0.9935 - val_loss: 7.6717 - val_accuracy: 0.9161\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.0278 - accuracy: 0.9952 - val_loss: 7.4768 - val_accuracy: 0.9290\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.7490 - accuracy: 0.9935 - val_loss: 6.9692 - val_accuracy: 0.9097\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.5087 - accuracy: 0.9984 - val_loss: 6.9043 - val_accuracy: 0.9161\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.3141 - accuracy: 0.9935 - val_loss: 6.7069 - val_accuracy: 0.9097\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.0934 - accuracy: 0.9935 - val_loss: 6.5240 - val_accuracy: 0.8710\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.9162 - accuracy: 0.9838 - val_loss: 6.3218 - val_accuracy: 0.8774\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.6800 - accuracy: 0.9919 - val_loss: 6.1364 - val_accuracy: 0.8710\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.4889 - accuracy: 0.9903 - val_loss: 6.0922 - val_accuracy: 0.8839\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 5.3045 - accuracy: 0.9935 - val_loss: 5.7996 - val_accuracy: 0.8839\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.1158 - accuracy: 0.9952 - val_loss: 5.6918 - val_accuracy: 0.8774\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.9782 - accuracy: 0.9838 - val_loss: 5.5494 - val_accuracy: 0.8903\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.7872 - accuracy: 0.9968 - val_loss: 5.3864 - val_accuracy: 0.8839\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 4.6320 - accuracy: 0.9903 - val_loss: 5.2240 - val_accuracy: 0.8645\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.4651 - accuracy: 0.9935 - val_loss: 4.9931 - val_accuracy: 0.8839\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.3196 - accuracy: 0.9919 - val_loss: 4.8062 - val_accuracy: 0.8968\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.1961 - accuracy: 0.9903 - val_loss: 4.5744 - val_accuracy: 0.9097\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 4.0568 - accuracy: 0.9903 - val_loss: 4.7766 - val_accuracy: 0.8774\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.8984 - accuracy: 0.9968 - val_loss: 4.5280 - val_accuracy: 0.8387\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.7994 - accuracy: 0.9887 - val_loss: 4.2805 - val_accuracy: 0.8903\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.6616 - accuracy: 0.9903 - val_loss: 4.0989 - val_accuracy: 0.9161\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.5299 - accuracy: 0.9968 - val_loss: 4.0862 - val_accuracy: 0.9032\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.4060 - accuracy: 0.9984 - val_loss: 3.8526 - val_accuracy: 0.9032\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.3163 - accuracy: 0.9887 - val_loss: 3.6498 - val_accuracy: 0.9161\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.1946 - accuracy: 0.9919 - val_loss: 3.6006 - val_accuracy: 0.9032\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.0908 - accuracy: 0.9952 - val_loss: 3.6002 - val_accuracy: 0.9161\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.9765 - accuracy: 1.0000 - val_loss: 3.5698 - val_accuracy: 0.9032\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.8810 - accuracy: 0.9968 - val_loss: 3.4751 - val_accuracy: 0.9161\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.7825 - accuracy: 0.9984 - val_loss: 3.4195 - val_accuracy: 0.8968\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.7115 - accuracy: 0.9919 - val_loss: 3.2743 - val_accuracy: 0.9097\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.6216 - accuracy: 0.9952 - val_loss: 3.3311 - val_accuracy: 0.8839\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.5368 - accuracy: 0.9935 - val_loss: 3.5265 - val_accuracy: 0.8839\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.5072 - accuracy: 0.9919 - val_loss: 3.2195 - val_accuracy: 0.8968\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.4161 - accuracy: 0.9871 - val_loss: 2.9210 - val_accuracy: 0.9032\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.3404 - accuracy: 0.9952 - val_loss: 2.9129 - val_accuracy: 0.9161\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.2636 - accuracy: 0.9935 - val_loss: 2.9536 - val_accuracy: 0.8968\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.2142 - accuracy: 0.9919 - val_loss: 2.9056 - val_accuracy: 0.9161\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.1232 - accuracy: 0.9968 - val_loss: 2.9078 - val_accuracy: 0.9097\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.0675 - accuracy: 0.9952 - val_loss: 2.6884 - val_accuracy: 0.9290\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.9786 - accuracy: 0.9984 - val_loss: 2.5492 - val_accuracy: 0.9161\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.9235 - accuracy: 0.9968 - val_loss: 2.4413 - val_accuracy: 0.9097\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.8577 - accuracy: 0.9968 - val_loss: 2.3762 - val_accuracy: 0.9032\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.8101 - accuracy: 0.9935 - val_loss: 2.6401 - val_accuracy: 0.8968\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7562 - accuracy: 0.9952 - val_loss: 2.7260 - val_accuracy: 0.9097\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.7060 - accuracy: 0.9935 - val_loss: 2.5828 - val_accuracy: 0.9226\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.6497 - accuracy: 0.9952 - val_loss: 2.4190 - val_accuracy: 0.9419\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.5990 - accuracy: 0.9984 - val_loss: 2.4262 - val_accuracy: 0.9226\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.5642 - accuracy: 0.9952 - val_loss: 2.1289 - val_accuracy: 0.9290\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.5304 - accuracy: 0.9935 - val_loss: 2.3040 - val_accuracy: 0.8774\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.5019 - accuracy: 0.9855 - val_loss: 2.0957 - val_accuracy: 0.9226\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.4142 - accuracy: 0.9968 - val_loss: 2.1668 - val_accuracy: 0.9097\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.3734 - accuracy: 0.9968 - val_loss: 2.4129 - val_accuracy: 0.8774\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.3280 - accuracy: 0.9968 - val_loss: 2.5470 - val_accuracy: 0.8645\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.2949 - accuracy: 0.9952 - val_loss: 2.0513 - val_accuracy: 0.8839\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.2353 - accuracy: 1.0000 - val_loss: 1.9400 - val_accuracy: 0.8839\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.1946 - accuracy: 1.0000 - val_loss: 1.8740 - val_accuracy: 0.8839\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.1542 - accuracy: 1.0000 - val_loss: 1.7936 - val_accuracy: 0.8839\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.1146 - accuracy: 1.0000 - val_loss: 1.7135 - val_accuracy: 0.8839\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.0767 - accuracy: 1.0000 - val_loss: 1.6541 - val_accuracy: 0.8839\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.0508 - accuracy: 0.9984 - val_loss: 1.6385 - val_accuracy: 0.8903\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.0379 - accuracy: 0.9887 - val_loss: 1.5641 - val_accuracy: 0.8968\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.9957 - accuracy: 0.9968 - val_loss: 1.8367 - val_accuracy: 0.8903\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.0171 - accuracy: 0.9871 - val_loss: 1.4121 - val_accuracy: 0.9161\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.9626 - accuracy: 0.9887 - val_loss: 1.2284 - val_accuracy: 0.9161\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.9181 - accuracy: 0.9984 - val_loss: 1.3477 - val_accuracy: 0.9161\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.8892 - accuracy: 1.0000 - val_loss: 1.3834 - val_accuracy: 0.9097\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.8595 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.9032\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.8303 - accuracy: 1.0000 - val_loss: 1.2848 - val_accuracy: 0.9032\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.8007 - accuracy: 1.0000 - val_loss: 1.2335 - val_accuracy: 0.9226\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.7836 - accuracy: 0.9968 - val_loss: 1.1669 - val_accuracy: 0.9355\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.7890 - accuracy: 0.9935 - val_loss: 1.1336 - val_accuracy: 0.9161\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7389 - accuracy: 0.9952 - val_loss: 1.4173 - val_accuracy: 0.8774\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7237 - accuracy: 0.9952 - val_loss: 1.8340 - val_accuracy: 0.8774\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7106 - accuracy: 0.9935 - val_loss: 1.6241 - val_accuracy: 0.8968\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6905 - accuracy: 0.9952 - val_loss: 1.3214 - val_accuracy: 0.9226\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6584 - accuracy: 0.9968 - val_loss: 1.5555 - val_accuracy: 0.9161\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6720 - accuracy: 0.9903 - val_loss: 1.2911 - val_accuracy: 0.8968\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6456 - accuracy: 0.9952 - val_loss: 1.1863 - val_accuracy: 0.9161\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6416 - accuracy: 0.9887 - val_loss: 1.3454 - val_accuracy: 0.8839\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6193 - accuracy: 0.9887 - val_loss: 1.2038 - val_accuracy: 0.9032\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6250 - accuracy: 0.9887 - val_loss: 1.6589 - val_accuracy: 0.8516\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1336 - accuracy: 0.9161\n",
            "Test Loss: 1.1335668563842773, Test Accuracy: 0.9161290526390076\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 9s 86ms/step - loss: 50.4559 - accuracy: 0.5484 - val_loss: 49.4221 - val_accuracy: 0.7273\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 49.0282 - accuracy: 0.6871 - val_loss: 48.1543 - val_accuracy: 0.7273\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 47.5851 - accuracy: 0.7968 - val_loss: 46.8861 - val_accuracy: 0.7273\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 46.2086 - accuracy: 0.8452 - val_loss: 45.6465 - val_accuracy: 0.7273\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 44.7660 - accuracy: 0.9161 - val_loss: 44.4313 - val_accuracy: 0.7273\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 43.4023 - accuracy: 0.9452 - val_loss: 43.2672 - val_accuracy: 0.7273\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 42.0138 - accuracy: 0.9758 - val_loss: 42.1185 - val_accuracy: 0.7273\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 40.6780 - accuracy: 0.9855 - val_loss: 40.9296 - val_accuracy: 0.7273\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 39.3382 - accuracy: 0.9935 - val_loss: 39.7016 - val_accuracy: 0.7273\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 38.0567 - accuracy: 0.9855 - val_loss: 38.4061 - val_accuracy: 0.7273\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 36.7436 - accuracy: 0.9871 - val_loss: 37.2872 - val_accuracy: 0.7273\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 35.4649 - accuracy: 0.9855 - val_loss: 36.0826 - val_accuracy: 0.7273\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 34.2073 - accuracy: 0.9919 - val_loss: 34.8601 - val_accuracy: 0.7273\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 32.9605 - accuracy: 0.9968 - val_loss: 33.7418 - val_accuracy: 0.7273\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 31.7520 - accuracy: 0.9952 - val_loss: 32.5498 - val_accuracy: 0.7273\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 30.5674 - accuracy: 0.9952 - val_loss: 31.4193 - val_accuracy: 0.7273\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 29.4007 - accuracy: 0.9968 - val_loss: 30.2685 - val_accuracy: 0.7273\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 28.2757 - accuracy: 0.9968 - val_loss: 29.1972 - val_accuracy: 0.7273\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 27.1761 - accuracy: 0.9952 - val_loss: 28.1543 - val_accuracy: 0.7273\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 26.1026 - accuracy: 0.9984 - val_loss: 27.1492 - val_accuracy: 0.7273\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 25.0734 - accuracy: 0.9984 - val_loss: 25.9671 - val_accuracy: 0.7273\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 24.0628 - accuracy: 1.0000 - val_loss: 24.9468 - val_accuracy: 0.7273\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 23.0963 - accuracy: 0.9984 - val_loss: 23.9994 - val_accuracy: 0.7273\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 22.1551 - accuracy: 0.9968 - val_loss: 23.0094 - val_accuracy: 0.7273\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 21.2457 - accuracy: 1.0000 - val_loss: 22.1848 - val_accuracy: 0.7338\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 20.3731 - accuracy: 1.0000 - val_loss: 20.9280 - val_accuracy: 0.7468\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 19.5505 - accuracy: 0.9952 - val_loss: 20.0706 - val_accuracy: 0.7468\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 18.7663 - accuracy: 0.9903 - val_loss: 19.0863 - val_accuracy: 0.7987\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 18.0103 - accuracy: 0.9855 - val_loss: 18.7275 - val_accuracy: 0.7727\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 17.2997 - accuracy: 0.9823 - val_loss: 17.2856 - val_accuracy: 0.8506\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 16.5967 - accuracy: 0.9839 - val_loss: 16.5319 - val_accuracy: 0.8961\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 15.9336 - accuracy: 0.9919 - val_loss: 16.0574 - val_accuracy: 0.8636\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 15.3203 - accuracy: 0.9806 - val_loss: 15.2494 - val_accuracy: 0.8831\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 14.7179 - accuracy: 0.9855 - val_loss: 14.7320 - val_accuracy: 0.8831\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 14.1134 - accuracy: 0.9919 - val_loss: 14.1225 - val_accuracy: 0.8896\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 13.5626 - accuracy: 0.9887 - val_loss: 13.6452 - val_accuracy: 0.8961\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 13.0084 - accuracy: 1.0000 - val_loss: 13.1398 - val_accuracy: 0.8766\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 12.5064 - accuracy: 0.9952 - val_loss: 12.5528 - val_accuracy: 0.9091\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 12.0435 - accuracy: 0.9887 - val_loss: 12.0913 - val_accuracy: 0.8961\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 11.5402 - accuracy: 0.9919 - val_loss: 11.7567 - val_accuracy: 0.8896\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 11.1095 - accuracy: 0.9855 - val_loss: 11.0702 - val_accuracy: 0.9286\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 10.6850 - accuracy: 0.9887 - val_loss: 10.7082 - val_accuracy: 0.9286\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 10.2529 - accuracy: 0.9935 - val_loss: 10.3693 - val_accuracy: 0.9286\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 9.8986 - accuracy: 0.9871 - val_loss: 9.9599 - val_accuracy: 0.9026\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 9.5189 - accuracy: 0.9903 - val_loss: 9.5576 - val_accuracy: 0.9026\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 9.2092 - accuracy: 0.9758 - val_loss: 9.5012 - val_accuracy: 0.8636\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.9500 - accuracy: 0.9645 - val_loss: 9.1240 - val_accuracy: 0.8701\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.5769 - accuracy: 0.9742 - val_loss: 8.6177 - val_accuracy: 0.9026\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.2469 - accuracy: 0.9774 - val_loss: 8.6331 - val_accuracy: 0.8506\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.0871 - accuracy: 0.9597 - val_loss: 8.1694 - val_accuracy: 0.8896\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.6852 - accuracy: 0.9855 - val_loss: 7.9606 - val_accuracy: 0.9026\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.4577 - accuracy: 0.9839 - val_loss: 7.6178 - val_accuracy: 0.9221\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.2193 - accuracy: 0.9742 - val_loss: 7.5743 - val_accuracy: 0.8766\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.9379 - accuracy: 0.9903 - val_loss: 7.3730 - val_accuracy: 0.9091\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.6924 - accuracy: 0.9919 - val_loss: 7.2368 - val_accuracy: 0.8571\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.4610 - accuracy: 0.9919 - val_loss: 6.7114 - val_accuracy: 0.9156\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.3053 - accuracy: 0.9710 - val_loss: 6.4368 - val_accuracy: 0.9221\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 6.0267 - accuracy: 0.9903 - val_loss: 6.1617 - val_accuracy: 0.8896\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.8455 - accuracy: 0.9887 - val_loss: 6.3789 - val_accuracy: 0.8961\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 5.6258 - accuracy: 0.9952 - val_loss: 6.1153 - val_accuracy: 0.8636\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.4130 - accuracy: 1.0000 - val_loss: 5.9068 - val_accuracy: 0.8831\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 5.2320 - accuracy: 0.9984 - val_loss: 5.4901 - val_accuracy: 0.9156\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 5.0502 - accuracy: 0.9968 - val_loss: 5.2852 - val_accuracy: 0.9351\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.8639 - accuracy: 1.0000 - val_loss: 5.1078 - val_accuracy: 0.9351\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.6933 - accuracy: 1.0000 - val_loss: 4.9393 - val_accuracy: 0.9286\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.5281 - accuracy: 1.0000 - val_loss: 4.8071 - val_accuracy: 0.9221\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.3673 - accuracy: 1.0000 - val_loss: 4.6604 - val_accuracy: 0.9221\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.2129 - accuracy: 1.0000 - val_loss: 4.5076 - val_accuracy: 0.9221\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.0647 - accuracy: 1.0000 - val_loss: 4.3439 - val_accuracy: 0.9286\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.9200 - accuracy: 1.0000 - val_loss: 4.1972 - val_accuracy: 0.9286\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.7989 - accuracy: 0.9952 - val_loss: 4.0201 - val_accuracy: 0.9221\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.6486 - accuracy: 1.0000 - val_loss: 3.8385 - val_accuracy: 0.9286\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.5481 - accuracy: 0.9952 - val_loss: 3.9150 - val_accuracy: 0.8961\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.4403 - accuracy: 0.9919 - val_loss: 3.6674 - val_accuracy: 0.9091\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.3237 - accuracy: 0.9903 - val_loss: 3.6530 - val_accuracy: 0.9156\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.2084 - accuracy: 0.9952 - val_loss: 3.7936 - val_accuracy: 0.9091\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.1179 - accuracy: 0.9919 - val_loss: 3.4706 - val_accuracy: 0.9286\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.9973 - accuracy: 1.0000 - val_loss: 3.3051 - val_accuracy: 0.9286\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.9197 - accuracy: 0.9984 - val_loss: 3.3545 - val_accuracy: 0.9286\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.8201 - accuracy: 0.9968 - val_loss: 3.2475 - val_accuracy: 0.9286\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.7134 - accuracy: 1.0000 - val_loss: 3.1289 - val_accuracy: 0.9221\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.6239 - accuracy: 1.0000 - val_loss: 3.0248 - val_accuracy: 0.9286\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.5846 - accuracy: 0.9903 - val_loss: 3.0068 - val_accuracy: 0.9156\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.4752 - accuracy: 0.9935 - val_loss: 3.1034 - val_accuracy: 0.8896\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 2.3863 - accuracy: 0.9968 - val_loss: 2.6040 - val_accuracy: 0.9351\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.3488 - accuracy: 0.9855 - val_loss: 2.7524 - val_accuracy: 0.9286\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2.2259 - accuracy: 0.9984 - val_loss: 2.8952 - val_accuracy: 0.9026\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 2.1816 - accuracy: 0.9839 - val_loss: 2.6749 - val_accuracy: 0.9156\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.0920 - accuracy: 0.9952 - val_loss: 2.8027 - val_accuracy: 0.9026\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.0363 - accuracy: 0.9903 - val_loss: 2.7367 - val_accuracy: 0.8766\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.9604 - accuracy: 0.9968 - val_loss: 2.6016 - val_accuracy: 0.8961\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.8969 - accuracy: 0.9968 - val_loss: 2.4844 - val_accuracy: 0.9091\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.8368 - accuracy: 0.9935 - val_loss: 2.4690 - val_accuracy: 0.9156\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.7739 - accuracy: 0.9968 - val_loss: 2.7803 - val_accuracy: 0.8701\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.7086 - accuracy: 0.9984 - val_loss: 2.3918 - val_accuracy: 0.9091\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 1.6524 - accuracy: 0.9968 - val_loss: 2.2125 - val_accuracy: 0.9416\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 1.6066 - accuracy: 0.9968 - val_loss: 2.1457 - val_accuracy: 0.9351\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.5365 - accuracy: 1.0000 - val_loss: 2.1515 - val_accuracy: 0.9026\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.4991 - accuracy: 0.9935 - val_loss: 1.8609 - val_accuracy: 0.9156\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.4354 - accuracy: 1.0000 - val_loss: 1.7121 - val_accuracy: 0.9286\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.4108 - accuracy: 0.9935 - val_loss: 1.6528 - val_accuracy: 0.9481\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 1.3956 - accuracy: 0.9935 - val_loss: 1.6480 - val_accuracy: 0.9416\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.3334 - accuracy: 0.9903 - val_loss: 1.7313 - val_accuracy: 0.9286\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.3191 - accuracy: 0.9887 - val_loss: 1.7477 - val_accuracy: 0.9221\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.2748 - accuracy: 0.9887 - val_loss: 1.7785 - val_accuracy: 0.9221\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.2344 - accuracy: 0.9952 - val_loss: 1.7675 - val_accuracy: 0.9091\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.2106 - accuracy: 0.9919 - val_loss: 1.9456 - val_accuracy: 0.9026\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.1758 - accuracy: 0.9919 - val_loss: 1.6712 - val_accuracy: 0.8961\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.1260 - accuracy: 0.9935 - val_loss: 1.6928 - val_accuracy: 0.9026\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1.0775 - accuracy: 0.9935 - val_loss: 1.9500 - val_accuracy: 0.8831\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.0412 - accuracy: 0.9968 - val_loss: 1.8128 - val_accuracy: 0.9026\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.9959 - accuracy: 1.0000 - val_loss: 1.8109 - val_accuracy: 0.8831\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6481 - accuracy: 0.9416\n",
            "Test Loss: 1.6480717658996582, Test Accuracy: 0.9415584206581116\n",
            "\n",
            "Average Accuracy Across All Folds: 0.90056973695755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdamW + Random 증강 + L2규제 + dropout 6개 + Early stopping + batch_noramalization : 0.8875827431678772"
      ],
      "metadata": {
        "id": "oqD1RCgAMBxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model_with_batch_norm():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model_with_early_stopping()\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KcQaY_6KN5w",
        "outputId": "97cfc5c6-231a-490e-d245-41264d33c7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 75ms/step - loss: 48.6173 - accuracy: 0.6801 - val_loss: 46.0445 - val_accuracy: 0.6323\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 44.0903 - accuracy: 0.6979 - val_loss: 41.6951 - val_accuracy: 0.6323\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 39.8947 - accuracy: 0.6979 - val_loss: 37.7161 - val_accuracy: 0.6323\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 36.0107 - accuracy: 0.6979 - val_loss: 33.9787 - val_accuracy: 0.6323\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 32.4451 - accuracy: 0.7060 - val_loss: 30.6279 - val_accuracy: 0.6516\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 29.1702 - accuracy: 0.7738 - val_loss: 27.5583 - val_accuracy: 0.8000\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 26.2576 - accuracy: 0.8110 - val_loss: 24.7807 - val_accuracy: 0.7419\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 23.5596 - accuracy: 0.8336 - val_loss: 22.2813 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 21.1486 - accuracy: 0.8417 - val_loss: 20.0266 - val_accuracy: 0.7290\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 18.9620 - accuracy: 0.8498 - val_loss: 18.0172 - val_accuracy: 0.7806\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 17.0119 - accuracy: 0.8578 - val_loss: 16.0804 - val_accuracy: 0.7871\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 15.2139 - accuracy: 0.8821 - val_loss: 14.4416 - val_accuracy: 0.7613\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 13.6115 - accuracy: 0.8691 - val_loss: 12.9123 - val_accuracy: 0.8129\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 12.1324 - accuracy: 0.9079 - val_loss: 11.5943 - val_accuracy: 0.8194\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 10.8034 - accuracy: 0.9289 - val_loss: 10.3451 - val_accuracy: 0.8258\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 9.6180 - accuracy: 0.9467 - val_loss: 9.3148 - val_accuracy: 0.8194\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 8.5160 - accuracy: 0.9596 - val_loss: 8.7998 - val_accuracy: 0.8323\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 7.5241 - accuracy: 0.9580 - val_loss: 7.5834 - val_accuracy: 0.7355\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 6.7674 - accuracy: 0.9208 - val_loss: 6.6209 - val_accuracy: 0.8065\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 5.9579 - accuracy: 0.9564 - val_loss: 6.2298 - val_accuracy: 0.8258\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 5.2480 - accuracy: 0.9774 - val_loss: 5.5824 - val_accuracy: 0.8516\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 4.7482 - accuracy: 0.9483 - val_loss: 4.7490 - val_accuracy: 0.8194\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 4.1523 - accuracy: 0.9903 - val_loss: 4.5138 - val_accuracy: 0.8194\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6426 - accuracy: 0.9887 - val_loss: 4.7974 - val_accuracy: 0.8387\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 3.2595 - accuracy: 0.9677 - val_loss: 3.4329 - val_accuracy: 0.8323\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.8473 - accuracy: 0.9903 - val_loss: 3.4342 - val_accuracy: 0.8258\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 2.4912 - accuracy: 0.9984 - val_loss: 3.4295 - val_accuracy: 0.8387\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 2.2006 - accuracy: 0.9968 - val_loss: 3.1309 - val_accuracy: 0.8516\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.9427 - accuracy: 0.9952 - val_loss: 2.7344 - val_accuracy: 0.8581\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.7115 - accuracy: 0.9968 - val_loss: 2.5761 - val_accuracy: 0.8194\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.5152 - accuracy: 0.9968 - val_loss: 3.1263 - val_accuracy: 0.8129\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 1.3775 - accuracy: 0.9871 - val_loss: 2.2269 - val_accuracy: 0.8194\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.2608 - accuracy: 0.9693 - val_loss: 1.5767 - val_accuracy: 0.8129\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.0562 - accuracy: 0.9952 - val_loss: 2.2903 - val_accuracy: 0.8258\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.9424 - accuracy: 0.9935 - val_loss: 2.6602 - val_accuracy: 0.8000\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.8778 - accuracy: 0.9709 - val_loss: 1.3848 - val_accuracy: 0.8516\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7470 - accuracy: 0.9903 - val_loss: 1.4737 - val_accuracy: 0.8000\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6540 - accuracy: 0.9887 - val_loss: 1.3828 - val_accuracy: 0.8387\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5653 - accuracy: 0.9952 - val_loss: 1.5285 - val_accuracy: 0.8452\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4882 - accuracy: 1.0000 - val_loss: 1.4924 - val_accuracy: 0.8258\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4301 - accuracy: 1.0000 - val_loss: 1.4826 - val_accuracy: 0.8323\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3788 - accuracy: 1.0000 - val_loss: 1.4428 - val_accuracy: 0.8323\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3337 - accuracy: 1.0000 - val_loss: 1.3772 - val_accuracy: 0.8323\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.2943 - accuracy: 1.0000 - val_loss: 1.3440 - val_accuracy: 0.8323\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2597 - accuracy: 1.0000 - val_loss: 1.3020 - val_accuracy: 0.8323\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.2293 - accuracy: 1.0000 - val_loss: 1.2822 - val_accuracy: 0.8323\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.2025 - accuracy: 1.0000 - val_loss: 1.2740 - val_accuracy: 0.8323\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.1789 - accuracy: 1.0000 - val_loss: 1.2712 - val_accuracy: 0.8323\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 1.2854 - val_accuracy: 0.8323\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1399 - accuracy: 1.0000 - val_loss: 1.2999 - val_accuracy: 0.8258\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1238 - accuracy: 1.0000 - val_loss: 1.3012 - val_accuracy: 0.8323\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 1.2965 - val_accuracy: 0.8323\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 0.8258\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.8258\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 1.2737 - val_accuracy: 0.8258\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 1.2743 - val_accuracy: 0.8323\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 1.2586 - val_accuracy: 0.8258\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 1.2418 - val_accuracy: 0.8258\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 1.2234 - val_accuracy: 0.8258\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 1.2190 - val_accuracy: 0.8258\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 1.2224 - val_accuracy: 0.8258\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 1.2329 - val_accuracy: 0.8258\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.2562 - val_accuracy: 0.8194\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.2520 - val_accuracy: 0.8194\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.2243 - val_accuracy: 0.8258\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.2012 - val_accuracy: 0.8258\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.2102 - val_accuracy: 0.8194\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.2062 - val_accuracy: 0.8258\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.8258\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.2346 - val_accuracy: 0.8258\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.2419 - val_accuracy: 0.8258\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.2492 - val_accuracy: 0.8258\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.2422 - val_accuracy: 0.8258\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.2815 - val_accuracy: 0.8387\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3219 - val_accuracy: 0.8258\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.3062 - val_accuracy: 0.8194\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2012 - accuracy: 0.8258\n",
            "Test Loss: 1.2012009620666504, Test Accuracy: 0.8258064389228821\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 73ms/step - loss: 48.6189 - accuracy: 0.6527 - val_loss: 45.9343 - val_accuracy: 0.7161\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 44.0088 - accuracy: 0.6769 - val_loss: 41.4800 - val_accuracy: 0.7161\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 39.6891 - accuracy: 0.6769 - val_loss: 37.3289 - val_accuracy: 0.7161\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 35.7545 - accuracy: 0.6866 - val_loss: 33.6523 - val_accuracy: 0.8129\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 32.1524 - accuracy: 0.7254 - val_loss: 30.2854 - val_accuracy: 0.7613\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 28.9009 - accuracy: 0.8045 - val_loss: 27.1435 - val_accuracy: 0.8387\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 25.9548 - accuracy: 0.7981 - val_loss: 24.3362 - val_accuracy: 0.8065\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 23.2798 - accuracy: 0.8061 - val_loss: 21.8251 - val_accuracy: 0.8516\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 20.9049 - accuracy: 0.7803 - val_loss: 19.6867 - val_accuracy: 0.8258\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 18.7687 - accuracy: 0.7593 - val_loss: 17.5638 - val_accuracy: 0.8710\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 16.7902 - accuracy: 0.8384 - val_loss: 15.7112 - val_accuracy: 0.8194\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 14.9516 - accuracy: 0.8433 - val_loss: 14.0799 - val_accuracy: 0.8710\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 13.3279 - accuracy: 0.9144 - val_loss: 12.5791 - val_accuracy: 0.8710\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 11.8533 - accuracy: 0.9418 - val_loss: 11.2867 - val_accuracy: 0.8774\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 10.5263 - accuracy: 0.9645 - val_loss: 10.0848 - val_accuracy: 0.8968\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 9.3545 - accuracy: 0.9628 - val_loss: 9.4479 - val_accuracy: 0.6129\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 8.5632 - accuracy: 0.8013 - val_loss: 7.9589 - val_accuracy: 0.8645\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 7.5476 - accuracy: 0.8788 - val_loss: 7.1049 - val_accuracy: 0.8839\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 6.6436 - accuracy: 0.9467 - val_loss: 6.4153 - val_accuracy: 0.8710\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 5.8518 - accuracy: 0.9628 - val_loss: 5.7726 - val_accuracy: 0.8387\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 5.1187 - accuracy: 0.9758 - val_loss: 5.6009 - val_accuracy: 0.8774\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 4.5255 - accuracy: 0.9693 - val_loss: 4.6705 - val_accuracy: 0.8065\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 3.9866 - accuracy: 0.9806 - val_loss: 4.3848 - val_accuracy: 0.8903\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 3.5642 - accuracy: 0.9661 - val_loss: 3.8107 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 3.1389 - accuracy: 0.9758 - val_loss: 3.2253 - val_accuracy: 0.8903\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 2.7276 - accuracy: 0.9887 - val_loss: 2.9946 - val_accuracy: 0.8710\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 2.3878 - accuracy: 0.9968 - val_loss: 2.8996 - val_accuracy: 0.8968\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 2.1026 - accuracy: 0.9968 - val_loss: 2.5609 - val_accuracy: 0.8774\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.8704 - accuracy: 0.9919 - val_loss: 2.4466 - val_accuracy: 0.8323\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.6717 - accuracy: 0.9838 - val_loss: 1.8734 - val_accuracy: 0.8968\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.4669 - accuracy: 0.9887 - val_loss: 1.7607 - val_accuracy: 0.8903\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.2884 - accuracy: 0.9887 - val_loss: 1.6681 - val_accuracy: 0.8581\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.1173 - accuracy: 0.9952 - val_loss: 1.4086 - val_accuracy: 0.9032\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9745 - accuracy: 0.9968 - val_loss: 1.7909 - val_accuracy: 0.8774\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.8556 - accuracy: 0.9984 - val_loss: 1.4453 - val_accuracy: 0.8903\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.7847 - accuracy: 0.9887 - val_loss: 1.1201 - val_accuracy: 0.8645\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6798 - accuracy: 0.9935 - val_loss: 1.2406 - val_accuracy: 0.8581\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5871 - accuracy: 0.9968 - val_loss: 1.5520 - val_accuracy: 0.8516\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5113 - accuracy: 1.0000 - val_loss: 1.1744 - val_accuracy: 0.8774\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4564 - accuracy: 0.9952 - val_loss: 1.7382 - val_accuracy: 0.8452\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4214 - accuracy: 0.9887 - val_loss: 1.0566 - val_accuracy: 0.8645\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.3690 - accuracy: 0.9919 - val_loss: 0.9208 - val_accuracy: 0.8710\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3351 - accuracy: 0.9903 - val_loss: 0.8493 - val_accuracy: 0.8968\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2804 - accuracy: 0.9984 - val_loss: 1.0569 - val_accuracy: 0.8387\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2514 - accuracy: 0.9952 - val_loss: 0.8549 - val_accuracy: 0.8839\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2135 - accuracy: 0.9984 - val_loss: 0.8424 - val_accuracy: 0.9032\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2284 - accuracy: 0.9838 - val_loss: 0.9717 - val_accuracy: 0.8516\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2807 - accuracy: 0.9596 - val_loss: 0.5199 - val_accuracy: 0.8581\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1984 - accuracy: 0.9903 - val_loss: 0.7406 - val_accuracy: 0.8645\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1750 - accuracy: 0.9838 - val_loss: 0.7581 - val_accuracy: 0.8710\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1402 - accuracy: 0.9919 - val_loss: 0.5654 - val_accuracy: 0.8839\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1247 - accuracy: 0.9935 - val_loss: 0.6260 - val_accuracy: 0.8903\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1011 - accuracy: 0.9984 - val_loss: 0.4891 - val_accuracy: 0.9032\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.8903\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.7427 - val_accuracy: 0.8774\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.8645\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8645\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8710\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8710\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8774\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.8839\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.6820 - val_accuracy: 0.8839\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8903\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.9032\n",
            "Test Loss: 0.48911890387535095, Test Accuracy: 0.9032257795333862\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 73ms/step - loss: 48.6562 - accuracy: 0.6817 - val_loss: 46.0957 - val_accuracy: 0.6516\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 44.1607 - accuracy: 0.6931 - val_loss: 41.7870 - val_accuracy: 0.6516\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 39.9770 - accuracy: 0.6931 - val_loss: 37.7549 - val_accuracy: 0.6516\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 36.0650 - accuracy: 0.6931 - val_loss: 34.0211 - val_accuracy: 0.6645\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 32.5196 - accuracy: 0.7447 - val_loss: 30.6960 - val_accuracy: 0.8194\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 29.2802 - accuracy: 0.7964 - val_loss: 27.5683 - val_accuracy: 0.8194\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 26.3243 - accuracy: 0.8336 - val_loss: 24.7827 - val_accuracy: 0.8258\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 23.6446 - accuracy: 0.8417 - val_loss: 22.2861 - val_accuracy: 0.8387\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 21.2232 - accuracy: 0.8562 - val_loss: 19.9972 - val_accuracy: 0.8129\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 19.0181 - accuracy: 0.8853 - val_loss: 17.9159 - val_accuracy: 0.8645\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 17.0135 - accuracy: 0.8966 - val_loss: 16.1307 - val_accuracy: 0.8645\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 15.2406 - accuracy: 0.8934 - val_loss: 14.3828 - val_accuracy: 0.8645\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 13.6079 - accuracy: 0.9192 - val_loss: 12.8688 - val_accuracy: 0.8839\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 12.0928 - accuracy: 0.9612 - val_loss: 11.5913 - val_accuracy: 0.8903\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 10.8232 - accuracy: 0.9257 - val_loss: 10.2608 - val_accuracy: 0.9032\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 9.6720 - accuracy: 0.8966 - val_loss: 9.0677 - val_accuracy: 0.9290\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 8.5001 - accuracy: 0.9645 - val_loss: 8.5146 - val_accuracy: 0.8710\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 7.5613 - accuracy: 0.9693 - val_loss: 7.3330 - val_accuracy: 0.8581\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 6.7241 - accuracy: 0.9725 - val_loss: 6.7138 - val_accuracy: 0.8645\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.9513 - accuracy: 0.9742 - val_loss: 5.9562 - val_accuracy: 0.8774\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 5.2453 - accuracy: 0.9871 - val_loss: 5.3979 - val_accuracy: 0.8645\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 4.6409 - accuracy: 0.9919 - val_loss: 4.6588 - val_accuracy: 0.8968\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 4.1027 - accuracy: 0.9903 - val_loss: 4.4053 - val_accuracy: 0.8774\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 3.7134 - accuracy: 0.9612 - val_loss: 3.7360 - val_accuracy: 0.8645\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 3.2966 - accuracy: 0.9677 - val_loss: 3.3729 - val_accuracy: 0.8516\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.8661 - accuracy: 0.9903 - val_loss: 3.3817 - val_accuracy: 0.8452\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 2.5273 - accuracy: 0.9887 - val_loss: 3.0678 - val_accuracy: 0.8452\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 2.2315 - accuracy: 0.9855 - val_loss: 2.5617 - val_accuracy: 0.8903\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 1.9529 - accuracy: 0.9968 - val_loss: 2.2920 - val_accuracy: 0.9097\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.7328 - accuracy: 0.9935 - val_loss: 2.6060 - val_accuracy: 0.8065\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 1.9018 - accuracy: 0.8918 - val_loss: 1.9310 - val_accuracy: 0.6903\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 1.6279 - accuracy: 0.8691 - val_loss: 1.5950 - val_accuracy: 0.8710\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.2635 - accuracy: 0.9903 - val_loss: 1.6402 - val_accuracy: 0.8645\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1031 - accuracy: 0.9855 - val_loss: 1.6661 - val_accuracy: 0.8452\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.9956 - accuracy: 0.9822 - val_loss: 1.2720 - val_accuracy: 0.8774\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.8613 - accuracy: 0.9903 - val_loss: 1.1090 - val_accuracy: 0.9032\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7415 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.8903\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.6520 - accuracy: 0.9984 - val_loss: 0.9921 - val_accuracy: 0.9097\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5720 - accuracy: 1.0000 - val_loss: 0.9776 - val_accuracy: 0.9226\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5042 - accuracy: 1.0000 - val_loss: 0.9480 - val_accuracy: 0.9097\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4454 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.9097\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3939 - accuracy: 1.0000 - val_loss: 0.8542 - val_accuracy: 0.9097\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3485 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.9097\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3085 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.9097\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2732 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.9161\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2422 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.9226\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.9226\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1908 - accuracy: 1.0000 - val_loss: 0.6659 - val_accuracy: 0.9226\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1695 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.9161\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1508 - accuracy: 1.0000 - val_loss: 0.6140 - val_accuracy: 0.9226\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1343 - accuracy: 1.0000 - val_loss: 0.5875 - val_accuracy: 0.9226\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1197 - accuracy: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.9226\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.9226\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.9161\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.6615 - val_accuracy: 0.9226\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8968\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.8968\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.9226\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.9226\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.9226\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.9226\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.9226\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.9226\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.5697 - val_accuracy: 0.9226\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.9226\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.9226\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.5574 - val_accuracy: 0.9226\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.5629 - val_accuracy: 0.9226\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.9226\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.9226\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.5453 - val_accuracy: 0.9226\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.9226\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.9290\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.9226\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.9290\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.9226\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.9290\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5630 - val_accuracy: 0.9226\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.9226\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.9226\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.9226\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.9226\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.9226\n",
            "Test Loss: 0.5309041738510132, Test Accuracy: 0.9225806593894958\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 73ms/step - loss: 48.6068 - accuracy: 0.6640 - val_loss: 45.9785 - val_accuracy: 0.6968\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 44.1378 - accuracy: 0.6817 - val_loss: 41.7009 - val_accuracy: 0.6968\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 39.9464 - accuracy: 0.6817 - val_loss: 37.6999 - val_accuracy: 0.6968\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 36.0552 - accuracy: 0.6817 - val_loss: 33.9734 - val_accuracy: 0.6968\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 32.4912 - accuracy: 0.6817 - val_loss: 30.5652 - val_accuracy: 0.6968\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 29.2549 - accuracy: 0.6963 - val_loss: 27.5355 - val_accuracy: 0.7677\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 26.2693 - accuracy: 0.7900 - val_loss: 24.7104 - val_accuracy: 0.8258\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 23.6138 - accuracy: 0.8320 - val_loss: 22.1871 - val_accuracy: 0.8387\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 21.1677 - accuracy: 0.8239 - val_loss: 19.9021 - val_accuracy: 0.8194\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 18.9759 - accuracy: 0.8659 - val_loss: 17.8482 - val_accuracy: 0.8387\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 16.9913 - accuracy: 0.8643 - val_loss: 16.0063 - val_accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.2940 - accuracy: 0.8110 - val_loss: 14.3147 - val_accuracy: 0.8000\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 13.6038 - accuracy: 0.8691 - val_loss: 12.8059 - val_accuracy: 0.8194\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 12.1224 - accuracy: 0.9128 - val_loss: 11.4497 - val_accuracy: 0.8516\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 10.7907 - accuracy: 0.9418 - val_loss: 10.1934 - val_accuracy: 0.8581\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 9.6300 - accuracy: 0.9321 - val_loss: 9.1653 - val_accuracy: 0.8258\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 8.5331 - accuracy: 0.9677 - val_loss: 8.1774 - val_accuracy: 0.9032\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 7.5961 - accuracy: 0.9257 - val_loss: 7.2345 - val_accuracy: 0.8645\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 6.6915 - accuracy: 0.9515 - val_loss: 6.5753 - val_accuracy: 0.8645\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 5.9310 - accuracy: 0.9628 - val_loss: 5.7656 - val_accuracy: 0.8452\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 5.2673 - accuracy: 0.9628 - val_loss: 5.1463 - val_accuracy: 0.8839\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 4.9675 - accuracy: 0.8078 - val_loss: 4.7046 - val_accuracy: 0.7677\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 4.3623 - accuracy: 0.8675 - val_loss: 4.1392 - val_accuracy: 0.8065\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 3.7472 - accuracy: 0.9435 - val_loss: 3.6722 - val_accuracy: 0.8452\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 3.2472 - accuracy: 0.9822 - val_loss: 3.3335 - val_accuracy: 0.8645\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 2.8876 - accuracy: 0.9774 - val_loss: 2.8786 - val_accuracy: 0.8774\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 2.5334 - accuracy: 0.9838 - val_loss: 2.5898 - val_accuracy: 0.8968\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 2.2497 - accuracy: 0.9871 - val_loss: 2.4711 - val_accuracy: 0.8774\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 1.9558 - accuracy: 0.9984 - val_loss: 2.1475 - val_accuracy: 0.9032\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 1.7276 - accuracy: 0.9968 - val_loss: 2.0809 - val_accuracy: 0.8710\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.5200 - accuracy: 1.0000 - val_loss: 2.1089 - val_accuracy: 0.8516\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.3588 - accuracy: 0.9935 - val_loss: 1.9601 - val_accuracy: 0.8323\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.1956 - accuracy: 0.9919 - val_loss: 1.8832 - val_accuracy: 0.8194\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.0651 - accuracy: 0.9919 - val_loss: 1.5888 - val_accuracy: 0.8258\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9670 - accuracy: 0.9790 - val_loss: 1.6293 - val_accuracy: 0.7548\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.9150 - accuracy: 0.9580 - val_loss: 1.1797 - val_accuracy: 0.8516\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.7520 - accuracy: 0.9871 - val_loss: 1.0425 - val_accuracy: 0.8968\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6438 - accuracy: 0.9968 - val_loss: 1.2830 - val_accuracy: 0.8774\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5861 - accuracy: 0.9887 - val_loss: 0.9479 - val_accuracy: 0.8710\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5057 - accuracy: 0.9968 - val_loss: 0.9374 - val_accuracy: 0.8710\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4434 - accuracy: 0.9968 - val_loss: 0.9163 - val_accuracy: 0.8839\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3855 - accuracy: 1.0000 - val_loss: 0.9287 - val_accuracy: 0.8710\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3440 - accuracy: 0.9984 - val_loss: 0.7655 - val_accuracy: 0.8968\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3023 - accuracy: 1.0000 - val_loss: 0.9781 - val_accuracy: 0.8452\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2710 - accuracy: 0.9952 - val_loss: 0.7923 - val_accuracy: 0.8968\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2389 - accuracy: 0.9984 - val_loss: 0.7843 - val_accuracy: 0.8903\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2119 - accuracy: 0.9984 - val_loss: 0.7436 - val_accuracy: 0.8903\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2003 - accuracy: 0.9935 - val_loss: 0.9043 - val_accuracy: 0.8452\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2055 - accuracy: 0.9806 - val_loss: 0.5126 - val_accuracy: 0.8839\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1943 - accuracy: 0.9838 - val_loss: 0.6854 - val_accuracy: 0.8516\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1562 - accuracy: 0.9887 - val_loss: 0.6217 - val_accuracy: 0.8452\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1304 - accuracy: 0.9952 - val_loss: 0.6026 - val_accuracy: 0.8710\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1080 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.8710\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.9032\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9032\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.9032\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9097\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.9161\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9161\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9161\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9226\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9226\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9097\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9097\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9161\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9097\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9097\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9161\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9161\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9161\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9161\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.9097\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9161\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.9161\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.9097\n",
            "Test Loss: 0.3539999723434448, Test Accuracy: 0.9096774458885193\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 71ms/step - loss: 48.7168 - accuracy: 0.6565 - val_loss: 46.1561 - val_accuracy: 0.7273\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 44.3322 - accuracy: 0.6742 - val_loss: 41.9152 - val_accuracy: 0.7273\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 40.1998 - accuracy: 0.6742 - val_loss: 38.0041 - val_accuracy: 0.7273\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 36.3563 - accuracy: 0.6742 - val_loss: 34.3495 - val_accuracy: 0.7338\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 32.8345 - accuracy: 0.6968 - val_loss: 30.9795 - val_accuracy: 0.7468\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 29.6219 - accuracy: 0.7419 - val_loss: 27.9272 - val_accuracy: 0.7143\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 26.6527 - accuracy: 0.7710 - val_loss: 25.1586 - val_accuracy: 0.7532\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 24.0034 - accuracy: 0.7806 - val_loss: 22.6574 - val_accuracy: 0.7792\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 21.5443 - accuracy: 0.8226 - val_loss: 20.3208 - val_accuracy: 0.7662\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 19.3305 - accuracy: 0.8484 - val_loss: 18.2635 - val_accuracy: 0.7987\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 17.3172 - accuracy: 0.8629 - val_loss: 16.4242 - val_accuracy: 0.8312\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 15.5147 - accuracy: 0.8935 - val_loss: 14.7448 - val_accuracy: 0.7143\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 13.8901 - accuracy: 0.8806 - val_loss: 13.2437 - val_accuracy: 0.8247\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 12.3813 - accuracy: 0.9274 - val_loss: 11.8264 - val_accuracy: 0.8506\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 11.0240 - accuracy: 0.9484 - val_loss: 10.6287 - val_accuracy: 0.8117\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 9.8299 - accuracy: 0.9274 - val_loss: 9.6301 - val_accuracy: 0.7662\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 8.8060 - accuracy: 0.9081 - val_loss: 8.5039 - val_accuracy: 0.7922\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 7.8388 - accuracy: 0.9145 - val_loss: 7.7797 - val_accuracy: 0.7792\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 6.9242 - accuracy: 0.9452 - val_loss: 6.9161 - val_accuracy: 0.8766\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 6.1566 - accuracy: 0.9419 - val_loss: 6.3568 - val_accuracy: 0.7597\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 5.4092 - accuracy: 0.9774 - val_loss: 5.7783 - val_accuracy: 0.8636\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.7594 - accuracy: 0.9903 - val_loss: 6.1700 - val_accuracy: 0.7403\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 4.2876 - accuracy: 0.9742 - val_loss: 4.5828 - val_accuracy: 0.8766\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 3.7838 - accuracy: 0.9823 - val_loss: 4.0397 - val_accuracy: 0.8896\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 3.3309 - accuracy: 0.9839 - val_loss: 4.0136 - val_accuracy: 0.8571\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 3.0187 - accuracy: 0.9661 - val_loss: 3.4446 - val_accuracy: 0.7857\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 2.6552 - accuracy: 0.9774 - val_loss: 3.0445 - val_accuracy: 0.8506\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 2.2994 - accuracy: 0.9968 - val_loss: 3.3561 - val_accuracy: 0.8117\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.0196 - accuracy: 0.9984 - val_loss: 3.0611 - val_accuracy: 0.8636\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.7998 - accuracy: 0.9968 - val_loss: 2.6212 - val_accuracy: 0.8506\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.5737 - accuracy: 1.0000 - val_loss: 2.4376 - val_accuracy: 0.8636\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 1.3863 - accuracy: 1.0000 - val_loss: 2.3701 - val_accuracy: 0.8377\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.2220 - accuracy: 1.0000 - val_loss: 2.2339 - val_accuracy: 0.8636\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 1.0765 - accuracy: 1.0000 - val_loss: 2.0649 - val_accuracy: 0.8766\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.9485 - accuracy: 1.0000 - val_loss: 1.9169 - val_accuracy: 0.8701\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.8355 - accuracy: 1.0000 - val_loss: 1.7830 - val_accuracy: 0.8766\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.7360 - accuracy: 1.0000 - val_loss: 1.6873 - val_accuracy: 0.8766\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6484 - accuracy: 1.0000 - val_loss: 1.6199 - val_accuracy: 0.8766\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5709 - accuracy: 1.0000 - val_loss: 1.5588 - val_accuracy: 0.8766\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5028 - accuracy: 1.0000 - val_loss: 1.4988 - val_accuracy: 0.8831\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.4428 - accuracy: 1.0000 - val_loss: 1.4370 - val_accuracy: 0.8766\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3902 - accuracy: 1.0000 - val_loss: 1.3891 - val_accuracy: 0.8701\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3438 - accuracy: 1.0000 - val_loss: 1.3432 - val_accuracy: 0.8701\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.3029 - accuracy: 1.0000 - val_loss: 1.3049 - val_accuracy: 0.8831\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2670 - accuracy: 1.0000 - val_loss: 1.2679 - val_accuracy: 0.8766\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2354 - accuracy: 1.0000 - val_loss: 1.2429 - val_accuracy: 0.8766\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.2223 - val_accuracy: 0.8766\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1832 - accuracy: 1.0000 - val_loss: 1.1918 - val_accuracy: 0.8701\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1616 - accuracy: 1.0000 - val_loss: 1.1556 - val_accuracy: 0.8766\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1428 - accuracy: 1.0000 - val_loss: 1.1407 - val_accuracy: 0.8766\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1260 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.8766\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.1114 - accuracy: 1.0000 - val_loss: 1.1095 - val_accuracy: 0.8766\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 1.1013 - val_accuracy: 0.8766\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 1.0926 - val_accuracy: 0.8766\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.8766\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.8766\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 1.0612 - val_accuracy: 0.8766\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 1.0511 - val_accuracy: 0.8831\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 1.0380 - val_accuracy: 0.8766\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 1.0614 - val_accuracy: 0.8766\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.0868 - val_accuracy: 0.8766\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.8766\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.0711 - val_accuracy: 0.8831\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 1.0075 - val_accuracy: 0.8766\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.1454 - val_accuracy: 0.8442\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.0828 - val_accuracy: 0.8701\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.0931 - val_accuracy: 0.8766\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.0849 - val_accuracy: 0.8636\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.0378 - val_accuracy: 0.8766\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 0.8766\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.0310 - val_accuracy: 0.8766\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.0500 - val_accuracy: 0.8831\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0726 - val_accuracy: 0.8766\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.8636\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0075 - accuracy: 0.8766\n",
            "Test Loss: 1.0075143575668335, Test Accuracy: 0.8766233921051025\n",
            "\n",
            "Average Accuracy Across All Folds: 0.8875827431678772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdamW + Random 증강 + L2 규제 + dropout 6개 + weight_decay 설정 변경 :  0.8720569849014282"
      ],
      "metadata": {
        "id": "a7UtOD8pMdn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import AdamW\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model(weight_decay=1e-4):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2((weight_decay))))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2((weight_decay))))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model(weight_decay=1e-4)\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "id": "gAWcpqlILu2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc56f5d-071c-42a3-f5ce-0f0d9feee6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 17s 114ms/step - loss: 1.1098 - accuracy: 0.6721 - val_loss: 1.1469 - val_accuracy: 0.6323\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0724 - accuracy: 0.6979 - val_loss: 1.1405 - val_accuracy: 0.6323\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0181 - accuracy: 0.6979 - val_loss: 1.0719 - val_accuracy: 0.6323\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9498 - accuracy: 0.6979 - val_loss: 1.0447 - val_accuracy: 0.7226\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9192 - accuracy: 0.7270 - val_loss: 0.9793 - val_accuracy: 0.7742\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8956 - accuracy: 0.8078 - val_loss: 1.0376 - val_accuracy: 0.7871\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8655 - accuracy: 0.8304 - val_loss: 0.9627 - val_accuracy: 0.8194\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8453 - accuracy: 0.8643 - val_loss: 0.9383 - val_accuracy: 0.7355\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8472 - accuracy: 0.8255 - val_loss: 0.9433 - val_accuracy: 0.8194\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8296 - accuracy: 0.8627 - val_loss: 0.9638 - val_accuracy: 0.7871\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8236 - accuracy: 0.8465 - val_loss: 0.8826 - val_accuracy: 0.8258\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7679 - accuracy: 0.8934 - val_loss: 0.9023 - val_accuracy: 0.7935\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.7297 - accuracy: 0.9160 - val_loss: 0.8587 - val_accuracy: 0.8194\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6875 - accuracy: 0.9402 - val_loss: 0.9350 - val_accuracy: 0.7871\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6374 - accuracy: 0.9499 - val_loss: 1.0124 - val_accuracy: 0.7871\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6294 - accuracy: 0.9580 - val_loss: 0.8089 - val_accuracy: 0.8129\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6139 - accuracy: 0.9338 - val_loss: 0.7919 - val_accuracy: 0.8258\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5305 - accuracy: 0.9758 - val_loss: 0.7311 - val_accuracy: 0.8645\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4995 - accuracy: 0.9806 - val_loss: 1.2966 - val_accuracy: 0.7935\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4715 - accuracy: 0.9838 - val_loss: 0.7776 - val_accuracy: 0.8452\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4896 - accuracy: 0.9677 - val_loss: 0.8803 - val_accuracy: 0.8581\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4543 - accuracy: 0.9855 - val_loss: 0.8840 - val_accuracy: 0.8452\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4373 - accuracy: 0.9806 - val_loss: 0.7902 - val_accuracy: 0.8774\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4367 - accuracy: 0.9838 - val_loss: 1.0696 - val_accuracy: 0.8387\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4122 - accuracy: 0.9903 - val_loss: 0.9048 - val_accuracy: 0.8452\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4023 - accuracy: 0.9919 - val_loss: 0.9604 - val_accuracy: 0.8258\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.3865 - accuracy: 0.9968 - val_loss: 0.8662 - val_accuracy: 0.8387\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3753 - accuracy: 0.9984 - val_loss: 0.9659 - val_accuracy: 0.8645\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3732 - accuracy: 0.9984 - val_loss: 0.8676 - val_accuracy: 0.8581\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3653 - accuracy: 0.9984 - val_loss: 0.8718 - val_accuracy: 0.8645\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.3585 - accuracy: 0.9984 - val_loss: 0.9562 - val_accuracy: 0.8645\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3472 - accuracy: 1.0000 - val_loss: 0.8222 - val_accuracy: 0.8710\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3417 - accuracy: 1.0000 - val_loss: 0.8696 - val_accuracy: 0.8452\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3366 - accuracy: 1.0000 - val_loss: 0.9127 - val_accuracy: 0.8645\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3319 - accuracy: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.8710\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3273 - accuracy: 1.0000 - val_loss: 1.0010 - val_accuracy: 0.8710\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3227 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.8710\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3183 - accuracy: 1.0000 - val_loss: 1.0208 - val_accuracy: 0.8710\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3139 - accuracy: 1.0000 - val_loss: 1.0210 - val_accuracy: 0.8710\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 1.0224 - val_accuracy: 0.8710\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3053 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.8645\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3011 - accuracy: 1.0000 - val_loss: 1.0236 - val_accuracy: 0.8645\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2969 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.8645\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2928 - accuracy: 1.0000 - val_loss: 1.0264 - val_accuracy: 0.8710\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2888 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.8710\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2848 - accuracy: 1.0000 - val_loss: 1.0313 - val_accuracy: 0.8710\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2808 - accuracy: 1.0000 - val_loss: 1.0332 - val_accuracy: 0.8710\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2769 - accuracy: 1.0000 - val_loss: 1.0356 - val_accuracy: 0.8710\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2731 - accuracy: 1.0000 - val_loss: 1.0374 - val_accuracy: 0.8710\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2693 - accuracy: 1.0000 - val_loss: 1.0394 - val_accuracy: 0.8774\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2656 - accuracy: 1.0000 - val_loss: 1.0423 - val_accuracy: 0.8774\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2619 - accuracy: 1.0000 - val_loss: 1.0431 - val_accuracy: 0.8774\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 1.0458 - val_accuracy: 0.8710\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2547 - accuracy: 1.0000 - val_loss: 1.0489 - val_accuracy: 0.8710\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2511 - accuracy: 1.0000 - val_loss: 1.0525 - val_accuracy: 0.8710\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2476 - accuracy: 1.0000 - val_loss: 1.0552 - val_accuracy: 0.8710\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2442 - accuracy: 1.0000 - val_loss: 1.0585 - val_accuracy: 0.8710\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2408 - accuracy: 1.0000 - val_loss: 1.0596 - val_accuracy: 0.8710\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2375 - accuracy: 1.0000 - val_loss: 1.0568 - val_accuracy: 0.8710\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2342 - accuracy: 1.0000 - val_loss: 1.0566 - val_accuracy: 0.8774\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2309 - accuracy: 1.0000 - val_loss: 1.0621 - val_accuracy: 0.8774\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2277 - accuracy: 1.0000 - val_loss: 1.0707 - val_accuracy: 0.8710\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.8710\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.0730 - val_accuracy: 0.8710\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.0738 - val_accuracy: 0.8710\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.0778 - val_accuracy: 0.8710\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.0852 - val_accuracy: 0.8645\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.0863 - val_accuracy: 0.8645\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2065 - accuracy: 1.0000 - val_loss: 1.0865 - val_accuracy: 0.8645\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2036 - accuracy: 1.0000 - val_loss: 1.0857 - val_accuracy: 0.8645\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2008 - accuracy: 1.0000 - val_loss: 1.0868 - val_accuracy: 0.8581\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1980 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.8645\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1952 - accuracy: 1.0000 - val_loss: 1.0938 - val_accuracy: 0.8645\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1925 - accuracy: 1.0000 - val_loss: 1.1119 - val_accuracy: 0.8645\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1898 - accuracy: 1.0000 - val_loss: 1.1069 - val_accuracy: 0.8581\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1872 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 0.8581\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1846 - accuracy: 1.0000 - val_loss: 1.1003 - val_accuracy: 0.8645\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1820 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.8645\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1795 - accuracy: 1.0000 - val_loss: 1.1085 - val_accuracy: 0.8645\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1770 - accuracy: 1.0000 - val_loss: 1.1094 - val_accuracy: 0.8645\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1745 - accuracy: 1.0000 - val_loss: 1.1169 - val_accuracy: 0.8581\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1721 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.8645\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 1.1352 - val_accuracy: 0.8645\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1673 - accuracy: 1.0000 - val_loss: 1.1259 - val_accuracy: 0.8645\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1650 - accuracy: 1.0000 - val_loss: 1.1109 - val_accuracy: 0.8581\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1627 - accuracy: 1.0000 - val_loss: 1.1091 - val_accuracy: 0.8581\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1604 - accuracy: 1.0000 - val_loss: 1.0996 - val_accuracy: 0.8645\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.8645\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1560 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.8581\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1538 - accuracy: 1.0000 - val_loss: 1.1146 - val_accuracy: 0.8581\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 1.1258 - val_accuracy: 0.8645\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1496 - accuracy: 1.0000 - val_loss: 1.1336 - val_accuracy: 0.8645\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1475 - accuracy: 1.0000 - val_loss: 1.1339 - val_accuracy: 0.8645\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1454 - accuracy: 1.0000 - val_loss: 1.1276 - val_accuracy: 0.8645\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1434 - accuracy: 1.0000 - val_loss: 1.1159 - val_accuracy: 0.8581\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1414 - accuracy: 1.0000 - val_loss: 1.1126 - val_accuracy: 0.8581\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1394 - accuracy: 1.0000 - val_loss: 1.1076 - val_accuracy: 0.8581\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1374 - accuracy: 1.0000 - val_loss: 1.1143 - val_accuracy: 0.8581\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1355 - accuracy: 1.0000 - val_loss: 1.1245 - val_accuracy: 0.8645\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 1.1068 - val_accuracy: 0.8581\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1068 - accuracy: 0.8581\n",
            "Test Loss: 1.1068341732025146, Test Accuracy: 0.8580645322799683\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 52ms/step - loss: 1.1281 - accuracy: 0.6704 - val_loss: 1.1332 - val_accuracy: 0.7161\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.1113 - accuracy: 0.6769 - val_loss: 1.1306 - val_accuracy: 0.7161\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0813 - accuracy: 0.6769 - val_loss: 1.1267 - val_accuracy: 0.7161\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0571 - accuracy: 0.6769 - val_loss: 1.0196 - val_accuracy: 0.7161\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.0046 - accuracy: 0.6769 - val_loss: 1.0265 - val_accuracy: 0.7290\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9531 - accuracy: 0.6834 - val_loss: 0.9972 - val_accuracy: 0.8194\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9420 - accuracy: 0.7625 - val_loss: 0.8861 - val_accuracy: 0.7484\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9593 - accuracy: 0.7447 - val_loss: 0.9632 - val_accuracy: 0.8323\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9910 - accuracy: 0.7496 - val_loss: 0.9516 - val_accuracy: 0.8258\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9387 - accuracy: 0.7690 - val_loss: 0.9018 - val_accuracy: 0.8645\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8810 - accuracy: 0.8158 - val_loss: 0.9052 - val_accuracy: 0.8452\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8562 - accuracy: 0.8368 - val_loss: 0.9354 - val_accuracy: 0.8581\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8358 - accuracy: 0.8481 - val_loss: 0.8084 - val_accuracy: 0.8774\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7868 - accuracy: 0.8901 - val_loss: 0.7908 - val_accuracy: 0.9097\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7406 - accuracy: 0.9063 - val_loss: 0.7924 - val_accuracy: 0.9097\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7254 - accuracy: 0.9128 - val_loss: 0.9011 - val_accuracy: 0.7161\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7373 - accuracy: 0.8966 - val_loss: 0.7939 - val_accuracy: 0.8903\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6586 - accuracy: 0.9354 - val_loss: 0.7177 - val_accuracy: 0.8903\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6054 - accuracy: 0.9628 - val_loss: 0.7724 - val_accuracy: 0.8323\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5622 - accuracy: 0.9806 - val_loss: 0.6868 - val_accuracy: 0.9161\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5666 - accuracy: 0.9628 - val_loss: 0.7290 - val_accuracy: 0.8710\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5080 - accuracy: 0.9742 - val_loss: 0.7221 - val_accuracy: 0.8903\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5091 - accuracy: 0.9677 - val_loss: 0.8887 - val_accuracy: 0.8839\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5587 - accuracy: 0.9467 - val_loss: 0.7683 - val_accuracy: 0.8968\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4769 - accuracy: 0.9709 - val_loss: 0.6212 - val_accuracy: 0.9161\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4169 - accuracy: 0.9968 - val_loss: 0.7396 - val_accuracy: 0.8968\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3964 - accuracy: 1.0000 - val_loss: 0.7850 - val_accuracy: 0.9032\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4413 - accuracy: 0.9806 - val_loss: 0.9242 - val_accuracy: 0.8065\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4217 - accuracy: 0.9822 - val_loss: 0.6788 - val_accuracy: 0.8839\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4033 - accuracy: 0.9887 - val_loss: 0.7096 - val_accuracy: 0.8968\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3910 - accuracy: 0.9935 - val_loss: 0.7893 - val_accuracy: 0.8581\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3721 - accuracy: 0.9984 - val_loss: 0.8715 - val_accuracy: 0.8839\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3869 - accuracy: 0.9887 - val_loss: 0.8972 - val_accuracy: 0.8452\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3855 - accuracy: 0.9919 - val_loss: 0.7189 - val_accuracy: 0.8452\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3751 - accuracy: 0.9952 - val_loss: 0.6182 - val_accuracy: 0.9097\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3493 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.9161\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3437 - accuracy: 1.0000 - val_loss: 0.7806 - val_accuracy: 0.9161\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3389 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.9161\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3347 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.9226\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3306 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.9226\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3266 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.9226\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3227 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.9226\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3188 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.9161\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3150 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.9161\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3112 - accuracy: 1.0000 - val_loss: 0.7733 - val_accuracy: 0.9161\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3075 - accuracy: 1.0000 - val_loss: 0.7801 - val_accuracy: 0.9161\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3038 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.9161\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3001 - accuracy: 1.0000 - val_loss: 0.7841 - val_accuracy: 0.9161\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2965 - accuracy: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.9161\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2929 - accuracy: 1.0000 - val_loss: 0.7767 - val_accuracy: 0.9161\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2894 - accuracy: 1.0000 - val_loss: 0.7748 - val_accuracy: 0.9161\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2859 - accuracy: 1.0000 - val_loss: 0.7763 - val_accuracy: 0.9161\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2825 - accuracy: 1.0000 - val_loss: 0.7774 - val_accuracy: 0.9161\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2791 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.9161\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2757 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.9226\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2723 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.9161\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2691 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.9097\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2658 - accuracy: 1.0000 - val_loss: 0.8232 - val_accuracy: 0.9161\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2626 - accuracy: 1.0000 - val_loss: 0.8284 - val_accuracy: 0.9161\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2594 - accuracy: 1.0000 - val_loss: 0.8317 - val_accuracy: 0.9161\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2563 - accuracy: 1.0000 - val_loss: 0.8335 - val_accuracy: 0.9097\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.2531 - accuracy: 1.0000 - val_loss: 0.8354 - val_accuracy: 0.9161\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2501 - accuracy: 1.0000 - val_loss: 0.8389 - val_accuracy: 0.9161\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2470 - accuracy: 1.0000 - val_loss: 0.8501 - val_accuracy: 0.9097\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.2441 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.9097\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2411 - accuracy: 1.0000 - val_loss: 0.8572 - val_accuracy: 0.9097\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.2382 - accuracy: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.9161\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2354 - accuracy: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.9032\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2325 - accuracy: 1.0000 - val_loss: 0.9058 - val_accuracy: 0.9032\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2297 - accuracy: 1.0000 - val_loss: 0.8250 - val_accuracy: 0.9161\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.7837 - val_accuracy: 0.9161\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.9161\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2214 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.9226\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.9226\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.9226\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.9226\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.9226\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.7302 - val_accuracy: 0.9226\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2057 - accuracy: 1.0000 - val_loss: 0.7327 - val_accuracy: 0.9226\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2032 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.9226\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2007 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.9226\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1982 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.9226\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1958 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.9226\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1934 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.9226\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1911 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.9226\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1887 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.9226\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1864 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.9226\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1842 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.9161\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1819 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.9161\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1797 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.9161\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1775 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.9161\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1753 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.9161\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1732 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.9161\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1710 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.9161\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1689 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.9161\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1669 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.9161\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1648 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.9161\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1628 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.9161\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1608 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.9161\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1588 - accuracy: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.9161\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6860 - accuracy: 0.9161\n",
            "Test Loss: 0.6859844326972961, Test Accuracy: 0.9161290526390076\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 53ms/step - loss: 1.1130 - accuracy: 0.6850 - val_loss: 1.1550 - val_accuracy: 0.6516\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0674 - accuracy: 0.6931 - val_loss: 1.1057 - val_accuracy: 0.6516\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0421 - accuracy: 0.6931 - val_loss: 1.1331 - val_accuracy: 0.6516\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0121 - accuracy: 0.6931 - val_loss: 1.0743 - val_accuracy: 0.6710\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9518 - accuracy: 0.6947 - val_loss: 1.0015 - val_accuracy: 0.7161\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9313 - accuracy: 0.7383 - val_loss: 1.0280 - val_accuracy: 0.7677\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9124 - accuracy: 0.7900 - val_loss: 0.9846 - val_accuracy: 0.7935\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8577 - accuracy: 0.8320 - val_loss: 1.0134 - val_accuracy: 0.7548\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8888 - accuracy: 0.8223 - val_loss: 0.9346 - val_accuracy: 0.7677\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8693 - accuracy: 0.8352 - val_loss: 0.9364 - val_accuracy: 0.7677\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8015 - accuracy: 0.8675 - val_loss: 0.9053 - val_accuracy: 0.8516\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7721 - accuracy: 0.8805 - val_loss: 0.9686 - val_accuracy: 0.7290\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7703 - accuracy: 0.8837 - val_loss: 0.9148 - val_accuracy: 0.8323\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7086 - accuracy: 0.9208 - val_loss: 0.9098 - val_accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7044 - accuracy: 0.9305 - val_loss: 0.9560 - val_accuracy: 0.8129\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6559 - accuracy: 0.9354 - val_loss: 0.8959 - val_accuracy: 0.8387\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6439 - accuracy: 0.9354 - val_loss: 0.9812 - val_accuracy: 0.8323\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5959 - accuracy: 0.9515 - val_loss: 1.0514 - val_accuracy: 0.8581\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5397 - accuracy: 0.9758 - val_loss: 0.9984 - val_accuracy: 0.8581\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4821 - accuracy: 0.9919 - val_loss: 1.0706 - val_accuracy: 0.8000\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5987 - accuracy: 0.9467 - val_loss: 1.1703 - val_accuracy: 0.6581\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5537 - accuracy: 0.9386 - val_loss: 0.8455 - val_accuracy: 0.8645\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4740 - accuracy: 0.9806 - val_loss: 0.8795 - val_accuracy: 0.8387\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4250 - accuracy: 0.9968 - val_loss: 0.9967 - val_accuracy: 0.8516\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4025 - accuracy: 0.9984 - val_loss: 1.1799 - val_accuracy: 0.8581\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4067 - accuracy: 0.9935 - val_loss: 1.4042 - val_accuracy: 0.8452\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4507 - accuracy: 0.9806 - val_loss: 1.2108 - val_accuracy: 0.8323\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4303 - accuracy: 0.9790 - val_loss: 1.0769 - val_accuracy: 0.8581\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4112 - accuracy: 0.9903 - val_loss: 0.9146 - val_accuracy: 0.8581\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3814 - accuracy: 0.9968 - val_loss: 1.0593 - val_accuracy: 0.8516\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3729 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.8581\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3644 - accuracy: 1.0000 - val_loss: 1.2054 - val_accuracy: 0.8645\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3816 - accuracy: 0.9919 - val_loss: 1.1974 - val_accuracy: 0.8452\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4698 - accuracy: 0.9612 - val_loss: 0.7876 - val_accuracy: 0.8387\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4337 - accuracy: 0.9612 - val_loss: 0.9389 - val_accuracy: 0.8516\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3689 - accuracy: 0.9968 - val_loss: 0.8315 - val_accuracy: 0.8774\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3477 - accuracy: 1.0000 - val_loss: 0.9021 - val_accuracy: 0.8774\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3399 - accuracy: 1.0000 - val_loss: 0.9744 - val_accuracy: 0.8774\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3346 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.8774\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3305 - accuracy: 1.0000 - val_loss: 1.1163 - val_accuracy: 0.8774\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3264 - accuracy: 1.0000 - val_loss: 1.1231 - val_accuracy: 0.8903\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3224 - accuracy: 1.0000 - val_loss: 1.1276 - val_accuracy: 0.8839\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3186 - accuracy: 1.0000 - val_loss: 1.1312 - val_accuracy: 0.8903\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3147 - accuracy: 1.0000 - val_loss: 1.1355 - val_accuracy: 0.8903\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3110 - accuracy: 1.0000 - val_loss: 1.1390 - val_accuracy: 0.8839\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3072 - accuracy: 1.0000 - val_loss: 1.1414 - val_accuracy: 0.8839\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3035 - accuracy: 1.0000 - val_loss: 1.1434 - val_accuracy: 0.8839\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2999 - accuracy: 1.0000 - val_loss: 1.1462 - val_accuracy: 0.8839\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2963 - accuracy: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.8839\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2927 - accuracy: 1.0000 - val_loss: 1.1508 - val_accuracy: 0.8839\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.2892 - accuracy: 1.0000 - val_loss: 1.1529 - val_accuracy: 0.8839\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.2857 - accuracy: 1.0000 - val_loss: 1.1560 - val_accuracy: 0.8839\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2822 - accuracy: 1.0000 - val_loss: 1.1585 - val_accuracy: 0.8839\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2788 - accuracy: 1.0000 - val_loss: 1.1606 - val_accuracy: 0.8839\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2754 - accuracy: 1.0000 - val_loss: 1.1628 - val_accuracy: 0.8839\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.2721 - accuracy: 1.0000 - val_loss: 1.1654 - val_accuracy: 0.8839\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2688 - accuracy: 1.0000 - val_loss: 1.1662 - val_accuracy: 0.8839\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.2655 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.8839\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2623 - accuracy: 1.0000 - val_loss: 1.1674 - val_accuracy: 0.8839\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2591 - accuracy: 1.0000 - val_loss: 1.1673 - val_accuracy: 0.8839\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2559 - accuracy: 1.0000 - val_loss: 1.1683 - val_accuracy: 0.8839\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2528 - accuracy: 1.0000 - val_loss: 1.1688 - val_accuracy: 0.8839\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2497 - accuracy: 1.0000 - val_loss: 1.1680 - val_accuracy: 0.8839\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2467 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.8839\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2437 - accuracy: 1.0000 - val_loss: 1.1704 - val_accuracy: 0.8774\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2407 - accuracy: 1.0000 - val_loss: 1.1747 - val_accuracy: 0.8710\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2378 - accuracy: 1.0000 - val_loss: 1.1784 - val_accuracy: 0.8710\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2349 - accuracy: 1.0000 - val_loss: 1.1801 - val_accuracy: 0.8710\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2320 - accuracy: 1.0000 - val_loss: 1.1820 - val_accuracy: 0.8710\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2291 - accuracy: 1.0000 - val_loss: 1.1817 - val_accuracy: 0.8710\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.1818 - val_accuracy: 0.8710\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2236 - accuracy: 1.0000 - val_loss: 1.1830 - val_accuracy: 0.8710\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.8710\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.1827 - val_accuracy: 0.8710\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1805 - val_accuracy: 0.8710\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.1795 - val_accuracy: 0.8710\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1793 - val_accuracy: 0.8710\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.1800 - val_accuracy: 0.8710\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2051 - accuracy: 1.0000 - val_loss: 1.1803 - val_accuracy: 0.8710\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2026 - accuracy: 1.0000 - val_loss: 1.1807 - val_accuracy: 0.8710\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2001 - accuracy: 1.0000 - val_loss: 1.1791 - val_accuracy: 0.8710\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1976 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.8710\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1952 - accuracy: 1.0000 - val_loss: 1.1835 - val_accuracy: 0.8710\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1928 - accuracy: 1.0000 - val_loss: 1.1838 - val_accuracy: 0.8710\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1904 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.8710\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1881 - accuracy: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.8710\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1858 - accuracy: 1.0000 - val_loss: 1.1938 - val_accuracy: 0.8710\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1835 - accuracy: 1.0000 - val_loss: 1.1972 - val_accuracy: 0.8710\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1812 - accuracy: 1.0000 - val_loss: 1.1979 - val_accuracy: 0.8710\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1790 - accuracy: 1.0000 - val_loss: 1.1994 - val_accuracy: 0.8710\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1768 - accuracy: 1.0000 - val_loss: 1.1985 - val_accuracy: 0.8710\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1746 - accuracy: 1.0000 - val_loss: 1.1955 - val_accuracy: 0.8710\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1724 - accuracy: 1.0000 - val_loss: 1.1957 - val_accuracy: 0.8710\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1703 - accuracy: 1.0000 - val_loss: 1.1980 - val_accuracy: 0.8710\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1682 - accuracy: 1.0000 - val_loss: 1.1965 - val_accuracy: 0.8710\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1661 - accuracy: 1.0000 - val_loss: 1.1969 - val_accuracy: 0.8710\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1641 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.8710\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1621 - accuracy: 1.0000 - val_loss: 1.1916 - val_accuracy: 0.8710\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1601 - accuracy: 1.0000 - val_loss: 1.1943 - val_accuracy: 0.8710\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1581 - accuracy: 1.0000 - val_loss: 1.2072 - val_accuracy: 0.8710\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.2072 - accuracy: 0.8710\n",
            "Test Loss: 1.2071869373321533, Test Accuracy: 0.8709677457809448\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 6s 52ms/step - loss: 1.1314 - accuracy: 0.6397 - val_loss: 1.1580 - val_accuracy: 0.6968\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.0864 - accuracy: 0.6817 - val_loss: 1.1407 - val_accuracy: 0.6968\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0506 - accuracy: 0.6817 - val_loss: 1.1008 - val_accuracy: 0.6968\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9958 - accuracy: 0.6817 - val_loss: 1.0463 - val_accuracy: 0.7097\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.9318 - accuracy: 0.6931 - val_loss: 0.9307 - val_accuracy: 0.7871\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9146 - accuracy: 0.7787 - val_loss: 1.0597 - val_accuracy: 0.7419\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8835 - accuracy: 0.8094 - val_loss: 0.9116 - val_accuracy: 0.8516\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8656 - accuracy: 0.8562 - val_loss: 0.9113 - val_accuracy: 0.8645\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.8295 - accuracy: 0.8498 - val_loss: 0.8534 - val_accuracy: 0.8710\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8237 - accuracy: 0.8530 - val_loss: 0.8836 - val_accuracy: 0.8258\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.7924 - accuracy: 0.8805 - val_loss: 0.8276 - val_accuracy: 0.8645\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.7298 - accuracy: 0.8982 - val_loss: 0.9163 - val_accuracy: 0.7806\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7820 - accuracy: 0.8837 - val_loss: 0.8958 - val_accuracy: 0.7677\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.7393 - accuracy: 0.8885 - val_loss: 0.7886 - val_accuracy: 0.8903\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6573 - accuracy: 0.9386 - val_loss: 0.7817 - val_accuracy: 0.8516\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6046 - accuracy: 0.9661 - val_loss: 0.7603 - val_accuracy: 0.8581\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5513 - accuracy: 0.9855 - val_loss: 0.7457 - val_accuracy: 0.8903\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5137 - accuracy: 0.9887 - val_loss: 0.8327 - val_accuracy: 0.7935\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4874 - accuracy: 0.9855 - val_loss: 0.9214 - val_accuracy: 0.8710\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5037 - accuracy: 0.9612 - val_loss: 0.7357 - val_accuracy: 0.8581\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4760 - accuracy: 0.9742 - val_loss: 0.7174 - val_accuracy: 0.8516\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4516 - accuracy: 0.9806 - val_loss: 1.0842 - val_accuracy: 0.7613\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4351 - accuracy: 0.9822 - val_loss: 0.7453 - val_accuracy: 0.8710\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4227 - accuracy: 0.9838 - val_loss: 0.9777 - val_accuracy: 0.8065\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4081 - accuracy: 0.9855 - val_loss: 0.7483 - val_accuracy: 0.8516\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3717 - accuracy: 0.9984 - val_loss: 0.7708 - val_accuracy: 0.8581\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3616 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.8839\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3536 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.8710\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3474 - accuracy: 1.0000 - val_loss: 0.7882 - val_accuracy: 0.8710\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3419 - accuracy: 1.0000 - val_loss: 0.7887 - val_accuracy: 0.8774\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3366 - accuracy: 1.0000 - val_loss: 0.8170 - val_accuracy: 0.8774\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3314 - accuracy: 1.0000 - val_loss: 0.8395 - val_accuracy: 0.8774\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3265 - accuracy: 1.0000 - val_loss: 0.8574 - val_accuracy: 0.8710\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3217 - accuracy: 1.0000 - val_loss: 0.8727 - val_accuracy: 0.8710\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3170 - accuracy: 1.0000 - val_loss: 0.8867 - val_accuracy: 0.8710\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3123 - accuracy: 1.0000 - val_loss: 0.9005 - val_accuracy: 0.8710\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3077 - accuracy: 1.0000 - val_loss: 0.9070 - val_accuracy: 0.8710\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3031 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.8710\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2987 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.8710\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2943 - accuracy: 1.0000 - val_loss: 0.9045 - val_accuracy: 0.8710\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2900 - accuracy: 1.0000 - val_loss: 0.9032 - val_accuracy: 0.8710\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2857 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.8710\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2815 - accuracy: 1.0000 - val_loss: 0.9136 - val_accuracy: 0.8710\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2774 - accuracy: 1.0000 - val_loss: 0.9216 - val_accuracy: 0.8710\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2734 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8710\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2693 - accuracy: 1.0000 - val_loss: 0.9371 - val_accuracy: 0.8710\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2654 - accuracy: 1.0000 - val_loss: 0.9359 - val_accuracy: 0.8710\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2615 - accuracy: 1.0000 - val_loss: 0.9319 - val_accuracy: 0.8710\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2577 - accuracy: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.8710\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2539 - accuracy: 1.0000 - val_loss: 0.9324 - val_accuracy: 0.8710\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2502 - accuracy: 1.0000 - val_loss: 0.9384 - val_accuracy: 0.8710\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2466 - accuracy: 1.0000 - val_loss: 0.9390 - val_accuracy: 0.8710\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 0.9383 - val_accuracy: 0.8710\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2394 - accuracy: 1.0000 - val_loss: 0.9442 - val_accuracy: 0.8710\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2360 - accuracy: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.8710\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2325 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.8710\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2291 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.8710\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2258 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.8710\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2225 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.8710\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.8710\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.9501 - val_accuracy: 0.8710\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.9621 - val_accuracy: 0.8710\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.8710\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2068 - accuracy: 1.0000 - val_loss: 0.9503 - val_accuracy: 0.8710\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2038 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.8710\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2009 - accuracy: 1.0000 - val_loss: 0.9181 - val_accuracy: 0.8710\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1979 - accuracy: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.8710\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1951 - accuracy: 1.0000 - val_loss: 0.8981 - val_accuracy: 0.8774\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1923 - accuracy: 1.0000 - val_loss: 0.8983 - val_accuracy: 0.8774\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1895 - accuracy: 1.0000 - val_loss: 0.9110 - val_accuracy: 0.8710\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1867 - accuracy: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.8710\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1840 - accuracy: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.8710\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1814 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.8710\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1788 - accuracy: 1.0000 - val_loss: 0.9122 - val_accuracy: 0.8710\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1762 - accuracy: 1.0000 - val_loss: 0.9115 - val_accuracy: 0.8710\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1736 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.8710\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1711 - accuracy: 1.0000 - val_loss: 0.9014 - val_accuracy: 0.8710\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1686 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.8710\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1662 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.8710\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1638 - accuracy: 1.0000 - val_loss: 0.9131 - val_accuracy: 0.8710\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1614 - accuracy: 1.0000 - val_loss: 0.9148 - val_accuracy: 0.8710\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1591 - accuracy: 1.0000 - val_loss: 0.9232 - val_accuracy: 0.8710\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1568 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.8710\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1545 - accuracy: 1.0000 - val_loss: 0.9115 - val_accuracy: 0.8710\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1523 - accuracy: 1.0000 - val_loss: 0.9172 - val_accuracy: 0.8710\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1501 - accuracy: 1.0000 - val_loss: 0.9162 - val_accuracy: 0.8710\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1479 - accuracy: 1.0000 - val_loss: 0.9077 - val_accuracy: 0.8710\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.1458 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.8710\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1437 - accuracy: 1.0000 - val_loss: 0.9076 - val_accuracy: 0.8710\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1416 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.8710\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1395 - accuracy: 1.0000 - val_loss: 0.9141 - val_accuracy: 0.8710\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.1375 - accuracy: 1.0000 - val_loss: 0.9114 - val_accuracy: 0.8710\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1356 - accuracy: 1.0000 - val_loss: 0.9350 - val_accuracy: 0.8710\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.8710\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.1316 - accuracy: 1.0000 - val_loss: 0.9412 - val_accuracy: 0.8710\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1297 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.8710\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1278 - accuracy: 1.0000 - val_loss: 0.9171 - val_accuracy: 0.8710\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1260 - accuracy: 1.0000 - val_loss: 0.9166 - val_accuracy: 0.8710\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1242 - accuracy: 1.0000 - val_loss: 0.9089 - val_accuracy: 0.8710\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1224 - accuracy: 1.0000 - val_loss: 0.9060 - val_accuracy: 0.8710\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.9060 - accuracy: 0.8710\n",
            "Test Loss: 0.905972957611084, Test Accuracy: 0.8709677457809448\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 6s 105ms/step - loss: 1.1431 - accuracy: 0.6581 - val_loss: 1.1528 - val_accuracy: 0.7273\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.1127 - accuracy: 0.6742 - val_loss: 1.0977 - val_accuracy: 0.7273\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 1.0993 - accuracy: 0.6742 - val_loss: 1.0853 - val_accuracy: 0.7273\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.0445 - accuracy: 0.6742 - val_loss: 1.0478 - val_accuracy: 0.7273\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9900 - accuracy: 0.6742 - val_loss: 1.0958 - val_accuracy: 0.7208\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9701 - accuracy: 0.6887 - val_loss: 0.9772 - val_accuracy: 0.7468\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9129 - accuracy: 0.7806 - val_loss: 1.0003 - val_accuracy: 0.7597\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.9043 - accuracy: 0.8210 - val_loss: 0.8975 - val_accuracy: 0.7987\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.9003 - accuracy: 0.8065 - val_loss: 0.9200 - val_accuracy: 0.7727\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.8831 - accuracy: 0.8306 - val_loss: 0.8945 - val_accuracy: 0.8506\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8389 - accuracy: 0.8484 - val_loss: 0.8951 - val_accuracy: 0.8312\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8084 - accuracy: 0.8710 - val_loss: 0.8495 - val_accuracy: 0.8377\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8001 - accuracy: 0.8790 - val_loss: 0.8951 - val_accuracy: 0.7922\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7880 - accuracy: 0.8758 - val_loss: 0.9520 - val_accuracy: 0.6818\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8464 - accuracy: 0.8323 - val_loss: 0.8641 - val_accuracy: 0.8052\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.7761 - accuracy: 0.8645 - val_loss: 0.8372 - val_accuracy: 0.8247\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.7020 - accuracy: 0.9097 - val_loss: 0.8211 - val_accuracy: 0.8377\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6376 - accuracy: 0.9516 - val_loss: 0.8242 - val_accuracy: 0.8377\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6263 - accuracy: 0.9500 - val_loss: 0.8445 - val_accuracy: 0.8442\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5685 - accuracy: 0.9742 - val_loss: 0.8922 - val_accuracy: 0.8571\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5623 - accuracy: 0.9710 - val_loss: 0.8264 - val_accuracy: 0.8571\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5024 - accuracy: 0.9790 - val_loss: 0.9204 - val_accuracy: 0.8182\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4761 - accuracy: 0.9839 - val_loss: 1.0629 - val_accuracy: 0.8766\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4451 - accuracy: 0.9855 - val_loss: 0.9226 - val_accuracy: 0.8701\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4354 - accuracy: 0.9903 - val_loss: 0.9609 - val_accuracy: 0.8571\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4165 - accuracy: 0.9935 - val_loss: 1.1023 - val_accuracy: 0.8312\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4085 - accuracy: 0.9968 - val_loss: 1.3033 - val_accuracy: 0.8701\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4289 - accuracy: 0.9887 - val_loss: 1.4768 - val_accuracy: 0.7143\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.8343 - accuracy: 0.8661 - val_loss: 0.9343 - val_accuracy: 0.7922\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5182 - accuracy: 0.9548 - val_loss: 0.7414 - val_accuracy: 0.8377\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4397 - accuracy: 0.9887 - val_loss: 0.7756 - val_accuracy: 0.8442\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3949 - accuracy: 1.0000 - val_loss: 0.8979 - val_accuracy: 0.8636\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3843 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.8571\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3737 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.8896\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3668 - accuracy: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.8766\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3611 - accuracy: 1.0000 - val_loss: 1.0494 - val_accuracy: 0.8701\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3559 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 0.8636\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3512 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.8636\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3465 - accuracy: 1.0000 - val_loss: 1.1502 - val_accuracy: 0.8506\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3424 - accuracy: 1.0000 - val_loss: 1.2207 - val_accuracy: 0.8571\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3388 - accuracy: 1.0000 - val_loss: 1.2595 - val_accuracy: 0.8571\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3348 - accuracy: 1.0000 - val_loss: 1.3031 - val_accuracy: 0.8701\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3312 - accuracy: 1.0000 - val_loss: 1.3350 - val_accuracy: 0.8701\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3275 - accuracy: 1.0000 - val_loss: 1.3645 - val_accuracy: 0.8636\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3240 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.8571\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3204 - accuracy: 1.0000 - val_loss: 1.4190 - val_accuracy: 0.8571\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3169 - accuracy: 1.0000 - val_loss: 1.4432 - val_accuracy: 0.8571\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3134 - accuracy: 1.0000 - val_loss: 1.4645 - val_accuracy: 0.8442\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3100 - accuracy: 1.0000 - val_loss: 1.4859 - val_accuracy: 0.8442\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3066 - accuracy: 1.0000 - val_loss: 1.5028 - val_accuracy: 0.8442\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.3032 - accuracy: 1.0000 - val_loss: 1.5150 - val_accuracy: 0.8442\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2999 - accuracy: 1.0000 - val_loss: 1.5249 - val_accuracy: 0.8442\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2966 - accuracy: 1.0000 - val_loss: 1.5295 - val_accuracy: 0.8442\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2933 - accuracy: 1.0000 - val_loss: 1.5340 - val_accuracy: 0.8442\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2901 - accuracy: 1.0000 - val_loss: 1.5367 - val_accuracy: 0.8442\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2869 - accuracy: 1.0000 - val_loss: 1.5443 - val_accuracy: 0.8442\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2837 - accuracy: 1.0000 - val_loss: 1.5516 - val_accuracy: 0.8442\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2806 - accuracy: 1.0000 - val_loss: 1.5568 - val_accuracy: 0.8442\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2775 - accuracy: 1.0000 - val_loss: 1.5707 - val_accuracy: 0.8377\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2744 - accuracy: 1.0000 - val_loss: 1.5789 - val_accuracy: 0.8377\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2714 - accuracy: 1.0000 - val_loss: 1.5822 - val_accuracy: 0.8377\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2683 - accuracy: 1.0000 - val_loss: 1.5889 - val_accuracy: 0.8377\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2654 - accuracy: 1.0000 - val_loss: 1.5929 - val_accuracy: 0.8377\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2624 - accuracy: 1.0000 - val_loss: 1.5967 - val_accuracy: 0.8377\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2595 - accuracy: 1.0000 - val_loss: 1.5964 - val_accuracy: 0.8377\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2566 - accuracy: 1.0000 - val_loss: 1.5984 - val_accuracy: 0.8377\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2538 - accuracy: 1.0000 - val_loss: 1.5990 - val_accuracy: 0.8377\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2509 - accuracy: 1.0000 - val_loss: 1.5862 - val_accuracy: 0.8377\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2481 - accuracy: 1.0000 - val_loss: 1.5736 - val_accuracy: 0.8377\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2454 - accuracy: 1.0000 - val_loss: 1.5701 - val_accuracy: 0.8377\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2426 - accuracy: 1.0000 - val_loss: 1.5685 - val_accuracy: 0.8442\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2399 - accuracy: 1.0000 - val_loss: 1.5678 - val_accuracy: 0.8442\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2372 - accuracy: 1.0000 - val_loss: 1.5689 - val_accuracy: 0.8442\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2346 - accuracy: 1.0000 - val_loss: 1.5746 - val_accuracy: 0.8442\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2320 - accuracy: 1.0000 - val_loss: 1.5788 - val_accuracy: 0.8442\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.2294 - accuracy: 1.0000 - val_loss: 1.5911 - val_accuracy: 0.8377\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2268 - accuracy: 1.0000 - val_loss: 1.5932 - val_accuracy: 0.8377\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2243 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.8377\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.6038 - val_accuracy: 0.8377\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2193 - accuracy: 1.0000 - val_loss: 1.6082 - val_accuracy: 0.8377\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.6266 - val_accuracy: 0.8442\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.6562 - val_accuracy: 0.8442\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.6778 - val_accuracy: 0.8442\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.6801 - val_accuracy: 0.8442\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.6684 - val_accuracy: 0.8442\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2049 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.8442\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2025 - accuracy: 1.0000 - val_loss: 1.6171 - val_accuracy: 0.8442\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2002 - accuracy: 1.0000 - val_loss: 1.6063 - val_accuracy: 0.8442\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1980 - accuracy: 1.0000 - val_loss: 1.6059 - val_accuracy: 0.8442\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1957 - accuracy: 1.0000 - val_loss: 1.6115 - val_accuracy: 0.8442\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1935 - accuracy: 1.0000 - val_loss: 1.6261 - val_accuracy: 0.8442\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1913 - accuracy: 1.0000 - val_loss: 1.6210 - val_accuracy: 0.8442\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1892 - accuracy: 1.0000 - val_loss: 1.6081 - val_accuracy: 0.8442\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1870 - accuracy: 1.0000 - val_loss: 1.5880 - val_accuracy: 0.8506\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1849 - accuracy: 1.0000 - val_loss: 1.6216 - val_accuracy: 0.8442\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1828 - accuracy: 1.0000 - val_loss: 1.6417 - val_accuracy: 0.8442\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1807 - accuracy: 1.0000 - val_loss: 1.6914 - val_accuracy: 0.8442\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1787 - accuracy: 1.0000 - val_loss: 1.6791 - val_accuracy: 0.8442\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1766 - accuracy: 1.0000 - val_loss: 1.6570 - val_accuracy: 0.8442\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1746 - accuracy: 1.0000 - val_loss: 1.6137 - val_accuracy: 0.8442\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.6137 - accuracy: 0.8442\n",
            "Test Loss: 1.6137268543243408, Test Accuracy: 0.8441558480262756\n",
            "\n",
            "Average Accuracy Across All Folds: 0.8720569849014282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Weight"
      ],
      "metadata": {
        "id": "xSyOpl70WgKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "    class_weight = {0: 0.15, 1: 0.85}\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=128, validation_data=(X_test, y_test), class_weight=class_weight)\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "id": "kFZ6COdxWjz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Up sampling"
      ],
      "metadata": {
        "id": "g55GrcBP0lIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import AdamW\n",
        "from keras.regularizers import l2\n"
      ],
      "metadata": {
        "id": "8cHTkjvN5g8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import where\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "A8pC4Ml15mvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 증강o\n",
        "\n",
        "def load_images_and_labels(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # 랜덤으로 선택할 증강 리스트\n",
        "    augmentation_options = [\n",
        "        {'name': 'rotation', 'param': 40},\n",
        "        {'name': 'width_shift', 'param': 0.2},\n",
        "        {'name': 'height_shift', 'param': 0.2},\n",
        "        {'name': 'shear', 'param': 0.2},\n",
        "        {'name': 'zoom', 'param': 0.2},\n",
        "        {'name': 'horizontal_flip', 'param': True},\n",
        "    ]\n",
        "\n",
        "    # 데이터 증강을 위한 ImageDataGenerator 정의\n",
        "    datagen = ImageDataGenerator()\n",
        "\n",
        "    for folder_name in os.listdir(data_dir):\n",
        "        folder_path = os.path.join(data_dir, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for filename in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, filename)\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                # 원본 이미지를 리스트에 추가\n",
        "                images.append(img)\n",
        "                labels.append(folder_name)\n",
        "\n",
        "                # 랜덤으로 선택한 증강 옵션을 적용\n",
        "                selected_augmentations = random.sample(augmentation_options, k=random.randint(0, len(augmentation_options)))\n",
        "                for aug_option in selected_augmentations:\n",
        "                    if aug_option['name'] == 'rotation':\n",
        "                        img = ImageDataGenerator(rotation_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'width_shift':\n",
        "                        img = ImageDataGenerator(width_shift_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'height_shift':\n",
        "                        img = ImageDataGenerator(height_shift_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'shear':\n",
        "                        img = ImageDataGenerator(shear_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'zoom':\n",
        "                        img = ImageDataGenerator(zoom_range=aug_option['param']).random_transform(img)\n",
        "                    elif aug_option['name'] == 'horizontal_flip':\n",
        "                        img = ImageDataGenerator(horizontal_flip=aug_option['param']).random_transform(img)\n",
        "\n",
        "                    # 증강된 이미지를 리스트에 추가\n",
        "                    images.append(img)\n",
        "                    labels.append(folder_name)\n",
        "    return shuffle(images, labels, random_state=42)"
      ],
      "metadata": {
        "id": "zZSF30BN5ix8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "epoch 50 -> 30 / 오버피팅 위험이 있기 때문에 줄임"
      ],
      "metadata": {
        "id": "Q__cdCDGXCuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "# Flatten each image if needed\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_flatten = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Apply SMOTE\n",
        "smt = SMOTE()\n",
        "X_new, y_new = smt.fit_resample(X_flatten, y)\n",
        "\n",
        "X_new_reshaped = X_new.reshape(X_new.shape[0], 128, 128, 3)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X_new_reshaped):\n",
        "    X_train, X_test = X_new_reshaped[train_index], X_new_reshaped[test_index]\n",
        "    y_train, y_test = y_new[train_index], y_new[test_index]\n",
        "\n",
        "    model = create_vgg16_model()\n",
        "\n",
        "\n",
        "    # 모델 훈련\n",
        "    history = model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_test, y_test)) # 오버피팅 가능성이 있기 때문에 epoch 줄임\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    plot_learning_curve(history)\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "id": "QPgLW5vYXE6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batchnormalization O / Epoch 30"
      ],
      "metadata": {
        "id": "Kr_K65Y3XiLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "# Flatten each image if needed\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_flatten = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Apply SMOTE\n",
        "smt = SMOTE()\n",
        "X_new, y_new = smt.fit_resample(X_flatten, y)\n",
        "\n",
        "X_new_reshaped = X_new.reshape(X_new.shape[0], 128, 128, 3)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model_with_upsampling():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X_new_reshaped):\n",
        "    X_train, X_test = X_new_reshaped[train_index], X_new_reshaped[test_index]\n",
        "    y_train, y_test = y_new[train_index], y_new[test_index]\n",
        "\n",
        "    model = create_vgg16_model_with_upsampling()\n",
        "\n",
        "\n",
        "    # 모델 훈련\n",
        "    history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test)) # 오버피팅 가능성이 있기 때문에 epoch 줄임\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    plot_learning_curve(history)\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "id": "-O2FgXf1XqH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 40"
      ],
      "metadata": {
        "id": "G1Pm3tFNXrqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.9862648725509644"
      ],
      "metadata": {
        "id": "BOEr5kNp76Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "# Flatten each image if needed\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_flatten = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Apply SMOTE\n",
        "smt = SMOTE()\n",
        "X_new, y_new = smt.fit_resample(X_flatten, y)\n",
        "\n",
        "X_new_reshaped = X_new.reshape(X_new.shape[0], 128, 128, 3)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model_with_upsampling():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X_new_reshaped):\n",
        "    X_train, X_test = X_new_reshaped[train_index], X_new_reshaped[test_index]\n",
        "    y_train, y_test = y_new[train_index], y_new[test_index]\n",
        "\n",
        "    model = create_vgg16_model_with_upsampling()\n",
        "\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=40, batch_size=64, validation_data=(X_test, y_test)) # 오버피팅 가능성이 있기 때문에 epoch 줄임\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5rtFsG61Scd",
        "outputId": "5b385d63-ce07-411d-be2d-c04782e31a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "26/26 [==============================] - 28s 286ms/step - loss: 93.0689 - accuracy: 0.8043 - val_loss: 89.7457 - val_accuracy: 0.5931\n",
            "Epoch 2/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 85.8409 - accuracy: 0.9245 - val_loss: 83.3382 - val_accuracy: 0.4804\n",
            "Epoch 3/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 78.7849 - accuracy: 0.9344 - val_loss: 77.4373 - val_accuracy: 0.4804\n",
            "Epoch 4/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 72.1718 - accuracy: 0.9331 - val_loss: 71.7657 - val_accuracy: 0.4877\n",
            "Epoch 5/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 66.1169 - accuracy: 0.9491 - val_loss: 67.3898 - val_accuracy: 0.4804\n",
            "Epoch 6/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 60.4409 - accuracy: 0.9730 - val_loss: 61.5648 - val_accuracy: 0.4804\n",
            "Epoch 7/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 55.1161 - accuracy: 0.9853 - val_loss: 56.5433 - val_accuracy: 0.4877\n",
            "Epoch 8/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 50.1408 - accuracy: 0.9791 - val_loss: 50.7109 - val_accuracy: 0.4926\n",
            "Epoch 9/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 45.4922 - accuracy: 0.9810 - val_loss: 46.5970 - val_accuracy: 0.5662\n",
            "Epoch 10/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 41.2599 - accuracy: 0.9798 - val_loss: 40.7984 - val_accuracy: 0.6887\n",
            "Epoch 11/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 37.4344 - accuracy: 0.9755 - val_loss: 37.2403 - val_accuracy: 0.6887\n",
            "Epoch 12/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 34.0219 - accuracy: 0.9724 - val_loss: 32.9959 - val_accuracy: 0.8431\n",
            "Epoch 13/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 30.9248 - accuracy: 0.9718 - val_loss: 29.6133 - val_accuracy: 0.9289\n",
            "Epoch 14/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 28.0696 - accuracy: 0.9834 - val_loss: 26.6771 - val_accuracy: 0.9730\n",
            "Epoch 15/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 25.5095 - accuracy: 0.9755 - val_loss: 24.2451 - val_accuracy: 0.9828\n",
            "Epoch 16/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 23.2519 - accuracy: 0.9706 - val_loss: 22.6719 - val_accuracy: 0.9338\n",
            "Epoch 17/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 21.1180 - accuracy: 0.9798 - val_loss: 20.1448 - val_accuracy: 0.9755\n",
            "Epoch 18/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 19.1792 - accuracy: 0.9828 - val_loss: 18.1654 - val_accuracy: 0.9902\n",
            "Epoch 19/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 17.3589 - accuracy: 0.9840 - val_loss: 16.4689 - val_accuracy: 0.9951\n",
            "Epoch 20/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 15.7012 - accuracy: 0.9914 - val_loss: 14.8773 - val_accuracy: 0.9926\n",
            "Epoch 21/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 14.1868 - accuracy: 0.9945 - val_loss: 13.4333 - val_accuracy: 0.9926\n",
            "Epoch 22/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 12.8230 - accuracy: 0.9920 - val_loss: 12.1377 - val_accuracy: 0.9877\n",
            "Epoch 23/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 11.6037 - accuracy: 0.9871 - val_loss: 11.1717 - val_accuracy: 0.9681\n",
            "Epoch 24/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 10.6218 - accuracy: 0.9798 - val_loss: 9.9777 - val_accuracy: 0.9902\n",
            "Epoch 25/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 9.5046 - accuracy: 0.9920 - val_loss: 8.9950 - val_accuracy: 0.9902\n",
            "Epoch 26/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 8.5842 - accuracy: 0.9871 - val_loss: 8.1126 - val_accuracy: 0.9926\n",
            "Epoch 27/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 7.7138 - accuracy: 0.9951 - val_loss: 7.2924 - val_accuracy: 0.9975\n",
            "Epoch 28/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 6.9266 - accuracy: 0.9963 - val_loss: 6.6164 - val_accuracy: 0.9755\n",
            "Epoch 29/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 6.2607 - accuracy: 0.9877 - val_loss: 5.9027 - val_accuracy: 0.9853\n",
            "Epoch 30/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 5.6627 - accuracy: 0.9840 - val_loss: 5.4282 - val_accuracy: 0.9559\n",
            "Epoch 31/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 5.0889 - accuracy: 0.9933 - val_loss: 4.8467 - val_accuracy: 0.9804\n",
            "Epoch 32/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.5974 - accuracy: 0.9914 - val_loss: 4.3589 - val_accuracy: 0.9828\n",
            "Epoch 33/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.1329 - accuracy: 0.9933 - val_loss: 3.9107 - val_accuracy: 0.9902\n",
            "Epoch 34/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 3.7135 - accuracy: 0.9939 - val_loss: 3.5200 - val_accuracy: 0.9902\n",
            "Epoch 35/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.3824 - accuracy: 0.9896 - val_loss: 3.2443 - val_accuracy: 0.9779\n",
            "Epoch 36/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.0674 - accuracy: 0.9859 - val_loss: 2.8832 - val_accuracy: 0.9877\n",
            "Epoch 37/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.7869 - accuracy: 0.9859 - val_loss: 2.7484 - val_accuracy: 0.9559\n",
            "Epoch 38/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 2.5756 - accuracy: 0.9791 - val_loss: 2.6414 - val_accuracy: 0.9338\n",
            "Epoch 39/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.3266 - accuracy: 0.9816 - val_loss: 2.3823 - val_accuracy: 0.9583\n",
            "Epoch 40/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.0776 - accuracy: 0.9914 - val_loss: 1.9961 - val_accuracy: 0.9779\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 1.9961 - accuracy: 0.9779\n",
            "Test Loss: 1.9961155652999878, Test Accuracy: 0.9779411554336548\n",
            "Epoch 1/40\n",
            "26/26 [==============================] - 11s 89ms/step - loss: 93.3150 - accuracy: 0.7890 - val_loss: 90.0826 - val_accuracy: 0.6250\n",
            "Epoch 2/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 86.4527 - accuracy: 0.9178 - val_loss: 83.9404 - val_accuracy: 0.5882\n",
            "Epoch 3/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 79.6363 - accuracy: 0.9252 - val_loss: 78.0262 - val_accuracy: 0.5515\n",
            "Epoch 4/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 73.0073 - accuracy: 0.9589 - val_loss: 72.2681 - val_accuracy: 0.5319\n",
            "Epoch 5/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 66.7338 - accuracy: 0.9693 - val_loss: 66.8478 - val_accuracy: 0.5319\n",
            "Epoch 6/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 60.8409 - accuracy: 0.9699 - val_loss: 59.8708 - val_accuracy: 0.5319\n",
            "Epoch 7/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 55.3627 - accuracy: 0.9663 - val_loss: 56.4075 - val_accuracy: 0.5343\n",
            "Epoch 8/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 50.3574 - accuracy: 0.9650 - val_loss: 49.5520 - val_accuracy: 0.6446\n",
            "Epoch 9/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 45.7401 - accuracy: 0.9810 - val_loss: 44.9579 - val_accuracy: 0.6814\n",
            "Epoch 10/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 41.5237 - accuracy: 0.9779 - val_loss: 40.5305 - val_accuracy: 0.7549\n",
            "Epoch 11/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 37.7313 - accuracy: 0.9675 - val_loss: 36.4048 - val_accuracy: 0.8529\n",
            "Epoch 12/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 34.2613 - accuracy: 0.9681 - val_loss: 33.1182 - val_accuracy: 0.8873\n",
            "Epoch 13/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 31.1791 - accuracy: 0.9675 - val_loss: 30.0334 - val_accuracy: 0.9265\n",
            "Epoch 14/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 28.3732 - accuracy: 0.9755 - val_loss: 27.3661 - val_accuracy: 0.9412\n",
            "Epoch 15/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 25.8604 - accuracy: 0.9693 - val_loss: 25.0260 - val_accuracy: 0.9387\n",
            "Epoch 16/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 23.4572 - accuracy: 0.9840 - val_loss: 22.3279 - val_accuracy: 0.9828\n",
            "Epoch 17/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 21.2669 - accuracy: 0.9847 - val_loss: 20.4598 - val_accuracy: 0.9657\n",
            "Epoch 18/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 19.2468 - accuracy: 0.9926 - val_loss: 18.2894 - val_accuracy: 0.9828\n",
            "Epoch 19/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 17.3834 - accuracy: 0.9963 - val_loss: 16.4740 - val_accuracy: 0.9902\n",
            "Epoch 20/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 15.6906 - accuracy: 0.9920 - val_loss: 14.8658 - val_accuracy: 0.9902\n",
            "Epoch 21/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 14.1429 - accuracy: 0.9957 - val_loss: 13.4058 - val_accuracy: 0.9877\n",
            "Epoch 22/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 12.7425 - accuracy: 0.9939 - val_loss: 12.0573 - val_accuracy: 0.9926\n",
            "Epoch 23/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 11.4495 - accuracy: 0.9951 - val_loss: 11.0521 - val_accuracy: 0.9314\n",
            "Epoch 24/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 10.3946 - accuracy: 0.9791 - val_loss: 9.9693 - val_accuracy: 0.9706\n",
            "Epoch 25/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 9.3998 - accuracy: 0.9791 - val_loss: 8.8983 - val_accuracy: 0.9828\n",
            "Epoch 26/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 8.4545 - accuracy: 0.9908 - val_loss: 8.0498 - val_accuracy: 0.9902\n",
            "Epoch 27/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 7.5883 - accuracy: 0.9975 - val_loss: 7.2353 - val_accuracy: 0.9828\n",
            "Epoch 28/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 6.8519 - accuracy: 0.9859 - val_loss: 6.4970 - val_accuracy: 0.9902\n",
            "Epoch 29/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 6.1560 - accuracy: 0.9902 - val_loss: 5.9008 - val_accuracy: 0.9755\n",
            "Epoch 30/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 5.5393 - accuracy: 0.9902 - val_loss: 5.2555 - val_accuracy: 0.9902\n",
            "Epoch 31/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.9619 - accuracy: 0.9982 - val_loss: 4.6951 - val_accuracy: 0.9902\n",
            "Epoch 32/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.4938 - accuracy: 0.9816 - val_loss: 4.3008 - val_accuracy: 0.9559\n",
            "Epoch 33/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.0638 - accuracy: 0.9853 - val_loss: 4.0295 - val_accuracy: 0.9363\n",
            "Epoch 34/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.6537 - accuracy: 0.9896 - val_loss: 3.5227 - val_accuracy: 0.9853\n",
            "Epoch 35/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.2598 - accuracy: 0.9963 - val_loss: 3.2141 - val_accuracy: 0.9828\n",
            "Epoch 36/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.9157 - accuracy: 0.9963 - val_loss: 2.8130 - val_accuracy: 0.9877\n",
            "Epoch 37/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.6085 - accuracy: 0.9975 - val_loss: 2.5725 - val_accuracy: 0.9804\n",
            "Epoch 38/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.3430 - accuracy: 0.9963 - val_loss: 2.2471 - val_accuracy: 0.9853\n",
            "Epoch 39/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.0883 - accuracy: 0.9957 - val_loss: 1.9657 - val_accuracy: 0.9951\n",
            "Epoch 40/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 1.8737 - accuracy: 0.9945 - val_loss: 1.7991 - val_accuracy: 0.9828\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 1.7991 - accuracy: 0.9828\n",
            "Test Loss: 1.7991068363189697, Test Accuracy: 0.9828431606292725\n",
            "Epoch 1/40\n",
            "26/26 [==============================] - 11s 90ms/step - loss: 92.9320 - accuracy: 0.8239 - val_loss: 89.4796 - val_accuracy: 0.5564\n",
            "Epoch 2/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 85.5538 - accuracy: 0.9172 - val_loss: 83.2715 - val_accuracy: 0.4975\n",
            "Epoch 3/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 78.3499 - accuracy: 0.9460 - val_loss: 77.3735 - val_accuracy: 0.4975\n",
            "Epoch 4/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 71.5696 - accuracy: 0.9558 - val_loss: 71.5734 - val_accuracy: 0.4975\n",
            "Epoch 5/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 65.1975 - accuracy: 0.9706 - val_loss: 66.8263 - val_accuracy: 0.4975\n",
            "Epoch 6/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 59.2203 - accuracy: 0.9767 - val_loss: 62.8097 - val_accuracy: 0.4975\n",
            "Epoch 7/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 53.6642 - accuracy: 0.9712 - val_loss: 55.8253 - val_accuracy: 0.5025\n",
            "Epoch 8/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 48.6250 - accuracy: 0.9699 - val_loss: 47.8307 - val_accuracy: 0.6201\n",
            "Epoch 9/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 44.1174 - accuracy: 0.9638 - val_loss: 46.9671 - val_accuracy: 0.5417\n",
            "Epoch 10/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 40.1595 - accuracy: 0.9540 - val_loss: 39.7799 - val_accuracy: 0.7500\n",
            "Epoch 11/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 36.5881 - accuracy: 0.9558 - val_loss: 35.8020 - val_accuracy: 0.8064\n",
            "Epoch 12/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 33.3494 - accuracy: 0.9699 - val_loss: 31.9847 - val_accuracy: 0.8995\n",
            "Epoch 13/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 30.3374 - accuracy: 0.9822 - val_loss: 29.3757 - val_accuracy: 0.9020\n",
            "Epoch 14/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 27.6418 - accuracy: 0.9718 - val_loss: 26.4109 - val_accuracy: 0.9363\n",
            "Epoch 15/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 25.0914 - accuracy: 0.9847 - val_loss: 24.4595 - val_accuracy: 0.8799\n",
            "Epoch 16/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 22.7573 - accuracy: 0.9902 - val_loss: 21.8407 - val_accuracy: 0.9485\n",
            "Epoch 17/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 20.6064 - accuracy: 0.9920 - val_loss: 19.5774 - val_accuracy: 0.9804\n",
            "Epoch 18/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 18.6198 - accuracy: 0.9939 - val_loss: 17.7339 - val_accuracy: 0.9706\n",
            "Epoch 19/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 16.8059 - accuracy: 0.9951 - val_loss: 15.9821 - val_accuracy: 0.9804\n",
            "Epoch 20/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 15.1778 - accuracy: 0.9877 - val_loss: 14.3897 - val_accuracy: 0.9828\n",
            "Epoch 21/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 13.6947 - accuracy: 0.9896 - val_loss: 12.9672 - val_accuracy: 0.9902\n",
            "Epoch 22/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 12.4355 - accuracy: 0.9767 - val_loss: 11.8496 - val_accuracy: 0.9632\n",
            "Epoch 23/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 11.2944 - accuracy: 0.9767 - val_loss: 10.8253 - val_accuracy: 0.9681\n",
            "Epoch 24/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 10.2542 - accuracy: 0.9785 - val_loss: 9.6907 - val_accuracy: 0.9926\n",
            "Epoch 25/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 9.2271 - accuracy: 0.9902 - val_loss: 8.7419 - val_accuracy: 0.9951\n",
            "Epoch 26/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 8.3303 - accuracy: 0.9908 - val_loss: 7.9481 - val_accuracy: 0.9804\n",
            "Epoch 27/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 7.5290 - accuracy: 0.9896 - val_loss: 7.1305 - val_accuracy: 0.9951\n",
            "Epoch 28/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 6.7688 - accuracy: 0.9920 - val_loss: 6.4824 - val_accuracy: 0.9804\n",
            "Epoch 29/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 6.0916 - accuracy: 0.9926 - val_loss: 5.7748 - val_accuracy: 0.9926\n",
            "Epoch 30/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 5.4623 - accuracy: 0.9957 - val_loss: 5.1690 - val_accuracy: 0.9951\n",
            "Epoch 31/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.8941 - accuracy: 0.9988 - val_loss: 4.6450 - val_accuracy: 0.9951\n",
            "Epoch 32/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.3780 - accuracy: 0.9988 - val_loss: 4.2040 - val_accuracy: 0.9853\n",
            "Epoch 33/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.9535 - accuracy: 0.9914 - val_loss: 3.7390 - val_accuracy: 0.9926\n",
            "Epoch 34/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.5844 - accuracy: 0.9883 - val_loss: 3.5611 - val_accuracy: 0.9436\n",
            "Epoch 35/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.3081 - accuracy: 0.9798 - val_loss: 3.1859 - val_accuracy: 0.9804\n",
            "Epoch 36/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.9897 - accuracy: 0.9926 - val_loss: 2.8683 - val_accuracy: 0.9877\n",
            "Epoch 37/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.7154 - accuracy: 0.9859 - val_loss: 2.5702 - val_accuracy: 0.9926\n",
            "Epoch 38/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.4192 - accuracy: 0.9957 - val_loss: 2.3058 - val_accuracy: 0.9902\n",
            "Epoch 39/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.1776 - accuracy: 0.9957 - val_loss: 2.0532 - val_accuracy: 0.9926\n",
            "Epoch 40/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 1.9626 - accuracy: 0.9926 - val_loss: 1.9276 - val_accuracy: 0.9902\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 1.9276 - accuracy: 0.9902\n",
            "Test Loss: 1.9276087284088135, Test Accuracy: 0.9901960492134094\n",
            "Epoch 1/40\n",
            "26/26 [==============================] - 16s 294ms/step - loss: 93.1409 - accuracy: 0.8069 - val_loss: 89.9075 - val_accuracy: 0.6216\n",
            "Epoch 2/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 86.0509 - accuracy: 0.9240 - val_loss: 83.5800 - val_accuracy: 0.5602\n",
            "Epoch 3/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 78.9044 - accuracy: 0.9552 - val_loss: 78.0451 - val_accuracy: 0.5307\n",
            "Epoch 4/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 72.0873 - accuracy: 0.9491 - val_loss: 72.0592 - val_accuracy: 0.5283\n",
            "Epoch 5/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 65.5917 - accuracy: 0.9736 - val_loss: 66.4372 - val_accuracy: 0.5307\n",
            "Epoch 6/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 59.6267 - accuracy: 0.9626 - val_loss: 59.8368 - val_accuracy: 0.5749\n",
            "Epoch 7/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 54.2415 - accuracy: 0.9540 - val_loss: 55.5376 - val_accuracy: 0.5995\n",
            "Epoch 8/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 49.2235 - accuracy: 0.9785 - val_loss: 49.7640 - val_accuracy: 0.6192\n",
            "Epoch 9/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 44.6406 - accuracy: 0.9828 - val_loss: 44.1232 - val_accuracy: 0.7174\n",
            "Epoch 10/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 40.4241 - accuracy: 0.9834 - val_loss: 39.5353 - val_accuracy: 0.7641\n",
            "Epoch 11/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 36.6258 - accuracy: 0.9730 - val_loss: 35.2280 - val_accuracy: 0.8624\n",
            "Epoch 12/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 33.2630 - accuracy: 0.9657 - val_loss: 31.7853 - val_accuracy: 0.9312\n",
            "Epoch 13/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 30.2134 - accuracy: 0.9761 - val_loss: 28.7484 - val_accuracy: 0.9681\n",
            "Epoch 14/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 27.5167 - accuracy: 0.9651 - val_loss: 26.3233 - val_accuracy: 0.9337\n",
            "Epoch 15/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 24.9410 - accuracy: 0.9810 - val_loss: 23.8245 - val_accuracy: 0.9754\n",
            "Epoch 16/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 22.6226 - accuracy: 0.9890 - val_loss: 21.5454 - val_accuracy: 0.9853\n",
            "Epoch 17/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 20.4482 - accuracy: 0.9945 - val_loss: 19.4148 - val_accuracy: 0.9877\n",
            "Epoch 18/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 18.4771 - accuracy: 0.9920 - val_loss: 17.5366 - val_accuracy: 0.9877\n",
            "Epoch 19/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 16.6819 - accuracy: 0.9908 - val_loss: 15.9092 - val_accuracy: 0.9681\n",
            "Epoch 20/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 15.1109 - accuracy: 0.9841 - val_loss: 14.2969 - val_accuracy: 0.9828\n",
            "Epoch 21/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 13.5978 - accuracy: 0.9884 - val_loss: 12.8819 - val_accuracy: 0.9975\n",
            "Epoch 22/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 12.2448 - accuracy: 0.9920 - val_loss: 11.5897 - val_accuracy: 0.9926\n",
            "Epoch 23/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 11.0121 - accuracy: 0.9933 - val_loss: 10.4679 - val_accuracy: 0.9853\n",
            "Epoch 24/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 9.9477 - accuracy: 0.9804 - val_loss: 9.4026 - val_accuracy: 0.9828\n",
            "Epoch 25/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 8.9193 - accuracy: 0.9945 - val_loss: 8.4876 - val_accuracy: 0.9779\n",
            "Epoch 26/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 8.0072 - accuracy: 0.9945 - val_loss: 7.6634 - val_accuracy: 0.9730\n",
            "Epoch 27/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 7.1768 - accuracy: 0.9957 - val_loss: 6.8542 - val_accuracy: 0.9803\n",
            "Epoch 28/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 6.4247 - accuracy: 0.9951 - val_loss: 6.0936 - val_accuracy: 0.9877\n",
            "Epoch 29/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 5.7233 - accuracy: 0.9988 - val_loss: 5.4291 - val_accuracy: 0.9828\n",
            "Epoch 30/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 5.1110 - accuracy: 0.9951 - val_loss: 4.8759 - val_accuracy: 0.9951\n",
            "Epoch 31/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.5660 - accuracy: 0.9945 - val_loss: 4.3703 - val_accuracy: 0.9951\n",
            "Epoch 32/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.1100 - accuracy: 0.9902 - val_loss: 3.9290 - val_accuracy: 0.9828\n",
            "Epoch 33/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.8928 - accuracy: 0.9595 - val_loss: 3.8408 - val_accuracy: 0.9410\n",
            "Epoch 34/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.5520 - accuracy: 0.9706 - val_loss: 3.3474 - val_accuracy: 0.9926\n",
            "Epoch 35/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.1775 - accuracy: 0.9884 - val_loss: 3.1001 - val_accuracy: 0.9681\n",
            "Epoch 36/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 2.8973 - accuracy: 0.9773 - val_loss: 2.7298 - val_accuracy: 0.9754\n",
            "Epoch 37/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.5868 - accuracy: 0.9853 - val_loss: 2.5044 - val_accuracy: 0.9705\n",
            "Epoch 38/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.3191 - accuracy: 0.9884 - val_loss: 2.1754 - val_accuracy: 0.9902\n",
            "Epoch 39/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.0567 - accuracy: 0.9926 - val_loss: 1.9457 - val_accuracy: 0.9803\n",
            "Epoch 40/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 1.8307 - accuracy: 0.9926 - val_loss: 1.7437 - val_accuracy: 0.9853\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.7437 - accuracy: 0.9853\n",
            "Test Loss: 1.7437403202056885, Test Accuracy: 0.9852579832077026\n",
            "Epoch 1/40\n",
            "26/26 [==============================] - 11s 90ms/step - loss: 93.3008 - accuracy: 0.7885 - val_loss: 90.1733 - val_accuracy: 0.5700\n",
            "Epoch 2/40\n",
            "26/26 [==============================] - 2s 71ms/step - loss: 86.4586 - accuracy: 0.9221 - val_loss: 84.0241 - val_accuracy: 0.4963\n",
            "Epoch 3/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 79.5517 - accuracy: 0.9454 - val_loss: 78.3042 - val_accuracy: 0.5012\n",
            "Epoch 4/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 72.8472 - accuracy: 0.9565 - val_loss: 71.9609 - val_accuracy: 0.4988\n",
            "Epoch 5/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 66.5002 - accuracy: 0.9712 - val_loss: 67.1759 - val_accuracy: 0.4889\n",
            "Epoch 6/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 60.5042 - accuracy: 0.9755 - val_loss: 62.2158 - val_accuracy: 0.4889\n",
            "Epoch 7/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 54.9213 - accuracy: 0.9730 - val_loss: 55.7284 - val_accuracy: 0.5135\n",
            "Epoch 8/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 49.8220 - accuracy: 0.9736 - val_loss: 51.1833 - val_accuracy: 0.5061\n",
            "Epoch 9/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 45.2103 - accuracy: 0.9669 - val_loss: 44.9632 - val_accuracy: 0.6560\n",
            "Epoch 10/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 41.1052 - accuracy: 0.9620 - val_loss: 40.1565 - val_accuracy: 0.7789\n",
            "Epoch 11/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 37.3283 - accuracy: 0.9730 - val_loss: 36.2548 - val_accuracy: 0.8059\n",
            "Epoch 12/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 33.8931 - accuracy: 0.9816 - val_loss: 32.7686 - val_accuracy: 0.8698\n",
            "Epoch 13/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 30.7696 - accuracy: 0.9810 - val_loss: 29.7640 - val_accuracy: 0.9165\n",
            "Epoch 14/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 27.8859 - accuracy: 0.9841 - val_loss: 26.6754 - val_accuracy: 0.9312\n",
            "Epoch 15/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 25.2248 - accuracy: 0.9920 - val_loss: 23.9437 - val_accuracy: 0.9803\n",
            "Epoch 16/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 22.7696 - accuracy: 0.9951 - val_loss: 21.6128 - val_accuracy: 0.9656\n",
            "Epoch 17/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 20.5770 - accuracy: 0.9828 - val_loss: 19.5169 - val_accuracy: 0.9754\n",
            "Epoch 18/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 18.5625 - accuracy: 0.9859 - val_loss: 17.5663 - val_accuracy: 0.9828\n",
            "Epoch 19/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 16.7841 - accuracy: 0.9834 - val_loss: 15.8775 - val_accuracy: 0.9902\n",
            "Epoch 20/40\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 15.1626 - accuracy: 0.9822 - val_loss: 14.3430 - val_accuracy: 0.9853\n",
            "Epoch 21/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 13.7289 - accuracy: 0.9834 - val_loss: 13.0120 - val_accuracy: 0.9902\n",
            "Epoch 22/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 12.3956 - accuracy: 0.9853 - val_loss: 11.6927 - val_accuracy: 0.9951\n",
            "Epoch 23/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 11.1558 - accuracy: 0.9920 - val_loss: 10.5802 - val_accuracy: 0.9803\n",
            "Epoch 24/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 10.0980 - accuracy: 0.9865 - val_loss: 9.6127 - val_accuracy: 0.9705\n",
            "Epoch 25/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 9.1353 - accuracy: 0.9822 - val_loss: 8.6532 - val_accuracy: 0.9828\n",
            "Epoch 26/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 8.2210 - accuracy: 0.9853 - val_loss: 7.8041 - val_accuracy: 0.9828\n",
            "Epoch 27/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 7.3838 - accuracy: 0.9902 - val_loss: 6.9576 - val_accuracy: 0.9926\n",
            "Epoch 28/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 6.6025 - accuracy: 0.9975 - val_loss: 6.2381 - val_accuracy: 0.9902\n",
            "Epoch 29/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 5.9168 - accuracy: 0.9957 - val_loss: 5.5710 - val_accuracy: 0.9951\n",
            "Epoch 30/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 5.2901 - accuracy: 0.9969 - val_loss: 4.9934 - val_accuracy: 0.9926\n",
            "Epoch 31/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.7409 - accuracy: 0.9939 - val_loss: 4.4789 - val_accuracy: 0.9951\n",
            "Epoch 32/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 4.2579 - accuracy: 0.9920 - val_loss: 4.0124 - val_accuracy: 0.9926\n",
            "Epoch 33/40\n",
            "26/26 [==============================] - 2s 71ms/step - loss: 3.8175 - accuracy: 0.9957 - val_loss: 3.6647 - val_accuracy: 0.9754\n",
            "Epoch 34/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.4384 - accuracy: 0.9890 - val_loss: 3.2359 - val_accuracy: 0.9951\n",
            "Epoch 35/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 3.0920 - accuracy: 0.9914 - val_loss: 2.9647 - val_accuracy: 0.9877\n",
            "Epoch 36/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.8398 - accuracy: 0.9847 - val_loss: 2.7559 - val_accuracy: 0.9828\n",
            "Epoch 37/40\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.5611 - accuracy: 0.9908 - val_loss: 2.4962 - val_accuracy: 0.9803\n",
            "Epoch 38/40\n",
            "26/26 [==============================] - 2s 71ms/step - loss: 2.3514 - accuracy: 0.9853 - val_loss: 2.2286 - val_accuracy: 0.9828\n",
            "Epoch 39/40\n",
            "26/26 [==============================] - 2s 71ms/step - loss: 2.1675 - accuracy: 0.9816 - val_loss: 2.0210 - val_accuracy: 0.9951\n",
            "Epoch 40/40\n",
            "26/26 [==============================] - 2s 71ms/step - loss: 1.9089 - accuracy: 0.9957 - val_loss: 1.8027 - val_accuracy: 0.9951\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 1.8027 - accuracy: 0.9951\n",
            "Test Loss: 1.8026710748672485, Test Accuracy: 0.9950860142707825\n",
            "\n",
            "Average Accuracy Across All Folds: 0.9862648725509644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "epoch 증가 + val_accuracy 에 따른 early stopping : 0.9831080913543702"
      ],
      "metadata": {
        "id": "l9f-QsgL79Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_dir = \"/content/drive/MyDrive/[딥러닝] Final Team Project/finalproject_dataset\"\n",
        "X, y = load_images_and_labels(data_dir)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=2)  # 클래스 개수에 따라 수정\n",
        "\n",
        "# 이미지 데이터를 전처리\n",
        "# Flatten each image if needed\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_flatten = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Apply SMOTE\n",
        "smt = SMOTE()\n",
        "X_new, y_new = smt.fit_resample(X_flatten, y)\n",
        "\n",
        "X_new_reshaped = X_new.reshape(X_new.shape[0], 128, 128, 3)\n",
        "\n",
        "# K-fold 교차 검증을 위한 K 값 설정\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# 모델 생성 함수\n",
        "def create_vgg16_model_with_upsampling():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))  # Adding Dropout with a dropout rate of 0.5\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 전체 k-fold에 대한 accuracy를 저장할 리스트\n",
        "all_accuracies = []\n",
        "\n",
        "# K-fold 교차 검증 수행\n",
        "for train_index, test_index in k_fold.split(X_new_reshaped):\n",
        "    X_train, X_test = X_new_reshaped[train_index], X_new_reshaped[test_index]\n",
        "    y_train, y_test = y_new[train_index], y_new[test_index]\n",
        "\n",
        "    model = create_vgg16_model_with_upsampling()\n",
        "\n",
        "\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test)) # 오버피팅 가능성이 있기 때문에 epoch 줄임\n",
        "\n",
        "    # 모델 평가\n",
        "    eval_result = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
        "\n",
        "    # 평가 결과를 리스트에 추가\n",
        "    all_accuracies.append(eval_result[1])\n",
        "\n",
        "# 전체 k-fold에 대한 평균 accuracy 계산\n",
        "average_accuracy = np.mean(all_accuracies)\n",
        "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")"
      ],
      "metadata": {
        "id": "qFHEqS8-5qXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fbabe9-93ff-428a-9a16-b4ddd4b0f6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "26/26 [==============================] - 27s 248ms/step - loss: 93.1190 - accuracy: 0.8051 - val_loss: 89.9496 - val_accuracy: 0.5542\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 86.1193 - accuracy: 0.9246 - val_loss: 83.2990 - val_accuracy: 0.5084\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 79.0404 - accuracy: 0.9457 - val_loss: 76.7688 - val_accuracy: 0.5012\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 72.1221 - accuracy: 0.9608 - val_loss: 71.5167 - val_accuracy: 0.4964\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 65.6421 - accuracy: 0.9596 - val_loss: 65.0322 - val_accuracy: 0.5036\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 59.5770 - accuracy: 0.9716 - val_loss: 60.0901 - val_accuracy: 0.4988\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 53.9626 - accuracy: 0.9795 - val_loss: 53.9825 - val_accuracy: 0.5181\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 48.8321 - accuracy: 0.9692 - val_loss: 48.7705 - val_accuracy: 0.5422\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 44.1397 - accuracy: 0.9813 - val_loss: 44.4412 - val_accuracy: 0.6024\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 39.9401 - accuracy: 0.9722 - val_loss: 39.8699 - val_accuracy: 0.7012\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 36.3742 - accuracy: 0.9475 - val_loss: 35.6060 - val_accuracy: 0.8337\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 33.0633 - accuracy: 0.9572 - val_loss: 31.7246 - val_accuracy: 0.8940\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 30.0903 - accuracy: 0.9789 - val_loss: 28.8098 - val_accuracy: 0.9470\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 27.3278 - accuracy: 0.9813 - val_loss: 26.0490 - val_accuracy: 0.9590\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 24.7639 - accuracy: 0.9891 - val_loss: 23.5983 - val_accuracy: 0.9855\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 22.4570 - accuracy: 0.9825 - val_loss: 21.3821 - val_accuracy: 0.9783\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 20.3211 - accuracy: 0.9879 - val_loss: 19.3512 - val_accuracy: 0.9880\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 18.3541 - accuracy: 0.9909 - val_loss: 17.4855 - val_accuracy: 0.9807\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 16.5798 - accuracy: 0.9897 - val_loss: 15.7285 - val_accuracy: 0.9759\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 14.9928 - accuracy: 0.9885 - val_loss: 14.2490 - val_accuracy: 0.9855\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 13.4972 - accuracy: 0.9861 - val_loss: 12.8865 - val_accuracy: 0.9687\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 12.1814 - accuracy: 0.9849 - val_loss: 11.5846 - val_accuracy: 0.9783\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 10.9826 - accuracy: 0.9903 - val_loss: 10.5143 - val_accuracy: 0.9855\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 9.8771 - accuracy: 0.9928 - val_loss: 9.3535 - val_accuracy: 0.9855\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 8.8572 - accuracy: 0.9946 - val_loss: 8.4885 - val_accuracy: 0.9904\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 7.9430 - accuracy: 0.9964 - val_loss: 7.5740 - val_accuracy: 0.9855\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 7.1105 - accuracy: 0.9976 - val_loss: 6.7341 - val_accuracy: 0.9880\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 6.3709 - accuracy: 0.9952 - val_loss: 6.1540 - val_accuracy: 0.9470\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 5.7300 - accuracy: 0.9879 - val_loss: 5.5425 - val_accuracy: 0.9855\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 5.1733 - accuracy: 0.9897 - val_loss: 5.0425 - val_accuracy: 0.9807\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.6535 - accuracy: 0.9897 - val_loss: 4.6942 - val_accuracy: 0.9373\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.1882 - accuracy: 0.9891 - val_loss: 4.0729 - val_accuracy: 0.9928\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 3.7783 - accuracy: 0.9916 - val_loss: 3.6317 - val_accuracy: 0.9880\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 3.3739 - accuracy: 0.9952 - val_loss: 3.3132 - val_accuracy: 0.9759\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 3.0223 - accuracy: 0.9934 - val_loss: 2.9517 - val_accuracy: 0.9807\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.7172 - accuracy: 0.9934 - val_loss: 2.7763 - val_accuracy: 0.9711\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.4281 - accuracy: 0.9958 - val_loss: 2.3683 - val_accuracy: 0.9952\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.1680 - accuracy: 0.9952 - val_loss: 2.0982 - val_accuracy: 0.9928\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.9277 - accuracy: 0.9970 - val_loss: 1.8552 - val_accuracy: 0.9928\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.7078 - accuracy: 1.0000 - val_loss: 1.6351 - val_accuracy: 0.9952\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.5123 - accuracy: 0.9994 - val_loss: 1.4642 - val_accuracy: 0.9952\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.3470 - accuracy: 0.9976 - val_loss: 1.3228 - val_accuracy: 0.9928\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.2097 - accuracy: 0.9976 - val_loss: 1.2982 - val_accuracy: 0.9759\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.0956 - accuracy: 0.9970 - val_loss: 1.1647 - val_accuracy: 0.9904\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 1.0681 - accuracy: 0.9922 - val_loss: 1.2209 - val_accuracy: 0.9831\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.0237 - accuracy: 0.9909 - val_loss: 1.2870 - val_accuracy: 0.9711\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.9444 - accuracy: 0.9891 - val_loss: 1.1554 - val_accuracy: 0.9711\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.8540 - accuracy: 0.9928 - val_loss: 0.8800 - val_accuracy: 0.9831\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.7621 - accuracy: 0.9964 - val_loss: 0.8198 - val_accuracy: 0.9880\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.6830 - accuracy: 0.9934 - val_loss: 0.8190 - val_accuracy: 0.9711\n",
            "13/13 [==============================] - 1s 16ms/step - loss: 0.8190 - accuracy: 0.9711\n",
            "Test Loss: 0.8189927339553833, Test Accuracy: 0.9710843563079834\n",
            "Epoch 1/50\n",
            "26/26 [==============================] - 12s 157ms/step - loss: 92.9791 - accuracy: 0.8232 - val_loss: 89.8353 - val_accuracy: 0.5253\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 85.7116 - accuracy: 0.9276 - val_loss: 83.2279 - val_accuracy: 0.4940\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 78.4417 - accuracy: 0.9433 - val_loss: 77.3347 - val_accuracy: 0.4988\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 71.5750 - accuracy: 0.9529 - val_loss: 70.5749 - val_accuracy: 0.4940\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 65.1388 - accuracy: 0.9674 - val_loss: 65.7318 - val_accuracy: 0.5036\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 59.2170 - accuracy: 0.9644 - val_loss: 59.3436 - val_accuracy: 0.5108\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 53.6428 - accuracy: 0.9807 - val_loss: 54.3286 - val_accuracy: 0.5301\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 48.6084 - accuracy: 0.9777 - val_loss: 49.5471 - val_accuracy: 0.5253\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 43.9642 - accuracy: 0.9747 - val_loss: 44.4197 - val_accuracy: 0.6554\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 39.7268 - accuracy: 0.9807 - val_loss: 39.6784 - val_accuracy: 0.7084\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 36.0162 - accuracy: 0.9644 - val_loss: 34.2648 - val_accuracy: 0.9301\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 32.5517 - accuracy: 0.9789 - val_loss: 30.9473 - val_accuracy: 0.9566\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 29.5011 - accuracy: 0.9753 - val_loss: 28.0902 - val_accuracy: 0.9373\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 26.7097 - accuracy: 0.9734 - val_loss: 25.3713 - val_accuracy: 0.9663\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 24.1897 - accuracy: 0.9777 - val_loss: 22.9846 - val_accuracy: 0.9735\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 21.8902 - accuracy: 0.9801 - val_loss: 20.7674 - val_accuracy: 0.9735\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 19.8079 - accuracy: 0.9825 - val_loss: 18.7508 - val_accuracy: 0.9855\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 17.8666 - accuracy: 0.9873 - val_loss: 17.0127 - val_accuracy: 0.9711\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 16.1332 - accuracy: 0.9861 - val_loss: 15.3052 - val_accuracy: 0.9735\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 14.5012 - accuracy: 0.9934 - val_loss: 13.8722 - val_accuracy: 0.9687\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 13.0606 - accuracy: 0.9903 - val_loss: 12.3528 - val_accuracy: 0.9831\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 11.6981 - accuracy: 0.9982 - val_loss: 11.0495 - val_accuracy: 0.9904\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 10.4790 - accuracy: 0.9964 - val_loss: 9.9427 - val_accuracy: 0.9855\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 9.3859 - accuracy: 0.9940 - val_loss: 8.8927 - val_accuracy: 0.9759\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 8.4077 - accuracy: 0.9952 - val_loss: 7.9889 - val_accuracy: 0.9783\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 7.5533 - accuracy: 0.9891 - val_loss: 7.1565 - val_accuracy: 0.9807\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 6.8260 - accuracy: 0.9819 - val_loss: 6.7716 - val_accuracy: 0.9277\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 6.1417 - accuracy: 0.9813 - val_loss: 5.8073 - val_accuracy: 0.9928\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 5.4832 - accuracy: 0.9958 - val_loss: 5.2304 - val_accuracy: 0.9807\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.9246 - accuracy: 0.9928 - val_loss: 4.6727 - val_accuracy: 0.9855\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.3957 - accuracy: 0.9934 - val_loss: 4.1334 - val_accuracy: 0.9855\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 3.9056 - accuracy: 0.9976 - val_loss: 3.7151 - val_accuracy: 0.9880\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 3.4839 - accuracy: 0.9970 - val_loss: 3.2742 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 3.0919 - accuracy: 0.9994 - val_loss: 2.9426 - val_accuracy: 0.9952\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.7427 - accuracy: 0.9994 - val_loss: 2.6036 - val_accuracy: 0.9904\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.4286 - accuracy: 0.9994 - val_loss: 2.3027 - val_accuracy: 0.9904\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.1792 - accuracy: 0.9952 - val_loss: 2.0871 - val_accuracy: 0.9807\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.0626 - accuracy: 0.9813 - val_loss: 1.9918 - val_accuracy: 0.9639\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.8538 - accuracy: 0.9928 - val_loss: 1.8767 - val_accuracy: 0.9735\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.6946 - accuracy: 0.9897 - val_loss: 1.6391 - val_accuracy: 0.9880\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.5369 - accuracy: 0.9825 - val_loss: 1.8246 - val_accuracy: 0.9277\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.3714 - accuracy: 0.9922 - val_loss: 1.3575 - val_accuracy: 0.9783\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.2270 - accuracy: 0.9958 - val_loss: 1.2182 - val_accuracy: 0.9831\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 1.0963 - accuracy: 0.9970 - val_loss: 1.1119 - val_accuracy: 0.9783\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.9739 - accuracy: 0.9970 - val_loss: 0.9505 - val_accuracy: 0.9928\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.8753 - accuracy: 0.9952 - val_loss: 0.8959 - val_accuracy: 0.9807\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.8550 - accuracy: 0.9831 - val_loss: 0.8303 - val_accuracy: 0.9855\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.7692 - accuracy: 0.9897 - val_loss: 0.8445 - val_accuracy: 0.9711\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.7044 - accuracy: 0.9940 - val_loss: 0.7058 - val_accuracy: 0.9783\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 0.6212 - accuracy: 0.9940 - val_loss: 0.5829 - val_accuracy: 0.9952\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.5829 - accuracy: 0.9952\n",
            "Test Loss: 0.5828853845596313, Test Accuracy: 0.9951807260513306\n",
            "Epoch 1/50\n",
            "26/26 [==============================] - 14s 249ms/step - loss: 92.9981 - accuracy: 0.8215 - val_loss: 89.8049 - val_accuracy: 0.5676\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 85.7721 - accuracy: 0.9234 - val_loss: 83.1698 - val_accuracy: 0.5072\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 78.5231 - accuracy: 0.9554 - val_loss: 76.2592 - val_accuracy: 0.5024\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 71.5133 - accuracy: 0.9662 - val_loss: 70.3915 - val_accuracy: 0.5024\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 64.8783 - accuracy: 0.9668 - val_loss: 64.4258 - val_accuracy: 0.5024\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 58.7168 - accuracy: 0.9692 - val_loss: 58.7234 - val_accuracy: 0.5242\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 53.1341 - accuracy: 0.9602 - val_loss: 53.6696 - val_accuracy: 0.5145\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 48.1297 - accuracy: 0.9650 - val_loss: 48.2421 - val_accuracy: 0.6522\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 43.5143 - accuracy: 0.9837 - val_loss: 43.6779 - val_accuracy: 0.6932\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 39.2832 - accuracy: 0.9837 - val_loss: 38.0000 - val_accuracy: 0.7874\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 35.4259 - accuracy: 0.9801 - val_loss: 34.1574 - val_accuracy: 0.8647\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 31.9253 - accuracy: 0.9801 - val_loss: 30.3674 - val_accuracy: 0.9444\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 28.8158 - accuracy: 0.9807 - val_loss: 27.4740 - val_accuracy: 0.9565\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 26.0564 - accuracy: 0.9662 - val_loss: 25.1030 - val_accuracy: 0.8865\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 23.5344 - accuracy: 0.9674 - val_loss: 22.6085 - val_accuracy: 0.9275\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 21.1931 - accuracy: 0.9891 - val_loss: 20.2585 - val_accuracy: 0.9517\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 19.0818 - accuracy: 0.9897 - val_loss: 18.2198 - val_accuracy: 0.9589\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 17.1806 - accuracy: 0.9873 - val_loss: 16.3645 - val_accuracy: 0.9710\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 15.4516 - accuracy: 0.9849 - val_loss: 14.6270 - val_accuracy: 0.9855\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 13.8795 - accuracy: 0.9855 - val_loss: 13.1029 - val_accuracy: 0.9903\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 12.4449 - accuracy: 0.9897 - val_loss: 11.7976 - val_accuracy: 0.9807\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 11.1557 - accuracy: 0.9879 - val_loss: 10.6236 - val_accuracy: 0.9638\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 9.9626 - accuracy: 0.9928 - val_loss: 9.4828 - val_accuracy: 0.9855\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 8.9036 - accuracy: 0.9910 - val_loss: 8.4067 - val_accuracy: 0.9879\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 7.9552 - accuracy: 0.9897 - val_loss: 7.5555 - val_accuracy: 0.9879\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 7.1063 - accuracy: 0.9928 - val_loss: 6.7964 - val_accuracy: 0.9879\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 6.3370 - accuracy: 0.9934 - val_loss: 6.0511 - val_accuracy: 0.9831\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 5.7100 - accuracy: 0.9897 - val_loss: 5.4163 - val_accuracy: 0.9638\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 5.0744 - accuracy: 0.9958 - val_loss: 4.8777 - val_accuracy: 0.9734\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.5241 - accuracy: 0.9952 - val_loss: 4.3734 - val_accuracy: 0.9783\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.0407 - accuracy: 0.9928 - val_loss: 3.8836 - val_accuracy: 0.9855\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 3.6040 - accuracy: 0.9928 - val_loss: 3.5682 - val_accuracy: 0.9710\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 3.2521 - accuracy: 0.9928 - val_loss: 3.3335 - val_accuracy: 0.9734\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.9145 - accuracy: 0.9952 - val_loss: 2.8385 - val_accuracy: 0.9903\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.6441 - accuracy: 0.9849 - val_loss: 2.6025 - val_accuracy: 0.9710\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.4119 - accuracy: 0.9843 - val_loss: 2.4817 - val_accuracy: 0.9662\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.2445 - accuracy: 0.9759 - val_loss: 2.1981 - val_accuracy: 0.9662\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.0141 - accuracy: 0.9825 - val_loss: 2.0403 - val_accuracy: 0.9638\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.7740 - accuracy: 0.9928 - val_loss: 1.7562 - val_accuracy: 0.9831\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.5785 - accuracy: 0.9934 - val_loss: 1.5044 - val_accuracy: 0.9928\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.3761 - accuracy: 0.9988 - val_loss: 1.3239 - val_accuracy: 0.9952\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.2101 - accuracy: 0.9982 - val_loss: 1.1727 - val_accuracy: 0.9928\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.0729 - accuracy: 0.9988 - val_loss: 1.0148 - val_accuracy: 0.9928\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.9380 - accuracy: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.9879\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.8244 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.9903\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.7240 - accuracy: 0.9994 - val_loss: 0.7482 - val_accuracy: 0.9952\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.6515 - accuracy: 0.9958 - val_loss: 0.6562 - val_accuracy: 0.9831\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.6398 - accuracy: 0.9891 - val_loss: 0.7368 - val_accuracy: 0.9710\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.6913 - accuracy: 0.9789 - val_loss: 0.8204 - val_accuracy: 0.9734\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.6738 - accuracy: 0.9940 - val_loss: 0.8501 - val_accuracy: 0.9734\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.8501 - accuracy: 0.9734\n",
            "Test Loss: 0.8500658869743347, Test Accuracy: 0.9734299778938293\n",
            "Epoch 1/50\n",
            "26/26 [==============================] - 12s 158ms/step - loss: 93.0624 - accuracy: 0.8142 - val_loss: 89.7714 - val_accuracy: 0.6159\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 85.8833 - accuracy: 0.9192 - val_loss: 83.0065 - val_accuracy: 0.5773\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 78.6828 - accuracy: 0.9409 - val_loss: 76.1198 - val_accuracy: 0.5411\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 71.7424 - accuracy: 0.9710 - val_loss: 70.5919 - val_accuracy: 0.5266\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 65.1494 - accuracy: 0.9759 - val_loss: 64.5366 - val_accuracy: 0.5242\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 58.9630 - accuracy: 0.9723 - val_loss: 58.4729 - val_accuracy: 0.5314\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 53.4140 - accuracy: 0.9542 - val_loss: 53.6173 - val_accuracy: 0.5169\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 48.3643 - accuracy: 0.9656 - val_loss: 49.5259 - val_accuracy: 0.6184\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 43.8797 - accuracy: 0.9668 - val_loss: 43.9610 - val_accuracy: 0.6884\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 39.8000 - accuracy: 0.9723 - val_loss: 38.7523 - val_accuracy: 0.8261\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 36.0434 - accuracy: 0.9801 - val_loss: 34.2173 - val_accuracy: 0.9758\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 32.5816 - accuracy: 0.9891 - val_loss: 31.2217 - val_accuracy: 0.9227\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 29.4288 - accuracy: 0.9885 - val_loss: 28.3721 - val_accuracy: 0.8961\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 26.6506 - accuracy: 0.9747 - val_loss: 25.7418 - val_accuracy: 0.8961\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 24.1021 - accuracy: 0.9795 - val_loss: 23.4743 - val_accuracy: 0.9227\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 21.7749 - accuracy: 0.9783 - val_loss: 21.0795 - val_accuracy: 0.9251\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 19.7063 - accuracy: 0.9723 - val_loss: 18.6603 - val_accuracy: 0.9879\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 17.7396 - accuracy: 0.9903 - val_loss: 16.8071 - val_accuracy: 0.9903\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 15.9554 - accuracy: 0.9946 - val_loss: 15.1125 - val_accuracy: 0.9879\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 14.3322 - accuracy: 0.9958 - val_loss: 13.5541 - val_accuracy: 0.9879\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 12.8440 - accuracy: 0.9970 - val_loss: 12.1128 - val_accuracy: 0.9976\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 11.4920 - accuracy: 0.9964 - val_loss: 10.8702 - val_accuracy: 0.9903\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 10.2649 - accuracy: 0.9994 - val_loss: 9.6784 - val_accuracy: 0.9928\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 9.1586 - accuracy: 0.9970 - val_loss: 8.6331 - val_accuracy: 0.9903\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 8.1694 - accuracy: 0.9976 - val_loss: 7.6973 - val_accuracy: 0.9928\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 7.2979 - accuracy: 0.9922 - val_loss: 7.1042 - val_accuracy: 0.9734\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 6.6095 - accuracy: 0.9801 - val_loss: 6.7009 - val_accuracy: 0.9130\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 5.9768 - accuracy: 0.9771 - val_loss: 5.7587 - val_accuracy: 0.9565\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 5.3977 - accuracy: 0.9831 - val_loss: 5.0845 - val_accuracy: 0.9928\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.8183 - accuracy: 0.9934 - val_loss: 4.5777 - val_accuracy: 0.9879\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.3453 - accuracy: 0.9843 - val_loss: 4.1231 - val_accuracy: 0.9807\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 3.9076 - accuracy: 0.9873 - val_loss: 3.7056 - val_accuracy: 0.9928\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 3.5184 - accuracy: 0.9916 - val_loss: 3.3103 - val_accuracy: 0.9855\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 3.1284 - accuracy: 0.9928 - val_loss: 2.9314 - val_accuracy: 0.9952\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.7907 - accuracy: 0.9952 - val_loss: 2.6278 - val_accuracy: 0.9928\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.5126 - accuracy: 0.9897 - val_loss: 2.3934 - val_accuracy: 0.9831\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.2508 - accuracy: 0.9940 - val_loss: 2.1285 - val_accuracy: 0.9928\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.9854 - accuracy: 0.9988 - val_loss: 1.8889 - val_accuracy: 0.9903\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.7536 - accuracy: 0.9994 - val_loss: 1.7057 - val_accuracy: 0.9928\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.5605 - accuracy: 0.9964 - val_loss: 1.4694 - val_accuracy: 0.9952\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.4077 - accuracy: 0.9952 - val_loss: 1.3303 - val_accuracy: 0.9903\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.2796 - accuracy: 0.9952 - val_loss: 1.2373 - val_accuracy: 0.9855\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 1.1832 - accuracy: 0.9916 - val_loss: 1.1155 - val_accuracy: 0.9928\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.0649 - accuracy: 0.9976 - val_loss: 1.0275 - val_accuracy: 0.9903\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.9648 - accuracy: 0.9946 - val_loss: 0.9365 - val_accuracy: 0.9928\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.8753 - accuracy: 0.9928 - val_loss: 0.9550 - val_accuracy: 0.9686\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 0.8339 - accuracy: 0.9837 - val_loss: 0.8179 - val_accuracy: 0.9758\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 0.7531 - accuracy: 0.9922 - val_loss: 0.7966 - val_accuracy: 0.9831\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.7010 - accuracy: 0.9916 - val_loss: 0.7457 - val_accuracy: 0.9855\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 0.6520 - accuracy: 0.9879 - val_loss: 0.6628 - val_accuracy: 0.9903\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.6628 - accuracy: 0.9903\n",
            "Test Loss: 0.6628137230873108, Test Accuracy: 0.990338146686554\n",
            "Epoch 1/50\n",
            "26/26 [==============================] - 12s 158ms/step - loss: 93.0558 - accuracy: 0.8088 - val_loss: 89.7968 - val_accuracy: 0.5411\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 85.8394 - accuracy: 0.9282 - val_loss: 83.0067 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 78.5247 - accuracy: 0.9421 - val_loss: 76.2304 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 71.6213 - accuracy: 0.9481 - val_loss: 70.1628 - val_accuracy: 0.5121\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 65.2328 - accuracy: 0.9596 - val_loss: 64.8543 - val_accuracy: 0.5121\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 59.3119 - accuracy: 0.9735 - val_loss: 59.5535 - val_accuracy: 0.5048\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 53.7678 - accuracy: 0.9873 - val_loss: 53.8129 - val_accuracy: 0.5604\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 48.6321 - accuracy: 0.9801 - val_loss: 49.5660 - val_accuracy: 0.6014\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 43.9391 - accuracy: 0.9783 - val_loss: 44.0623 - val_accuracy: 0.5773\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 39.6940 - accuracy: 0.9837 - val_loss: 38.9843 - val_accuracy: 0.7657\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 35.8589 - accuracy: 0.9759 - val_loss: 34.2173 - val_accuracy: 0.9275\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 32.3584 - accuracy: 0.9855 - val_loss: 31.4103 - val_accuracy: 0.8623\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 29.2244 - accuracy: 0.9801 - val_loss: 27.7915 - val_accuracy: 0.9541\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 26.3094 - accuracy: 0.9891 - val_loss: 25.0977 - val_accuracy: 0.9541\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 23.7030 - accuracy: 0.9849 - val_loss: 22.5712 - val_accuracy: 0.9517\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 21.4726 - accuracy: 0.9662 - val_loss: 20.3031 - val_accuracy: 0.9855\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 19.4049 - accuracy: 0.9704 - val_loss: 18.6377 - val_accuracy: 0.9493\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 17.5963 - accuracy: 0.9698 - val_loss: 17.0487 - val_accuracy: 0.9493\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 15.9227 - accuracy: 0.9662 - val_loss: 15.2287 - val_accuracy: 0.9469\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 14.3525 - accuracy: 0.9813 - val_loss: 13.6227 - val_accuracy: 0.9831\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 12.8970 - accuracy: 0.9903 - val_loss: 12.1939 - val_accuracy: 0.9928\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 11.5936 - accuracy: 0.9885 - val_loss: 10.9421 - val_accuracy: 0.9928\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 10.4040 - accuracy: 0.9934 - val_loss: 9.8252 - val_accuracy: 0.9903\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 9.3173 - accuracy: 0.9940 - val_loss: 8.8129 - val_accuracy: 0.9903\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 8.3345 - accuracy: 0.9964 - val_loss: 7.8496 - val_accuracy: 0.9976\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 7.4314 - accuracy: 0.9988 - val_loss: 7.0007 - val_accuracy: 0.9976\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 6.6200 - accuracy: 0.9994 - val_loss: 6.2360 - val_accuracy: 0.9952\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 5.8870 - accuracy: 1.0000 - val_loss: 5.5418 - val_accuracy: 0.9976\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 5.2289 - accuracy: 0.9994 - val_loss: 4.9194 - val_accuracy: 0.9952\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.6397 - accuracy: 0.9994 - val_loss: 4.3630 - val_accuracy: 0.9976\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 4.1109 - accuracy: 0.9988 - val_loss: 3.8665 - val_accuracy: 0.9952\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 3.6460 - accuracy: 0.9994 - val_loss: 3.4768 - val_accuracy: 0.9734\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 3.3177 - accuracy: 0.9843 - val_loss: 3.2827 - val_accuracy: 0.9420\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 3.0549 - accuracy: 0.9843 - val_loss: 3.3871 - val_accuracy: 0.9541\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.8234 - accuracy: 0.9879 - val_loss: 2.7071 - val_accuracy: 0.9903\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.5116 - accuracy: 0.9970 - val_loss: 2.3692 - val_accuracy: 0.9976\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.2968 - accuracy: 0.9837 - val_loss: 2.2164 - val_accuracy: 0.9783\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.0375 - accuracy: 0.9910 - val_loss: 1.9245 - val_accuracy: 0.9928\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 1.7915 - accuracy: 0.9964 - val_loss: 1.6891 - val_accuracy: 0.9928\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 1.5956 - accuracy: 0.9952 - val_loss: 1.5075 - val_accuracy: 0.9855\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.4258 - accuracy: 0.9946 - val_loss: 1.3396 - val_accuracy: 0.9952\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.2917 - accuracy: 0.9910 - val_loss: 1.2291 - val_accuracy: 0.9903\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 1.1558 - accuracy: 0.9940 - val_loss: 1.1994 - val_accuracy: 0.9783\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.0473 - accuracy: 0.9940 - val_loss: 1.0377 - val_accuracy: 0.9807\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.9706 - accuracy: 0.9903 - val_loss: 1.0398 - val_accuracy: 0.9783\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.9554 - accuracy: 0.9807 - val_loss: 1.1606 - val_accuracy: 0.9517\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 0.8883 - accuracy: 0.9843 - val_loss: 0.9171 - val_accuracy: 0.9686\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.8508 - accuracy: 0.9789 - val_loss: 0.8291 - val_accuracy: 0.9807\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.7483 - accuracy: 0.9922 - val_loss: 0.7209 - val_accuracy: 0.9928\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.6666 - accuracy: 0.9922 - val_loss: 0.6393 - val_accuracy: 0.9855\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.6393 - accuracy: 0.9855\n",
            "Test Loss: 0.6393486261367798, Test Accuracy: 0.9855072498321533\n",
            "\n",
            "Average Accuracy Across All Folds: 0.9831080913543702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5sFIv9N8HBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 비교 시각화\n"
      ],
      "metadata": {
        "id": "IUjNvjnPi4Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 성능 지표 및 설정\n",
        "models_VGG = [\n",
        "    \"Adam + Random\",\n",
        "    \"AdamW + Random\",\n",
        "    \"AdamW + Random + dropout 3\",\n",
        "    #\"AdamW + Random + L2 + dropout 3\",\n",
        "    \"AdamW + Random + L2 + dropout 6\",\n",
        "    #\"Adamw + Random + L2 + dropout 6 + epoch 100 -> 200\",\n",
        "    \"AdamW + Random + L2 + dropout 3 + Early stopping\",\n",
        "    #\"AdamW + Random + L2 + dropout 3 + Early stopping + epoch 150 + batch_noramalization\",\n",
        "    #\"Adamw + Random + L2 + dropout 3 + Early stopping + epoch 200 + batch_noramalization\",\n",
        "    \"Adamw + Random + L2 + dropout 6 + Early stopping + batch_noramalization\",\n",
        "    #\"Adamw + Random + L2 + dropout 6 + weight_decay\"\n",
        "]\n",
        "\n",
        "models = [\n",
        "    \"1\",\n",
        "    \"2\",\n",
        "    \"3\",\n",
        "    \"4\",\n",
        "    \"5\",\n",
        "    \"6\"\n",
        "]\n",
        "\n",
        "accuracy_scores = [\n",
        "    0.7055885910987854,\n",
        "    0.8914704561233521,\n",
        "    0.8707917928695679,\n",
        "    #0.825571846961975,\n",
        "    0.9095182180404663,\n",
        "    #0.8489317059516907,\n",
        "    0.8811646461486816,\n",
        "    #0.9147465348243713,\n",
        "    #0.90056973695755,\n",
        "    0.8875827431678772,\n",
        "    #0.8720569849014282\n",
        "]\n",
        "\n",
        "# 막대그래프 그리기\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.bar(models, accuracy_scores, color=['#B8E9FF','#58CCFF','#18A8F1','#1187CF','#0E6CA5','#2E3D86'])\n",
        "plt.title('Model-Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)  # 정확도 범위에 따라 조절\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "\n",
        "\n",
        "# 그래프 표시\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "id": "VU0I4FaIi6Vn",
        "outputId": "df0547ea-9d0c-4d45-86a3-941e2a520140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 성능 지표 및 설정\n",
        "models = [\n",
        "    \"Adam + Random\",\n",
        "    \"AdamW + Random\",\n",
        "    \"AdamW + Random + dropout 3\",\n",
        "    #\"AdamW + Random + L2 + dropout 3\",\n",
        "    \"AdamW + Random + L2 + dropout 6\",\n",
        "    #\"Adamw + Random + L2 + dropout 6 + epoch 100 -> 200\",\n",
        "    \"AdamW + Random + L2 + dropout 3 + Early stopping\",\n",
        "    #\"AdamW + Random + L2 + dropout 3 + Early stopping + epoch 150 + batch_noramalization\",\n",
        "    #\"Adamw + Random + L2 + dropout 3 + Early stopping + epoch 200 + batch_noramalization\",\n",
        "    \"Adamw + Random + L2 + dropout 6 + Early stopping + batch_noramalization\",\n",
        "    #\"Adamw + Random + L2 + dropout 6 + weight_decay\"\n",
        "]\n",
        "\n",
        "accuracy_scores = [\n",
        "    0.7055885910987854,\n",
        "    0.8914704561233521,\n",
        "    0.8707917928695679,\n",
        "    #0.825571846961975,\n",
        "    0.9095182180404663,\n",
        "    #0.8489317059516907,\n",
        "    0.8811646461486816,\n",
        "    #0.9147465348243713,\n",
        "    #0.90056973695755,\n",
        "    0.8875827431678772,\n",
        "    #0.8720569849014282\n",
        "]\n",
        "\n",
        "# 막대그래프 그리기\n",
        "plt.figure(figsize=(10, 10))\n",
        "bars = plt.bar(models, accuracy_scores, color='skyblue')\n",
        "plt.title('Model-Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)  # 정확도 범위에 따라 조절\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# 각 막대 위에 accuracy_scores 값을 소수점 3자리까지 나타내는 텍스트 추가\n",
        "for bar, score in zip(bars, accuracy_scores):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.01, f'{score:.3f}', ha='center')\n",
        "\n",
        "# 그래프 표시\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WW33RdbjjCy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cef02a7-670b-471f-c8c6-11a3f21e96b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QiPQPDX6Ajcd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}